{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMl7T4qs5w6g/HCvLnhdZL5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/20nu1a0586/life-live/blob/main/Generative_AI_LLM's.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install pdfx\n",
        "!pip install pdfx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RzNsUNhbs_F",
        "outputId": "1dad26a2-0782-4ca8-83b5-a6828d82a824"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfx\n",
            "  Downloading pdfx-1.4.1-py2.py3-none-any.whl (21 kB)\n",
            "Collecting pdfminer.six==20201018 (from pdfx)\n",
            "  Downloading pdfminer.six-20201018-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chardet==4.0.0 (from pdfx)\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20201018->pdfx) (42.0.2)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20201018->pdfx) (2.4.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography->pdfminer.six==20201018->pdfx) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography->pdfminer.six==20201018->pdfx) (2.21)\n",
            "Installing collected packages: chardet, pdfminer.six, pdfx\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "Successfully installed chardet-4.0.0 pdfminer.six-20201018 pdfx-1.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import pdfX\n",
        "import pdfx"
      ],
      "metadata": {
        "id": "p2EG8iO6b9Uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pdf =pdfx.PDFx(\"file:///C:/Users/DIVYAGOWRIPENTAKOTA/Downloads/A-New-Vegetation-Index-to-Dete-35086913-d72d-4d90-b224-4bd93a517488.pdf\")\n",
        "pdf =pdfx.PDFx(\"/content/A-New-Vegetation-Index-to-Dete-35086913-d72d-4d90-b224-4bd93a517488.pdf\")\n",
        "pdf"
      ],
      "metadata": {
        "id": "xPJ21_Q8cBv0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2712707-08fa-4519-cb21-a27e54532642"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pdfx.PDFx at 0x7f40640f69e0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text =pdf.get_text()\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HGTD1gYvc-m_",
        "outputId": "4b537f07-3e4c-400a-d339-63854d6c3ea9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Article\\nA New Vegetation Index to Detect Periodically\\nSubmerged Mangrove Forest Using Single-Tide\\nSentinel-2 Imagery\\n\\nMingming Jia 1,2\\n\\n, Zongming Wang 1,*, Chao Wang 2\\n\\n, Dehua Mao 1\\n\\nand Yuanzhi Zhang 3,4\\n\\n1 Key Laboratory of Wetland Ecology and Environment, Northeast Institute of Geography and Agroecology,\\n\\n2\\n\\nChinese Academy of Sciences, No. 4888, Shengbei Street, Changchun 130102, China\\nState Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan\\nUniversity, No.129 Luoyu Road, Wuhan 430079, China\\n\\n3 Center for Housing Innovations, Chinese University of Hong Kong, Shatin, New Territories, Hong Kong\\n4 Key Lab of Lunar Science and Deep-exploration, National Astronomical Observatories, Chinese Academy of\\n\\nSciences, Beijing 100101, China\\n\\n* Correspondence: zongmingwang@iga.ac.cn\\n\\nReceived: 4 July 2019; Accepted: 27 August 2019; Published: 29 August 2019\\n\\nAbstract: Mangrove forests are tropical trees and shrubs that grow in sheltered intertidal zones.\\nAccurate mapping of mangrove forests is a great challenge for remote sensing because mangroves are\\nperiodically submerged by tidal ﬂoods. Traditionally, multi-tides images were needed to remove the\\ninﬂuence of water; however, such images are often unavailable due to rainy climates and uncertain\\nlocal tidal conditions. Therefore, extracting mangrove forests from a single-tide imagery is of great\\nimportance. In this study, reﬂectance of red-edge bands in Sentinel-2 imagery were utilized to\\nestablish a new vegetation index that is sensitive to submerged mangrove forests. Speciﬁcally, red\\nand short-wave near infrared bands were used to build a linear baseline; the average reﬂectance\\nvalue of four red-edge bands above the baseline is deﬁned as the Mangrove Forest Index (MFI).\\nTo evaluate MFI, capabilities of detecting mangrove forests were quantitatively assessed between\\nMFI and four widely used vegetation indices (VIs). Additionally, the practical roles of MFI were\\nvalidated by applying it to three mangrove forest sites globally. Results showed that: (1) theoretically,\\nJensen–Shannon divergence demonstrated that a submerged mangrove forest and water pixels have\\nthe largest distance in MFI compared to other VIs. In addition, the boxplot showed that all submerged\\nmangrove forests could be separated from the water background in the MFI image. Furthermore, in\\nthe MFI image, to separate mangrove forests and water, the threshold is a constant that is equal to\\nzero. (2) Practically, after applying the MFI to three global sites, 99–102% of submerged mangrove\\nforests were successfully extracted by MFI. Although there are still some uncertainties and limitations,\\nthe MFI oﬀers great beneﬁts in accurately mapping mangrove forests as well as other coastal and\\naquatic vegetation worldwide.\\n\\nKeywords: Sentinel-2 MultiSpectral Instrument (MSI); red-edge band; aquatic vegetation; tidal\\ncondition; vegetation index; coastal vegetation\\n\\n1. Introduction\\n\\nMangrove forest are highly productive ecosystems with signiﬁcant ecological and socio- economic\\nimportance in the world [1,2]. However, over the past century, these forests have declined at an\\nalarming rate that is more rapid than that of inland tropical forests [3]. Therefore, there is an emerging\\ndemand for conservation and restoration eﬀorts in mangrove forests. Obtaining accurate information\\n\\nRemote Sens. 2019, 11, 2043; doi:10.3390/rs11172043\\n\\nwww.mdpi.com/journal/remotesensing\\n\\nremote sensing  (cid:1)(cid:2)(cid:3)(cid:1)(cid:4)(cid:5)(cid:6)(cid:7)(cid:8)(cid:1)(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)\\x0cRemote Sens. 2019, 11, 2043\\n\\n2 of 17\\n\\nregarding the current and past acreage and condition of mangrove forests is essential for eﬃcient\\nmanagement of these ecosystems and for policy- and decision-making processes [4,5].\\n\\nLocated in intertidal zones, mangrove forests are often inaccessible for traditional ﬁeld surveys.\\nFor decades, remote sensing has been widely used to monitor the distribution of mangrove forests, yet\\naccurate and timely interpretation of the relatively small patches has been rare, due to the lack of full\\nconsideration of tidal conditions [6–9]. Mangrove forests located near the shoreline are periodically\\nsubmerged by tides, especially in regions with high tide ﬂuctuations and lower mangrove shrubs [9,10].\\nIdeally, it is better to use images acquired during low tides; however, such data are diﬃcult to obtain,\\ndue to uncertainties of local instantaneous tidal conditions during predetermined times that satellites\\npass over [11,12]. For a long time, numerous studies have pointed out that tides may seriously\\ninﬂuence remote sensing results of mangrove forests, yet, solutions were not reported until the past\\ntwo years [10,13,14]. However, all these studies used multi-tides (multi-date) images; therefore, we\\nhave one concern: if multi-tides images are not available due to rainy climates and uncertain local tide\\nconditions, how could we accurately map mangrove forests by a single-date image?\\n\\nOver the last two decades, remote sensing of submerged and emerged aquatic vegetation has\\nbeen widely studied [15,16]. Hyperspectral image with numerous narrow and contiguous bands is\\nreliable for studying aquatic vegetation and is able to detect the biophysical properties of vegetation\\neﬃciently [16–19]. However, there is no freely available satellite hyperspectral data in recent years, and\\nairborne applications are exorbitantly expensive and only cover a very small spatial extent. Landsat\\nimages with moderate spatial resolution of 30–60 m have been widely used for mapping aquatic\\nvegetation [20–24]. Yet, Landsat only has one band in the spectral region of near infrared (760–900 nm),\\nwhich may become less sensitive as water depth increases [25]. The MODIS (Moderate Resolution\\nImaging Spectroradiometer) and AVHRR (Advanced Very High Resolution Radiometer) are publicly\\navailable with high spectral resolution but coarse spatial resolution (250–1100 m, respectively), making\\nthem unsuitable for mangrove detection [9]. In contrast, the Sentinel-2 MultiSpectral Instrument\\n(MSI) sensor has a 10–20 m spatial resolution and ﬁve bands in near infrared region, which provides\\nopportunities to conduct quick, robust, and eﬃcient monitoring of submerged mangrove forests.\\n\\nFor years, numerous methods were utilized to map mangrove forests as well as other aquatic\\nvegetation from remote sensing imagery, ranging from pixel to object-oriented approach, and manual\\nto unsupervised methods [9,14,26–28]. Recently, machine-learning algorithms such as random\\nforest, neural network, and support vector machine provide promising accuracy in mangrove forests\\nextraction [10,13,29]. As it is hard to locate representative training samples due to uncertain tidal\\nconditions, it is relatively hard to apply these methods to extract submerged mangrove forests from\\na single-date image. Vegetation indices (VIs), which are mathematically determined based on the\\nspectral characteristics of vegetation, have been proven eﬃcient in monitoring vegetation from\\nspace [30]. The Normalized Diﬀerence Vegetation Index (NDVI) is the most commonly used index\\nin global vegetation studies (e.g., [30,31]). The Land Surface Water Index (LSWI) and the Modiﬁed\\nNormalized Diﬀerence Water Index (MNDWI) were proposed and widely used for mapping surface\\nwater [32–34]. Given that these indices are established based on diﬀerences between two bands,\\nthey are insensitive to small variations of the reﬂectance of submerged mangrove forests and water\\nbackground [14]. Furthermore, it is hard to decide thresholds that distinguish submerged mangroves\\nand water. With more bands, several VIs were built based on a baseline theory, such as Maximum\\nChlorophyll Index (MCI; [35]), the Floating Algae Index (FAI; [36]), and the Floating Vegetation Index\\n(FVI; [17]). However, these indices were deﬁned to extract ﬂoating vegetation (above water surface)\\nfrom water, not submerged vegetation. Meanwhile, bands used to build MCI and FVI did not exist in\\nSentinel MSI image.\\n\\nThus, the objective of this study is to develop a new vegetation index, called the Mangrove Forest\\nIndex (MFI), which is capable to map the distribution of mangroves based on a single date MSI image.\\nThen, we will compare MFI with other widely used VIs to validate MFI’s capabilities in detecting\\nsubmerged mangrove forests from water background. Additionally, MFI will be applied to three sites\\n\\n\\x0cRemote Sens. 2019, 11, 2043\\n\\n3 of 17\\n\\nof typical mangrove forests worldwide; the practical roles of mapping mangrove forests during local\\nhigh-tide conditions will also be discussed.\\n\\n2. Materials and Methods\\n\\n2.1. Sentinel-2 Imagery\\n\\nSentinel-2, a European Space Agency (ESA) land-monitoring mission, has two matching satellites\\nthat provide high-resolution optical imagery. Sentinel-2A and Sentinel-2B carry the MultiSpectral\\nInstrument (MSI) and were successfully launched in June 2015 and March 2017 respectively and\\nprovide important means to augment earth observation capabilities [37]. These satellites revisit the\\nsame location every 2 to 5 days. The MSI sensor oﬀers 13 spectral bands, with four bands at 10 m, six\\nbands at 20 m, and three bands at a 60 m spatial resolution (Table 1) and oﬀers a wide range of earth\\nobservation applications [38].\\n\\nIn this study, Sentinel-2 MSI images were downloaded from European Space Agency Sentinels\\nScientiﬁc Data Hub; the images were preprocessed with geometric and radiometric corrections at\\nsub-pixel accuracy. Then, atmospheric correction (converting top-of-atmosphere reﬂectance into\\ntop-of-canopy reﬂectance) was performed by the tool of SEN2COR (version 2.05.05), which was\\navailable in the Sentinel Application Platform (SNAP) toolbox [39,40]. In order to standardize diﬀerent\\nspatial resolutions of bands in MSI images, we excluded bands with a spatial resolution of 60 m (Band\\n1, Band 9, and Band 10). After atmospheric correction, all remaining bands were resampled to a pixel\\nsize of 20 m × 20 m.\\n\\nTable 1. General characteristics of the Sentinal-2 MultiSpectral Instrument (MSI) sensor.\\n\\nMSI Band\\n\\nBand Name\\n\\nWavelength\\n(Central, nm)\\n\\nSpectral Width\\n(nm)\\n\\nSpatial Resolution\\n(m)\\n\\nB1\\nB2\\nB3\\nB4\\nB5\\nB6\\nB7\\nB8\\nB8A\\nB9\\nB10\\n\\nB11\\n\\nB12\\n\\nAerosols\\nBlue\\nGreen\\nRed\\nVegetation red-edge\\nVegetation red-edge\\nVegetation red-edge\\nNear infrared\\nVegetation red-edge\\nWater-vapor\\nCirrus\\nShortwave-infrared\\nreﬂectance (SWIR)1\\nSWIR2\\n\\n443\\n490\\n560\\n665\\n705\\n740\\n783\\n842\\n865\\n945\\n1380\\n\\n1610\\n\\n2190\\n\\n20\\n65\\n35\\n30\\n15\\n15\\n20\\n115\\n20\\n20\\n30\\n\\n90\\n\\n180\\n\\n60\\n10\\n10\\n10\\n20\\n20\\n20\\n10\\n20\\n60\\n60\\n\\n20\\n\\n20\\n\\n2.2. Study Area\\n\\n(cid:48)\\n\\n(cid:48)\\n\\n◦\\n\\n◦\\n\\n00\\n\\n28\\n\\n–21\\n\\n(cid:48)\\n20\\n\\n◦\\n–108\\n\\n◦\\nN and 108\\n\\nThe study area, Zhenzhu Harbor (21\\n\\n(cid:48)\\nN), is located in Guangxi\\n42\\nProvince, China, in the southwest portion of mainland China and the north region of Tonkin Gulf\\n(Figure 1). In Zhenzhu Harbor, mangrove forests are mainly composed of four communities: Comm. A.\\nmarina, Comm. A. corniculatum, Comm. A. marina–A. corniculatum, and Comm. K. candel–A. corniculatum.\\nThe tides in the coast of Zhenzhu Harbor are diurnal, with an average tidal range of 2.24 m, and\\nmangrove forests here are primarily younger shrubs with an average height of less than 3 m [7].\\nTherefore, the Zhenzhu Harbor is a typical area for the study of submerged mangrove forests, due to a\\nlarge area of pioneer mangrove trees and shrubs that would be entirely submerged during high tides\\n(Figure 1A,B). Information of MSI images we selected are shown in Table 2.\\n\\n\\x0cRemote Sens. 2019, 11, 2043\\n\\n4 of 17\\n\\nAdditionally, a ﬁeld survey of Zhenzhu Harbor was conducted during April 2017, in which 408\\nground truth samples were collected including samples of mangrove forest, open water, and other\\nland cover.\\n\\nFigure 1. Snapshots of low- and high-tide Sentinel MSI images of study area ((A) during local low\\ntide all mangrove forests were emerged; (B) during local high tide some of the mangrove forests were\\nsubmerged).\\n\\nTable 2. Description of satellite data, including the path, row, date, time of acquisition, and tide level of\\n◦\\nthe nearest tide station (Fangcheng Harbor Station, 108\\n\\n◦\\nE, 21\\n\\n(cid:48)\\n14\\n\\nN).\\n\\n28\\n\\n(cid:48)\\n\\nSensor\\n\\nPath\\n\\nRow\\n\\nDate\\n\\nTime (hh:mm)\\n\\nMSI\\nMSI\\n\\n205\\n205\\n\\n118\\n118\\n\\n2017-12-17\\n2017-09-28\\n\\n11:23\\n16:37\\n\\nTide Height (m)\\n−0.9\\n1.8\\n\\n2.3. Build a Reference Map\\n\\nGround surveys were conducted along the coasts of Zhenzhu Harbor in November 2017. The\\nlocation of each sampling point was measured using a global positioning system (GPS), with an error\\nless than 1 m. The observations collected in the surveys contained 85 mangrove points and 81 water\\npoints. A vector ﬁle of ground survey points with the attributes of location (longitude and latitude),\\nland cover types, and photos was created with ArcGIS.\\n\\nThe spectral curves of water, submerged mangrove forests, and emerged mangrove forests were\\nextracted from images. The workﬂow of discriminating these classes is shown in Figure 2. A reference\\nmap was built based on object-oriented methods and visual interpretation.\\n\\nThe description of the object-oriented method can be found in Harayama and Jaquet [41]. The\\neCognition Developer 9.0, an image analysis program, was used to conduct object-oriented classiﬁcation.\\nVisual interpretation was performed to classify objects as either mangrove forests or water. To facilitate\\n\\n\\x0cRemote Sens. 2019, 11, 2043\\n\\n5 of 17\\n\\nvisual interpretation, a false color composite of MSI Bands 11 (centered 1610 nm), Band 8 (centered\\n842 nm), and Band 4 (centered 665 nm) was generated. This band combination that was deemed the\\nbest for detecting mangroves which appears dark green color [42]. Furthermore, in order to conduct the\\nadjustment in a robust manner, visual interpretation was performed by an experienced remote sensing\\nexpert who was familiar with this area. First, we identiﬁed mangrove forest and surrounding water\\nfrom the low-tide MSI image. Subsequently, a confusion matrix was generated using the independent\\nground-truth samples described in Section 2.2. With this matrix, we achieved an overall classiﬁcation\\naccuracy of 97% with a Kappa coeﬃcient of 0.92, which indicated excellent agreements between our\\nmapping results and ground-truth data. Therefore, mangrove forests identiﬁed with this method\\nwere assumed to cover entire area of local mangrove forests. Second, using the same techniques as\\nabove, mangrove forests were identiﬁed from the high-tide MSI image. Finally, the extent of the\\nsubmerged mangrove was determined by subtracting the high-tide from the low-tide mangrove forest\\nmap. Figure 3 shows the distributions of emerged mangrove forests and submerged mangrove forests\\nin the high-tidal MSI image.\\n\\nFigure 2. Work ﬂow for identifying submerge mangrove forests.\\n\\n\\x0cRemote Sens. 2019, 11, 2043\\n\\n6 of 17\\n\\nFigure 3. Distribution of emerged and submerged mangrove forests in high-tide MSI image.\\n\\n2.4. Theories\\n\\nFigure 4 shows the ﬁeld measurements of spectral curves of the water, emerged vegetation,\\n(2015;\\nand submerged vegetation, generated by Chen et al.\\nFigure 4B) [15,25]. As normal green plants, vegetation above the water surface showed high reﬂectance\\nin the spectral region of 770–890 nm. Waterbody is characterized by low reﬂectance in near infrared at\\n700 nm while emerged mangrove has a relatively high reﬂectance, which make them separable from\\neach other. However, when mangroves are submerged under water, the reﬂectance is largely reduced,\\ntherefore, it is diﬃcult to distinguish submerged vegetation from waterbody [15,25,43]. As measured,\\nwhen submerged vegetation are 43–51 cm below clear water, the NDVI value was close to zero, which\\nmeans no diﬀerences were observed between the red band and NIR band [44].\\n\\n(2018; Figure 4A) and Visser et al.\\n\\nHowever, by careful inspection of the spectral curves shown in Figure 4A,B, two reﬂectance\\npeaks ranging from approximately 690–740 nm and 810–830 nm were found, even for the curves of\\nvegetation located 40 cm below the water surface. These peaks result from the competing eﬀects\\nof the chlorophyll reﬂectance plateau and the absorption eﬀects of water located within submerged\\nvegetation and the surrounding water background. However, traditional multispectral satellite sensors\\ncould not capture these reﬂectance peaks. Fortunately, the MSI sensor has ﬁve channels that cover\\nthese regions. Figure 5 shows the typical spectral curves of water (WB), emerged mangrove forest\\n(EMF), and submerged mangrove forest (SMF) that are observed on the MSI image. As shown in\\nFigure 5, the emerged and shallow submerged mangrove forest pixels demonstrated a strong reﬂection\\nin the region of 660–900 nm, the absorption valleys appeared in bands 4 (centered wavelength 665 nm)\\nand 12 (centered 2160 nm). For the submerged mangrove forest (b) curves, a small reﬂectance peak\\nappeared in the 660–900 nm region; the absorption valley also appeared in bands 4 (centered 665 nm)\\nand 12 (centered 2160 nm). The reﬂectance of the water pixels shows a continuous decreasing tendency\\nbeginning with band 4 (central wavelength 665 nm). Therefore, comparing submerged curves to water\\ncurves, the higher reﬂectance in bands 5 (centered 705 nm), 6 (centered 740 nm), 7 (centered 783 nm),\\n8 (centered 842 nm), and 8A (centered 865 nm) could be used to distinguish submerged mangrove\\nforests from the water background.\\n\\n\\x0cRemote Sens. 2019, 11, 2043\\n\\n7 of 17\\n\\nFigure 4. The spectral curves of water, emerged, and submerged vegetation, as well as the absorption\\n−1). ((A) ﬁeld-measurement [15]; (B) ﬁeld-measured of submerged vegetation’s\\ncoeﬃcients of water (cm\\nreﬂectance at 1.5, 16, and 40 cm below water surface [25]).\\n\\nFigure 5. (A) Typical spectral curves of emerged (EMF), submerged mangrove forests (SMF) and water\\n(WB) in Sentinel-2A MSI image. (B) EMF and SMF forests in Sentinel MSI image and ﬁeld photo. (a)\\nRepresents shallow submerged mangrove forests (0–30 cm), (b) Represents deep submerged mangrove\\nforests (30–60 cm).\\n\\n2.5. Existing Vegetation Indices\\n\\nPreviously, NDVI (Equation 1), LSWI (Equation 2), and MNDWI (Equation 3) and FAI (Equation\\n\\n4) were used in detecting vegetation from water bodies [33,34,45].\\n\\nNDVI =\\n\\nLSWI =\\n\\nRed\\n\\nRed\\n\\nSWIR\\n\\n− ρ\\nρ\\nNIR\\nNIR + ρ\\nρ\\nρ\\n− ρ\\nNIR\\nNIR + ρ\\nρ\\nSWIR\\nρ\\n− ρ\\nGreen\\nρ\\nGreen + ρ\\n1240) × (1240 − 860)/(1240 − 660)](cid:9)\\n\\nSWIR\\n\\nSWIR\\n\\n(1)\\n\\n(2)\\n\\n(3)\\n\\n(4)\\n\\nMNDWI =\\n\\n− [ρ\\n\\n1240 + (ρ\\n\\n660−ρ\\n\\nFAI = (cid:8)ρ\\n\\n860\\nNIR, and ρ\\n\\nRed, ρ\\n\\nGreen, ρ\\n\\nwhere ρ\\nSWIR are the reﬂectance of the green, red, NIR, and SWIR, respectively.\\nHowever, these indices are not suitable for discerning submerged vegetation from water bodies,\\nbecause there are no obvious reﬂectance diﬀerences in bands green, red, and SWIR between submerged\\nvegetation and water bodies (Figures 4 and 5).\\n\\n\\x0cRemote Sens. 2019, 11, 2043\\n\\n2.6. Formulation of MFI\\n\\n8 of 17\\n\\nFor this study, according to the analysis in Section 2.4, the absorption valleys in band 4 (centered\\n665 nm) and band 12 (centered 2190 nm) could be used to form a baseline (Figure 6). In order to\\nenhance the stability of diﬀerences between submerged mangrove forests and the water background,\\nthe average value of reﬂectance of band 5 (centered 705 nm), band 6 (centered 740 nm), band 7 (centered\\n783 nm), and band 8A (centered 865 nm) above the baseline, is deﬁned as MFI. Band 8 was excluded\\nbecause Bands 7 (centered 783 nm) and 8A (centered 865 nm) covered most of its spectra, and its\\nspectral range overlaps with the water absorption region. The mathematical formulation is\\n\\nMFI =\\n\\n(ρλ1\\n\\n− ρ\\n\\nBλ1)+ (ρλ2\\n\\n− ρ\\n\\nBλ2)+(ρλ3\\n\\n− ρ\\n\\nBλ3)+(ρλ4\\n\\n− ρ\\n\\nBλ4\\n\\n]/4\\n\\n(cid:17)\\n\\n(cid:104)\\n\\nρ\\n\\nBλi = ρ\\n\\n2190 + (ρ\\n\\n665−ρ\\n\\n2190) × (2190 − λi)/(2190 − 665)\\n\\n(5)\\n\\n(6)\\n\\nwhere the ρλ is the reﬂectance of the band center of λ, and i ranged from 1 to 4; λ1, λ2, λ3, λ4 represent\\nthe center wavelengths at 705, 740, 783 and 865 nm, respectively. ρ\\nBλi is the baseline reﬂectance in\\nλi. ρ\\n2190 are the reﬂectance of band 4 (centered at 665 nm) and 12 (centered at 2190 nm),\\nrespectively. Pixels with an MFI value above 0 are recognized as mangrove forests.\\n\\n665 and ρ\\n\\nFigure 6. Baseline theory of establishing Mangrove Forest Index (MFI), including reﬂectance of\\nsubmerged mangrove forest and water.\\n\\n2.7. Quantitative Comparison between MFI and Other VIs\\n\\nIn this study, Jensen–Shannon divergence (JSD)—a measure of distance between a ﬁnite number\\nof distributions—was adopted to compare sensitivities of MFI and other VIs. The JSD (D) quantiﬁes\\nthe diﬀerence between two or more probability distributions. In this study, it was used to compare\\nthe diﬀerences between submerged mangrove forests and water pixels in diﬀerent VI images. The\\n(1)\\n)\\nD value, which was calculated in MATLAB, is deﬁned as follows:\\nk\\nand p(2) ≡\\n(cid:80)k\\n\\n(2)\\nk\\n≤ 1 for all i = 1,2, . . . ,k and j = 1,2; and let π(1) and π(2) denote the weights\\nof the distributions p(1) and p(2), satisfying the constraints π(1) + π(2) = 1 and 0 ≤ π( j) ≤ 1. Then the\\n\\ndenote two probability distributions satisfying the usual constraints\\n\\n(2)\\n1 , p\\np\\n= 1 and 0 ≤ p\\n\\n(2)\\n2 , . . . , p\\n( j)\\ni\\n\\nlet p(1) ≡ (p\\n\\n(1)\\n2 , . . . , p\\n\\n( j)\\ni=1 p\\ni\\n\\n(1)\\n1 , p\\n\\n(cid:19)\\n\\n(cid:18)\\n\\n\\x0cRemote Sens. 2019, 11, 2043\\n\\n9 of 17\\n\\n(7)\\n\\n(8)\\n\\nJensen–Shannon divergence D between the probability distributions p(1) and p(2) with weights π(1)\\nand π(2) is deﬁned by [46]:\\n\\n(cid:104)\\nD\\n\\np(1), p(2)(cid:105)\\n\\n≡ H\\n\\nπ(1)p(1) + π(2)p(2)(cid:105)\\n(cid:104)\\n\\n(cid:16)\\n\\n−\\n\\nπ(1)H\\n\\n(cid:104)\\n\\np(1)(cid:105)\\n\\n+ π(2)H\\n\\np(2)(cid:105)(cid:17)\\n(cid:104)\\n\\n(cid:88)k\\n\\nH[p] = −\\n\\npi log2 pi\\n\\ni=1\\n\\ndenotes the Shannon entropy of the probability distribution p ≡ (p1, p2, . . . pk). D ranging from 0–1, 0\\nmeans no diﬀerence between distributions, 1 means the distributions are completely diﬀerent.\\n\\nwhere\\n\\n3. Results\\n\\n3.1. Quantitative Comparison of MFI, FAI, NDVI, LSWI, and MNDWI\\n\\nTo compare the ability to distinguish submerged mangrove forests from the water background,\\nthe VIs values of all submerged mangrove forests (in total 12,001 pixels extracted in Section 2.3), and\\n22,668 pixels of water in the high-tidal MSI image (acquired on 28 September 2017) were calculated.\\nAdditionally, to make the diﬀerent VIs comparable, the MFI and FAI were calculated to 10 times of their\\noriginal values. The boxplots of submerged mangrove forests and water pixels are shown in Figure 7.\\n\\nFigure 7. Boxplot of diﬀerent index values over submerged mangrove forest pixels and water pixels\\n(MFI and Floating Algae Index (FAI) are 10 times their original value. SMF means submerged mangrove\\nforest, WB means Water Body. The horizontal axis represents diﬀerent indices).\\n\\nAs shown in Figure 7, all submerged mangrove forest pixels have higher MFI values than those of\\nthe water background, the minimum value of submerged mangrove forests is equal to the maximal\\nvalue of water. Most of the water pixels are confused with submerged mangrove forests in FAI, NDVI,\\nand NDWI image. According to our calculations, the D values of MFI, FAI, NDVI, LSWI, and MNDWI\\nare 0.209, 0.077, 0.012, 0.003, and 0.121, respectively, which means pixels of submerged mangrove\\nforests and water are better separated in an MFI image than other VIs.\\n\\n\\x0cRemote Sens. 2019, 11, 2043\\n\\n10 of 17\\n\\n3.2. Evaluation of MFI at Diﬀerent Mangrove Forests around the World\\n\\nGlobally, three selected mangrove forest sites were chosen to demonstrate the practical utility\\nof our newly formed index (MFI) in distinguishing mangrove forests from water background. They\\nare (a) Zhenzhu Harbor, Guangxi, China, (b) Dalhousie Island, Sundarbans, India, (c) Baia do Arraial,\\nAmazon Coast, Brazil. Locations are shown in Figure 8.\\n\\nFigure 8. Global study sites of mangrove forests. (Displayed imagery: R:G:B = Sentinel MSI Band 8A:\\n4:3. (a) Zhenzhu Harbor, Guangxi, China; (b) Dalhousie Island, Sundarbans, India; (c) Baia do Arraial,\\nAmazon Coast, Brazil).\\n\\nClassiﬁcation accuracy assessment is essential for validating the performance of the MFI index.\\nIn this study, a table containing the overall accuracy, user’s accuracy, producer’s accuracy, and the\\nKappa coeﬃcient of each site were presented in Table 3. In Zhenzhu Harbor, the validation samples\\nwere collected from ﬁeld survey. In Dalhousie Island and Baja do Arraial, validation samples were\\nrandomly selected from Google Earth high-resolution images.\\n\\n\\x0cRemote Sens. 2019, 11, 2043\\n\\n11 of 17\\n\\nTable 3. Confusion matrix for worldwide study sites of mangrove forests, including overall accuracy,\\nproducer’s accuracy, user’s accuracy, and Kappa coeﬃcient.\\n\\nZhenzhu Harbor\\nLand Cover\\n\\nMangrove\\nWater\\nUser’s accuracy\\nOverall accuracy\\nDalhousie Island\\nMangrove\\nWater\\nUser’s accuracy\\nOverall accuracy\\nBaja do Arraial\\nMangrove\\nWater\\nUser’s accuracy\\nOverall accuracy\\n\\nMangrove\\n\\n82\\n2\\n97.6%\\n97.0%\\nMangrove\\n52\\n2\\n96.2%\\n96.8%\\nMangrove\\n30\\n3\\n90.9%\\n91.7%\\n\\nClassiﬁcation Results\\n\\nWater\\n\\nProducer’s Accuracy\\n\\n3\\n79\\n96.3%\\nKappa coeﬃcient\\nWater\\n1\\n39\\n97.5%\\nKappa coeﬃcient\\nWater\\n3\\n36\\n92.3%\\nKappa coeﬃcient\\n\\n96.4%\\n97.5%\\n–\\n0.94\\nProducer’s accuracy\\n98.1%\\n95.1%\\n–\\n0.93\\nProducer’s accuracy\\n90.9%\\n92.3%\\n–\\n0.83\\n\\n3.2.1. Zhenzhu Harbor, Guangxi, China\\n\\nMFI was applied to the high-tidal Sentinel MSI image (acquired 2017-09-28). Figure 9 shows\\nthe MFI image (Figure 9A), mangrove forest distribution classiﬁed from MFI image (Figure 9B), and\\nreference map (Figure 9C) derived from low-tide Sentinel MSI images (described in Section 2.3).\\nAccording to the results shown in the reference map (Figure 9C), the total area of mangrove forests was\\n856.30 ha, with 107.05 ha of submerged and 749.25 ha of emerged mangrove forests. In Figure 9B, the\\ntotal area of mangrove forest we classiﬁed from the MFI image was 849.4 ha, which means 99% of the\\nmangrove forest pixels were successfully extracted from water background by the MFI. According to\\nTable 3, the overall accuracy of this mangrove map is 97% with a Kappa coeﬃcient of 0.94. In Zhenzhu\\nHarbor, the MFI value of emerged mangrove forests, submerged mangrove forests, and water pixels\\nrange from 0.19 to 0.30, −0.01 to 0.18, and −0.2 to −0.01.\\n\\nFigure 9. Apply the MFI to extract mangrove forests in Zhenzhu Harbor, Guangxi, China. (A) MFI\\nimage, (B) mangrove forests extracted from MFI image, and (C) reference map.\\n\\n3.2.2. Dalhousie Island, Sundarbans, India\\n\\nSundarbans has the biggest patch of mangrove forest ﬂourishing on the world’s largest delta\\n(Ganga–Bramhaputra–Meghna Delta; [47]). The tidal amplitude within the estuary ranges from 3.5\\nto 4 m, with seasonal variation between 1 and 6 m; mangrove forests are periodically submerged\\nduring high tide [48,49]. In this study, Dalhousie Island (located in the southern part of Sundarbans,\\nIndia) was chosen as a typical area to validate the performance of the MFI. Figure 10 shows a local\\nhigh-tidal MSI image (Figure 10A, captured on 2016-10-17), the MFI-derived image (Figure 10B), and\\n\\n\\x0cRemote Sens. 2019, 11, 2043\\n\\n12 of 17\\n\\nground-truth images obtained by Google Earth snapshot (Figure 10a–c). As shown in Figure 10A, in\\nmangrove swamps, a number of patches seem similar to seawater. In Figure 10a–c, although these\\npatches show white tones, they are lower and sparser mangrove forests that are intermittently ﬂooded\\nby tides. Fortunately, these patches have positive values in the MFI image (Figure 10B). According to\\nMondal and Saha (2018), Dalhousie Island had 5950 ha of mangrove forests on 2015-08-03 [50]. In the\\nMFI image, the extent of mangrove extracted by the MFI is 6105 ha (pixels with positive MFI values),\\naccounting for 102% of Mondal and Saha’s result. Although the MSI image was captured during high\\ntide, almost all the local mangrove forests were detected by the MFI. According to Table 3, the overall\\naccuracy of this mangrove map is 96.8%, with a Kappa coeﬃcient of 0.93. In Dalhousie Island, the MFI\\nvalue of emerged mangrove forests, submerged mangrove forests, and water pixels range from 0.11 to\\n0.25, 0 to 0.10, and –0.03 to 0.\\n\\nFigure 10. Apply the MFI to extract mangrove forests in Dalhousie Island, Sundarbans, India. (A)\\nSentinel MSI image (Band combination: R:G:B = 8A: 4: 3); (B) Sentinel MSI-based MFI image; (a–c):\\nGoogle Earth snapshot.\\n\\n3.2.3. Baia do Arraial, Amazon Coast, Brazil\\n\\nBaia do Arraial is located along the south coasts of São Luís city, Brazil (Figure 11). The coastal\\nzone of São Luís is dominated by a semidiurnal tide; the high energy causes a maximum tidal height\\nof 8 m during the equinoctial spring tide. Therefore, numerous mangrove trees and shrubs would\\nbe submerged during high tides. As shown in Figure 11A, on 2018-06-14, patches in the northwest\\nand the middle of mangrove swamps were submerged; fortunately, these mangrove forests showed\\npositive values in Figure 11B, and the snapshot of Google Earth images conﬁrmed that these places\\nwere occupied by low mangrove forests. Therefore, we concluded that submerged mangrove forests\\nin Baia do Arraial could be detected by the MFI. According to Table 3, the overall accuracy of this\\nmangrove map is 91.7%, with a Kappa coeﬃcient of 0.83. In Baia do Arraial, the MFI values of emerged\\nmangrove forests, submerged mangrove forests, and water pixels range from 0.09 to 0.25, 0 to 0.09, and\\n−0.06 to 0.\\n\\n\\x0cRemote Sens. 2019, 11, 2043\\n\\n13 of 17\\n\\nFigure 11. Apply the MFI to extract mangrove forests in Baia do Arraial, Amazon Coast, Brazil. (A)\\nSentinel MSI image (band combination: R:G:B = 8A: 4: 3), (B) Sentinel MSI based MFI image, (a,b):\\nGoogle Earth snapshot.\\n\\n4. Discussion\\n\\n4.1. Advantages and Potential Applications of MFI\\n\\nLocated along intertidal zones, mangrove forests are always relatively small patches; therefore,\\nmisclassiﬁcation of a small area would greatly aﬀect mapping results. The lack of full consideration\\nof tidal conditions would cause misclassiﬁcation between mangrove forests and water background.\\nTo accurately map and manage mangrove forests, in this study, we attempt to extract all mangrove\\nforests during local high tides. Undeniably, using VIs to extract mangrove forests is not new. All the\\ncommonly used indices are applicable to detecting emerged mangrove forests. However, during high\\ntides, according to our statistics in Figure 7, in LSWI, MNDWI, NDVI, and FAI images 27%, 8%, 19%,\\nand 5% of submerged pixels were mixed with water background. Furthermore, based on the result of\\nJensen–Shannon divergence, MFI greatly increased the distance of submerged mangrove forests and\\nwater. However, in the MFI image, nearly all the submerged pixels were completely separated from\\nthe water background. Furthermore, all traditional vegetation indices have a vital uncertainty, that\\nallow for the determination of the threshold of VIs. Fortunately, based on the theory of being above\\nthe baseline, one advantage of using the MFI in detecting mangrove forests is that the threshold is at\\nthe ﬁxed value of zero.\\n\\nThis study provides an index built by Sentinel-2 MSI bands for discriminating submerged\\nmangrove forests from water background. It supports the ﬁndings of previous studies that the NIR\\nand red-edge provide great opportunities in discriminating between vegetation and water. Sentinel-2\\nMSI image contains ﬁve bands in NIR region, four of which were used to build the MFI. The FAI was\\nalso established based on baseline theory, but with one NIR band. However, according to Figure 7\\nand our statistics, unlike MFI (completely separated submerged mangrove forest and water), in the\\nFAI image, 5% of submerged mangrove forests pixels were mixed with water pixels. This is primarily\\nbecause unexpected ﬂuctuation in one NIR band could greatly aﬀect the value of the FAI. The four MSI\\nred-edge bands demonstrated relatively stable discrimination between submerged mangrove forest\\nand water.\\n\\nTheoretically, the MFI concept can be applied to other sensors that contain spectral channels of red,\\nNIR, and SWIR, for example, the Landsat OLI sensor which has a red band ranging from 630 to 690 nm,\\nan NIR band ranging from 840 to 890 nm, and a SWIR band ranging from 2100 to 2300 nm. However,\\ndiﬀerent sensors may acquire diﬀerent MFI values due to the diﬀerent ranges of red, NIR, and SWIR\\nbands. Furthermore, the performance of the Sentinel-2 MSI red-edge bands will also be present on\\nthe Sentinel-3 Ocean and Land Color Instrument (OLCI) sensor [51]. Therefore, the adaptability of\\nthe MFI to other remote sensing sensors still requires further examination. Moreover, the MFI was\\ndesigned based on the reﬂectance peak in the NIR spectral regions of green vegetation. Therefore,\\n\\n\\x0cRemote Sens. 2019, 11, 2043\\n\\n14 of 17\\n\\nthe MFI has great potential in detecting any submerged or emerged vegetation in aquatic environments,\\nsuch as ﬂoating algae and aquatic macrophytes. However, considering the various environments\\nwhere aquatic vegetation grows, the applicability of the MFI in detecting other aquatic vegetation still\\nwarrants further exploration.\\n\\n4.2. Uncertainties Leading to Overestimation of Mangrove Forests Using the MFI\\n\\nThis study demonstrates that there are abundant diﬀerences in the spectral reﬂectance between\\nsubmerged mangrove forests and water bodies. In addition, the spectral curves of submerged and\\nemerged mangrove forests showed similar concave–convex characteristics (Figure 5). Therefore, the\\nMFI function can eﬃciently identify and detect mangrove forests from water background. However,\\nthe MFI was designed based on the reﬂectance peak between red and SWIR; any other vegetation that\\ncontains absorption signatures of chlorophyll in aquatic environment can also be detected [17,36,52].\\nHence, pixels containing ﬂoating vegetation (for example, algae) and other aquatic macrophytes (for\\nexample, Spartina alterniﬂora) may be classiﬁed as mangrove forest. Additionally, due to limits in image\\nresolution, a small area of the water could still be classiﬁed as mangrove forests, due to having similar\\nspectral characteristics as nearby mangrove forests. These uncertainties can lead to overestimation of\\nmangrove forests by the MFI. In our application in Dalhousie Island, Sundarbans, India, the bias of\\narea of mangrove forests obtained by MFI is 2% larger.\\n\\n4.3. Limitations Leading to Underestimation of Mangrove Forests Using the MFI\\n\\nIn this study, MFI was created based on the typical reﬂectance curves of submerged mangrove\\nforests. However, the spectral curve of submerged mangrove forest can be aﬀected by several factors,\\nincluding water transparency (turbidity), distance that mangrove canopy under the water surface, and\\nthe coverage of mangrove forest [15]. Liew and Chang proved that the spectral curves of submerged\\nvegetation changes when water turbidity and depth change [53]. They demonstrated that with high\\nturbidity (50 nephelometric turbidity units), green vegetation could not be distinguished at a water\\ndepth of 0.5 m. In addition, with low turbidity (0.5 nephelometric turbidity units), typical vegetation\\nreﬂectance was undetectable at a water depth of 1 m. Chen et al. discovered that when submerged\\nvegetation coverage was less than 40%, it is diﬃcult to detect vegetation based on the NIR peak in\\nthe spectral reﬂectance curve [15]. Unfortunately, water ﬂow in mangrove swamps always has high\\nturbidity, and newly grown trees at the edge of mangrove forests always have low coverage. According\\nto our ﬁeld measurement, in Zhenzhu Harbor, submerged mangrove forests with a depth of 60 cm\\nunder the water surface would not be detected by MFI. Moreover, due to limits of image resolution,\\nsmall parts of the mangrove forests may be classiﬁed as water due to low tree coverage. As shown in\\nFigure 12, in Zhenzhu Harbor, low mangrove forests along tidal creeks were not identiﬁed by MFI.\\nThese limitations lead to underestimation of the areal extent of mangrove forests by the MFI.\\n\\nFigure 12. Intermittently ﬂooded mangrove forests in local low tide period.\\n\\n5. Conclusions\\n\\nBased on the spectral response curves of submerged mangrove forests, a new vegetation index\\n(MFI) was developed to distinguish mangrove forests from the water background. To take full\\n\\n\\x0cRemote Sens. 2019, 11, 2043\\n\\n15 of 17\\n\\nadvantage of the diﬀerences in reﬂectance between submerged mangrove forests and the water\\nbackground, Sentinel-2 MSI bands, red and SWIR2 were selected to build a linear baseline, and the\\naverage reﬂectance value of four red-edge bands above the baseline was deﬁned as mangrove forest\\nindex (MFI). This new vegetation index is more advantageous in detecting submerged mangrove\\nforests than the traditional NDVI, LSWI, MNDWI, and FAI indices. According to the results of\\nJensen–Shannon divergence, MFI signiﬁcantly widens the distance of submerged mangrove forest and\\nwater pixels compared to other VIs (the Jensen-Shannon divergence values of MFI, FAI, NDVI, LSWI,\\nand MNDWI are 0.209, 0.077, 0.012, 0.003, and 0.121, respectively). Theoretically, 100% of submerged\\nmangrove forests could be extracted from MFI images. Practically, application of the MFI in three\\nglobal mangrove sites showed 99% to 102% of submerged mangrove forests were successfully extracted\\nfrom the MFI image. The overall accuracy of classiﬁcation results obtained from the MFI image ranged\\nfrom 91.7% to 97.6%. According to our ﬁeld measurements in Zhenzhu Harbor, MFI is insensitive to\\nmangrove forests with canopies under 60 cm of the water surface. There are some uncertainties and\\nlimitations, but the MFI was proven to be eﬀective in detecting the extent and condition of mangrove\\nforests from high-tide Sentinel MSI images. Although the repeatability and portability of the MFI is\\nstill a work in progress, this index brings great beneﬁts to remote sensing communities of coastal and\\naquatic vegetation studies.\\n\\nAuthor Contributions: M.J. and Z.W. designed the research, process the data, and wrote the manuscript draft.\\nY.Z. helped with designed research and reviewed the manuscript. C.W. helped with image analysis, ﬁeldwork,\\nand reviewed the manuscript. D.M. helped with image analysis and reviewed the manuscript.\\n\\nFunding: The work is supported by Science and Technology Basic Resources Investigation Program of China (No.\\n2017FY100706), the National Natural Science Foundation of China (No. 41601470, No. 41601406), the Strategic\\nPlanning Project of the Institute of Northeast Geography and Agroecology (IGA), Chinese Academy of Sciences\\n(No. Y6H2091000), and the Youth Innovation Promotion Association of Chinese Academy of Sciences (2017277,\\n2012178). This work is supported by Open Fund of State Laboratory of Information Engineering in Surveying,\\nMapping and Remote Sensing, Wuhan University (Grant No. 19I02).\\n\\nAcknowledgments: The authors are grateful to the colleagues who participated in the ﬁeld surveys and\\ndata collection.\\n\\nConﬂicts of Interest: The authors declare no conﬂict of interest.\\n\\nReferences\\n\\n1.\\n\\n2.\\n\\n3.\\n\\n4.\\n\\nCollins, D.S.; Avdis, A.; Allison, P.A.; Johnson, H.D.; Hill, J.; Piggott, M.D.; Hassan, M.H.A.; Damit, A.R.\\nTidal dynamics and mangrove carbon sequestration during the Oligo-Miocene in the South China Sea.\\nNat. Commun. 2017, 8, 15698. [CrossRef] [PubMed]\\nRichards, D.R.; Friess, D.A. Rates and drivers of mangrove deforestation in Southeast Asia, 2000–2012.\\nProc. Natl. Acad. Sci. USA 2016, 113, 344–349. [CrossRef] [PubMed]\\nFriess, D.A.; Webb, E.L. Variability in mangrove change estimates and implications for the assessment of\\necosystem service provision. Glob. Ecol. Biogeogr. 2014, 23, 715–725. [CrossRef]\\nKuenzer, C.; Bluemel, A.; Gebhardt, S.; Quoc, T.V.; Dech, S. Remote sensing of mangrove ecosystems:\\nA review. Remote Sens. 2011, 3, 878–928. [CrossRef]\\n\\n6.\\n\\n5. Hamilton, S.E.; Casey, D. Creation of a high spatio-temporal resolution global database of continuous\\nmangrove forest cover for the 21st century (CGMFC-21). Glob. Ecol. Biogeogr. 2016, 25, 729–738. [CrossRef]\\nGiri, C.; Pengra, B.; Zhu, Z.; Singh, A.; Tieszen, L.L. Monitoring mangrove forest dynamics of the Sundarbans\\nin Bangladesh and India using multi-temporal satellite data from 1973 to 2000. Estuar. Coast. Shelf Sci. 2007,\\n73, 91–100. [CrossRef]\\nLi, M.; Lee, S. Mangroves of China: A brief review. For. Ecol. Manag. 1997, 96, 241–259. [CrossRef]\\nSpalding, M.D.; Blasco, F.; Field, C.D. World Mangrove Atlas; Routledge: London, UK, 1997.\\nCardenas, N.Y.; Joyce, K.E.; Maier, S.W. Monitoring mangrove forests: Are we taking full advantage of\\ntechnology? Int. J. Appl. Earth Obs. Geoinf. 2017, 63, 1–14. [CrossRef]\\n\\n7.\\n8.\\n9.\\n\\n10. Rogers, K.; Lymburner, L.; Salum, R.; Brooke, B.P.; Woodroﬀe, C.D. Mapping of mangrove extent and\\nzonation using high and low tide composites of Landsat data. Hydrobiologia 2017, 803, 49–68. [CrossRef]\\n\\n\\x0cRemote Sens. 2019, 11, 2043\\n\\n16 of 17\\n\\n11.\\n\\n12.\\n\\nJia, M.; Wang, Z.; Zhang, Y.; Mao, D.; Wang, C. Monitoring loss and recovery of mangrove forests during\\n42 years: The achievements of mangrove conservation in China. Int. J. Appl. Earth Obs. Geoinf. 2018, 73,\\n535–545. [CrossRef]\\nJia, M.; Wang, Z.; Zhang, Y.; Ren, C.; Song, K. Landsat-based estimation of mangrove forest loss and\\nrestoration in Guangxi province, China, inﬂuenced by human and natural factors. IEEE J. Sel. Top. Appl.\\nEarth Obs. Remote Sens. 2015, 8, 311–323. [CrossRef]\\n\\n13. Xia, Q.; Qin, C.-Z.; Li, H.; Huang, C.; Su, F.-Z. Mapping mangrove forests based on multi-tidal high-resolution\\n\\nsatellite imagery. Remote Sens. 2018, 10, 1343. [CrossRef]\\n\\n14. Zhang, X.; Treitz, P.M.; Chen, D.; Quan, C.; Shi, L.; Li, X. Mapping mangrove forests using multi-tidal\\nremotely-sensed data and a decision-tree-based procedure. Int. J. Appl. Earth Obs. Geoinf. 2017, 62, 201–214.\\n[CrossRef]\\n\\n15. Chen, Q.; Yu, R.; Hao, Y.; Wu, L.; Zhang, W.; Zhang, Q.; Bu, X. A New Method for Mapping Aquatic\\nVegetation Especially Underwater Vegetation in Lake Ulansuhai Using GF-1 Satellite Data. Remote Sens.\\n2018, 10, 1279. [CrossRef]\\nSilva, T.S.; Costa, M.P.; Melack, J.M.; Novo, E.M. Remote sensing of aquatic vegetation: Theory and\\napplications. Environ. Monit. Assess. 2008, 140, 131–145. [CrossRef] [PubMed]\\n\\n16.\\n\\n17. Gao, B.-C.; Li, R.-R. FVI—A Floating Vegetation Index Formed with Three Near-IR Channels in the 1.0–1.24\\nµm Spectral Range for the Detection of Vegetation Floating over Water Surfaces. Remote Sens. 2018, 10, 1421.\\n[CrossRef]\\nSibanda, M.; Mutanga, O.; Dube, T.; S Vundla, T.; L Mafongoya, P. Estimating LAI and mapping canopy\\nstorage capacity for hydrological applications in wattle infested ecosystems using Sentinel-2 MSI derived\\nred edge bands. GISci. Remote Sens. 2019, 56, 68–86. [CrossRef]\\n\\n18.\\n\\n19. Williams, D.J.; Rybicki, N.B.; Lombana, A.V.; O’Brien, T.M.; Gomez, R.B. Preliminary investigation of\\nsubmerged aquatic vegetation mapping using hyperspectral remote sensing. In Coastal Monitoring through\\nPartnerships; Springer: Berlin, Germany, 2003; pp. 383–392.\\n\\n20. Luo, J.; Li, X.; Ma, R.; Li, F.; Duan, H.; Hu, W.; Qin, B.; Huang, W. Applying remote sensing techniques to\\nmonitoring seasonal and interannual changes of aquatic vegetation in Taihu Lake, China. Ecol. Indic. 2016,\\n60, 503–513. [CrossRef]\\n\\n21. Ma, R.; Duan, H.; Liu, Q.; Loiselle, S.A. Approximate bottom contribution to remote sensing reﬂectance in\\n\\nTaihu Lake, China. J. Great Lakes Res. 2011, 37, 18–25. [CrossRef]\\n\\n22. Pu, R.; Bell, S.; Meyer, C.; Baggett, L.; Zhao, Y. Mapping and assessing seagrass along the western coast of\\nFlorida using Landsat TM and EO-1 ALI/Hyperion imagery. Estuar. Coast. Shelf Sci. 2012, 115, 234–245.\\n[CrossRef]\\n\\n23. Purnamasayangsukasih, P.R.; Norizah, K.; Ismail, A.A.; Shamsudin, I. A review of uses of satellite imagery\\nin monitoring mangrove forests. In Proceedings of the IOP Conference Series: Earth and Environmental\\nScience, Prague, Czech Republic, 12–19 July 2016; p. 012034.\\n\\n24. Zhao, D.; Jiang, H.; Yang, T.; Cai, Y.; Xu, D.; An, S. Remote sensing of aquatic vegetation distribution in Taihu\\nLake using an improved classiﬁcation tree with modiﬁed thresholds. J. Environ. Manag. 2012, 95, 98–107.\\n[CrossRef] [PubMed]\\n\\n25. Visser, F.; Buis, K.; Verschoren, V.; Meire, P. Depth estimation of submerged aquatic vegetation in clear water\\nstreams using low-altitude optical remote sensing. Sensors 2015, 15, 25287–25312. [CrossRef] [PubMed]\\n26. Heumann, B.W. An object-based classiﬁcation of mangroves using a hybrid decision tree—Support vector\\n\\nmachine approach. Remote Sens. 2011, 3, 2440–2460. [CrossRef]\\n\\n27. Heumann, B.W. Satellite remote sensing of mangrove forests: Recent advances and future opportunities.\\n\\nProg. Phys. Geogr. 2011, 35, 87–108. [CrossRef]\\n\\n28. Wang, T.; Zhang, H.; Lin, H.; Fang, C. Textural–spectral feature-based species classiﬁcation of mangroves in\\n\\nMai Po Nature Reserve from Worldview-3 imagery. Remote Sens. 2016, 8, 24. [CrossRef]\\n\\n29. Wan, L.; Zhang, H.; Wang, T.; Li, G.; Lin, H. Mangrove species discrimination from very high resolution\\n\\nimagery using gaussian markov random ﬁeld model. Wetlands 2018, 38, 861–874. [CrossRef]\\n\\n30. Huete, A.; Justice, C.; Van Leeuwen, W. MODIS vegetation index (MOD 13) algorithm theoretical basis\\n\\ndocument (ATBD) Version 3.0. EOS Proj. Oﬀ. 1999, 2–3.\\n\\n\\x0cRemote Sens. 2019, 11, 2043\\n\\n17 of 17\\n\\n31. Matsushita, B.; Yang, W.; Chen, J.; Onda, Y.; Qiu, G. Sensitivity of the enhanced vegetation index (EVI) and\\nnormalized diﬀerence vegetation index (NDVI) to topographic eﬀects: A case study in high-density cypress\\nforest. Sensors 2007, 7, 2636–2651. [CrossRef] [PubMed]\\n\\n32. Gao, B.-C. NDWI—A normalized diﬀerence water index for remote sensing of vegetation liquid water from\\n\\nspace. Remote Sens. Environ. 1996, 58, 257–266. [CrossRef]\\n\\n33. Xiao, X.; Boles, S.; Liu, J.; Zhuang, D.; Frolking, S.; Li, C.; Salas, W.; Moore, B., III. Mapping paddy rice\\nagriculture in southern China using multi-temporal MODIS images. Remote Sens. Environ. 2005, 95, 480–492.\\n[CrossRef]\\n\\n34. Xu, H. Modiﬁcation of normalised diﬀerence water index (NDWI) to enhance open water features in remotely\\n\\nsensed imagery. Int. J. Remote Sens. 2006, 27, 3025–3033. [CrossRef]\\n\\n35. Gower, J.; Hu, C.; Borstad, G.; King, S. Ocean color satellites show extensive lines of ﬂoating Sargassum in\\n\\nthe Gulf of Mexico. IEEE Trans. Geosci. Remote Sens. 2006, 44, 3619–3625. [CrossRef]\\n\\n36. Hu, C. A novel ocean color index to detect ﬂoating algae in the global oceans. Remote Sens. Environ. 2009,\\n\\n113, 2118–2129. [CrossRef]\\n\\n37. Li, S.; Ganguly, S.; Dungan, J.L.; Wang, W.; Nemani, R.R. Sentinel-2 MSI radiometric characterization and\\n\\ncross-calibration with Landsat-8 OLI. Adv. Remote Sens 2017, 6, 147. [CrossRef]\\n\\n38. Wang, Q.; Blackburn, G.A.; Onojeghuo, A.O.; Dash, J.; Zhou, L.; Zhang, Y.; Atkinson, P.M. Fusion of Landsat\\n\\n8 OLI and Sentinel-2 MSI data. IEEE Trans. Geosci. Remote Sens. 2017, 55, 3885–3899. [CrossRef]\\n\\n39. Clevers, J.G.; Kooistra, L.; van den Brande, M.M. Using Sentinel-2 data for retrieving LAI and leaf and\\n\\ncanopy chlorophyll content of a potato crop. Remote Sens. 2017, 9, 405. [CrossRef]\\n\\n40. Quintano, C.; Fernández-Manso, A.; Fernández-Manso, O. Combination of Landsat and Sentinel-2 MSI data\\n\\nfor initial assessing of burn severity. Int. J. Appl. Earth Obs. Geoinf. 2018, 64, 221–225. [CrossRef]\\n\\n41. Harayama, A.; Jaquet, J.-M. Multi-Source Object-Oriented Classiﬁcation of Landcover Using Very High Resolution\\n\\nImagery and Digital Elevation Model; UNEP: Geneva, Switzerland, 2004.\\nSpalding, M. World Atlas of Mangroves; Routledge: London, UK, 2010.\\n\\n42.\\n43. Han, L.; Rundquist, D. The spectral responses of Ceratophyllum demersum at varying depths in an\\n\\nexperimental tank. Int. J. Remote Sens. 2003, 24, 859–864. [CrossRef]\\n\\n44. Cho, H.J.; Kirui, P.; Natarajan, H. Test of multi-spectral vegetation index for ﬂoating and canopy-forming\\n\\nsubmerged vegetation. Int. J. Environ. Res. Public Health 2008, 5, 477–483. [CrossRef]\\n\\n45. Tucker, C.J. Red and photographic infrared linear combinations for monitoring vegetation. Remote Sens.\\n\\nEnviron. 1979, 8, 127–150. [CrossRef]\\n\\n46. Lin, J. Divergence measures based on the Shannon entropy. IEEE Trans. Inf. Theory 1991, 37, 145–151. [CrossRef]\\n47. Manna, S.; Raychaudhuri, B. Mapping distribution of Sundarban mangroves using Sentinel-2 data and new\\n\\nspectral metric for detecting their health condition. Geocarto Int. 2018, 1–30. [CrossRef]\\n\\n48. Ghosh, A.; Schmidt, S.; Fickert, T.; Nüsser, M. The Indian Sundarban mangrove forests: History, utilization,\\n\\n49.\\n\\nconservation strategies and local perception. Diversity 2015, 7, 149–169. [CrossRef]\\nIslam, M.T. Vegetation changes of Sundarbans based on Landsat Imagery analysis between 1975 and 2006.\\nActa Geogr. Debrecina Landsc. Environ. Ser. 2014, 8, 1–9.\\n\\n50. Mondal, B.; Saha, A.K. Spatio-Temporal Analysis of Mangrove Loss in Vulnerable Islands of Sundarban World\\nHeritage Site, India. In Proceedings of the Annual International Conference on Geographic Information\\nScience, Lund, Sweden, 12–15 June 2018; Springer: Cham, Switzerland, 2018; pp. 93–109.\\n\\n51. Clevers, J.G.; Gitelson, A.A. Remote estimation of crop and grass chlorophyll and nitrogen content using\\n\\nred-edge bands on Sentinel-2 and-3. Int. J. Appl. Earth Obs. Geoinf. 2013, 23, 344–351. [CrossRef]\\n\\n52. Cho, H.J.; Lu, D. A water-depth correction algorithm for submerged vegetation spectra. Remote Sens. Lett.\\n\\n2010, 1, 29–35. [CrossRef]\\n\\n53. Liew, S.C.; Chang, C.W. Detecting submerged aquatic vegetation with 8-band WorldView-2 satellite images.\\nIn Proceedings of the 2012 IEEE International Geoscience and Remote Sensing Symposium (IGARSS), Munich,\\nGermany, 22–27 July 2012; pp. 2560–2562.\\n\\n© 2019 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access\\narticle distributed under the terms and conditions of the Creative Commons Attribution\\n(CC BY) license (http://creativecommons.org/licenses/by/4.0/).\\n\\n\\x0c'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gen1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8wt00w2j01y",
        "outputId": "4c09bb51-3ce5-4b37-9b1f-a71776dec781"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_dir='/content/gen1'"
      ],
      "metadata": {
        "id": "dOqHpWurlAiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_dir='/content/gen2'"
      ],
      "metadata": {
        "id": "iRW_mFpwKA9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kF-fk1wamWhU",
        "outputId": "75bd1e55-72fd-4e34-dd5e-6adbfdc1dde9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import PyPDF2"
      ],
      "metadata": {
        "id": "Rs2tyVCKmgxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for filename in os.listdir(pdf_dir):\n",
        "    if filename.endswith('.pdf'):\n",
        "      pdf_file = open(os.path.join(pdf_dir, filename), 'rb')"
      ],
      "metadata": {
        "id": "KYljZHfltpHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "text = ''\n",
        "\n",
        "for i in range(len(pdf_reader.pages)):\n",
        "    page = pdf_reader.pages[i]\n",
        "    text += page.extract_text()"
      ],
      "metadata": {
        "id": "qFpABURPt8T7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "AAdU3igBJyPS",
        "outputId": "0b6e69fb-401c-4a05-904e-c4b04547a7e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'remote sensing  \\nArticle\\nA New Vegetation Index to Detect Periodically\\nSubmerged Mangrove Forest Using Single-Tide\\nSentinel-2 Imagery\\nMingming Jia1,2\\n, Zongming Wang1,*, Chao Wang2\\n, Dehua Mao1\\nand Yuanzhi Zhang3,4\\n1Key Laboratory of Wetland Ecology and Environment, Northeast Institute of Geography and Agroecology,\\nChinese Academy of Sciences, No. 4888, Shengbei Street, Changchun 130102, China\\n2State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan\\nUniversity, No.129 Luoyu Road, Wuhan 430079, China\\n3Center for Housing Innovations, Chinese University of Hong Kong, Shatin, New Territories, Hong Kong\\n4Key Lab of Lunar Science and Deep-exploration, National Astronomical Observatories, Chinese Academy of\\nSciences, Beijing 100101, China\\n*Correspondence: zongmingwang@iga.ac.cn\\nReceived: 4 July 2019; Accepted: 27 August 2019; Published: 29 August 2019\\n/gid00030/gid00035/gid00032/gid00030/gid00038/gid00001/gid00033/gid00042/gid00045 /gid00001\\n/gid00048/gid00043/gid00031/gid00028/gid00047/gid00032/gid00046\\nAbstract: Mangrove forests are tropical trees and shrubs that grow in sheltered intertidal zones.\\nAccurate mapping of mangrove forests is a great challenge for remote sensing because mangroves are\\nperiodically submerged by tidal ﬂoods. Traditionally, multi-tides images were needed to remove the\\ninﬂuence of water; however, such images are often unavailable due to rainy climates and uncertain\\nlocal tidal conditions. Therefore, extracting mangrove forests from a single-tide imagery is of great\\nimportance. In this study, reﬂectance of red-edge bands in Sentinel-2 imagery were utilized to\\nestablish a new vegetation index that is sensitive to submerged mangrove forests. Speciﬁcally, red\\nand short-wave near infrared bands were used to build a linear baseline; the average reﬂectance\\nvalue of four red-edge bands above the baseline is deﬁned as the Mangrove Forest Index (MFI).\\nTo evaluate MFI, capabilities of detecting mangrove forests were quantitatively assessed between\\nMFI and four widely used vegetation indices (VIs). Additionally, the practical roles of MFI were\\nvalidated by applying it to three mangrove forest sites globally. Results showed that: (1) theoretically,\\nJensen–Shannon divergence demonstrated that a submerged mangrove forest and water pixels have\\nthe largest distance in MFI compared to other VIs. In addition, the boxplot showed that all submerged\\nmangrove forests could be separated from the water background in the MFI image. Furthermore, in\\nthe MFI image, to separate mangrove forests and water, the threshold is a constant that is equal to\\nzero. (2) Practically, after applying the MFI to three global sites, 99–102% of submerged mangrove\\nforests were successfully extracted by MFI. Although there are still some uncertainties and limitations,\\nthe MFI o \\x0bers great beneﬁts in accurately mapping mangrove forests as well as other coastal and\\naquatic vegetation worldwide.\\nKeywords: Sentinel-2 MultiSpectral Instrument (MSI); red-edge band; aquatic vegetation; tidal\\ncondition; vegetation index; coastal vegetation\\n1. Introduction\\nMangrove forest are highly productive ecosystems with signiﬁcant ecological and socio- economic\\nimportance in the world [ 1,2]. However, over the past century, these forests have declined at an\\nalarming rate that is more rapid than that of inland tropical forests [ 3]. Therefore, there is an emerging\\ndemand for conservation and restoration e \\x0borts in mangrove forests. Obtaining accurate information\\nRemote Sens. 2019 ,11, 2043; doi:10.3390 /rs11172043 www.mdpi.com /journal /remotesensingRemote Sens. 2019 ,11, 2043 2 of 17\\nregarding the current and past acreage and condition of mangrove forests is essential for e \\x0ecient\\nmanagement of these ecosystems and for policy- and decision-making processes [4,5].\\nLocated in intertidal zones, mangrove forests are often inaccessible for traditional ﬁeld surveys.\\nFor decades, remote sensing has been widely used to monitor the distribution of mangrove forests, yet\\naccurate and timely interpretation of the relatively small patches has been rare, due to the lack of full\\nconsideration of tidal conditions [ 6–9]. Mangrove forests located near the shoreline are periodically\\nsubmerged by tides, especially in regions with high tide ﬂuctuations and lower mangrove shrubs [ 9,10].\\nIdeally, it is better to use images acquired during low tides; however, such data are di \\x0ecult to obtain,\\ndue to uncertainties of local instantaneous tidal conditions during predetermined times that satellites\\npass over [ 11,12]. For a long time, numerous studies have pointed out that tides may seriously\\ninﬂuence remote sensing results of mangrove forests, yet, solutions were not reported until the past\\ntwo years [ 10,13,14]. However, all these studies used multi-tides (multi-date) images; therefore, we\\nhave one concern: if multi-tides images are not available due to rainy climates and uncertain local tide\\nconditions, how could we accurately map mangrove forests by a single-date image?\\nOver the last two decades, remote sensing of submerged and emerged aquatic vegetation has\\nbeen widely studied [ 15,16]. Hyperspectral image with numerous narrow and contiguous bands is\\nreliable for studying aquatic vegetation and is able to detect the biophysical properties of vegetation\\ne\\x0eciently [ 16–19]. However, there is no freely available satellite hyperspectral data in recent years, and\\nairborne applications are exorbitantly expensive and only cover a very small spatial extent. Landsat\\nimages with moderate spatial resolution of 30–60 m have been widely used for mapping aquatic\\nvegetation [ 20–24]. Yet, Landsat only has one band in the spectral region of near infrared (760–900 nm),\\nwhich may become less sensitive as water depth increases [ 25]. The MODIS (Moderate Resolution\\nImaging Spectroradiometer) and AVHRR (Advanced Very High Resolution Radiometer) are publicly\\navailable with high spectral resolution but coarse spatial resolution (250–1100 m, respectively), making\\nthem unsuitable for mangrove detection [ 9]. In contrast, the Sentinel-2 MultiSpectral Instrument\\n(MSI) sensor has a 10–20 m spatial resolution and ﬁve bands in near infrared region, which provides\\nopportunities to conduct quick, robust, and e \\x0ecient monitoring of submerged mangrove forests.\\nFor years, numerous methods were utilized to map mangrove forests as well as other aquatic\\nvegetation from remote sensing imagery, ranging from pixel to object-oriented approach, and manual\\nto unsupervised methods [ 9,14,26–28]. Recently, machine-learning algorithms such as random\\nforest, neural network, and support vector machine provide promising accuracy in mangrove forests\\nextraction [ 10,13,29]. As it is hard to locate representative training samples due to uncertain tidal\\nconditions, it is relatively hard to apply these methods to extract submerged mangrove forests from\\na single-date image. Vegetation indices (VIs), which are mathematically determined based on the\\nspectral characteristics of vegetation, have been proven e \\x0ecient in monitoring vegetation from\\nspace [ 30]. The Normalized Di \\x0berence Vegetation Index (NDVI) is the most commonly used index\\nin global vegetation studies (e.g., [ 30,31]). The Land Surface Water Index (LSWI) and the Modiﬁed\\nNormalized Di \\x0berence Water Index (MNDWI) were proposed and widely used for mapping surface\\nwater [ 32–34]. Given that these indices are established based on di \\x0berences between two bands,\\nthey are insensitive to small variations of the reﬂectance of submerged mangrove forests and water\\nbackground [ 14]. Furthermore, it is hard to decide thresholds that distinguish submerged mangroves\\nand water. With more bands, several VIs were built based on a baseline theory, such as Maximum\\nChlorophyll Index (MCI; [ 35]), the Floating Algae Index (FAI; [ 36]), and the Floating Vegetation Index\\n(FVI; [ 17]). However, these indices were deﬁned to extract ﬂoating vegetation (above water surface)\\nfrom water, not submerged vegetation. Meanwhile, bands used to build MCI and FVI did not exist in\\nSentinel MSI image.\\nThus, the objective of this study is to develop a new vegetation index, called the Mangrove Forest\\nIndex (MFI), which is capable to map the distribution of mangroves based on a single date MSI image.\\nThen, we will compare MFI with other widely used VIs to validate MFI’s capabilities in detecting\\nsubmerged mangrove forests from water background. Additionally, MFI will be applied to three sitesRemote Sens. 2019 ,11, 2043 3 of 17\\nof typical mangrove forests worldwide; the practical roles of mapping mangrove forests during local\\nhigh-tide conditions will also be discussed.\\n2. Materials and Methods\\n2.1. Sentinel-2 Imagery\\nSentinel-2, a European Space Agency (ESA) land-monitoring mission, has two matching satellites\\nthat provide high-resolution optical imagery. Sentinel-2A and Sentinel-2B carry the MultiSpectral\\nInstrument (MSI) and were successfully launched in June 2015 and March 2017 respectively and\\nprovide important means to augment earth observation capabilities [ 37]. These satellites revisit the\\nsame location every 2 to 5 days. The MSI sensor o \\x0bers 13 spectral bands, with four bands at 10 m, six\\nbands at 20 m, and three bands at a 60 m spatial resolution (Table 1) and o \\x0bers a wide range of earth\\nobservation applications [38].\\nIn this study, Sentinel-2 MSI images were downloaded from European Space Agency Sentinels\\nScientiﬁc Data Hub; the images were preprocessed with geometric and radiometric corrections at\\nsub-pixel accuracy. Then, atmospheric correction (converting top-of-atmosphere reﬂectance into\\ntop-of-canopy reﬂectance) was performed by the tool of SEN2COR (version 2.05.05), which was\\navailable in the Sentinel Application Platform (SNAP) toolbox [ 39,40]. In order to standardize di \\x0berent\\nspatial resolutions of bands in MSI images, we excluded bands with a spatial resolution of 60 m (Band\\n1, Band 9, and Band 10). After atmospheric correction, all remaining bands were resampled to a pixel\\nsize of 20 m\\x0220 m.\\nTable 1. General characteristics of the Sentinal-2 MultiSpectral Instrument (MSI) sensor.\\nMSI Band Band NameWavelength\\n(Central, nm)Spectral Width\\n(nm)Spatial Resolution\\n(m)\\nB1 Aerosols 443 20 60\\nB2 Blue 490 65 10\\nB3 Green 560 35 10\\nB4 Red 665 30 10\\nB5 Vegetation red-edge 705 15 20\\nB6 Vegetation red-edge 740 15 20\\nB7 Vegetation red-edge 783 20 20\\nB8 Near infrared 842 115 10\\nB8A Vegetation red-edge 865 20 20\\nB9 Water-vapor 945 20 60\\nB10 Cirrus 1380 30 60\\nB11Shortwave-infrared\\nreﬂectance (SWIR)11610 90 20\\nB12 SWIR2 2190 180 20\\n2.2. Study Area\\nThe study area, Zhenzhu Harbor (21\\x0e280–21\\x0e420N and 108\\x0e000–108\\x0e200N), is located in Guangxi\\nProvince, China, in the southwest portion of mainland China and the north region of Tonkin Gulf\\n(Figure 1). In Zhenzhu Harbor, mangrove forests are mainly composed of four communities: Comm. A.\\nmarina, Comm. A. corniculatum, Comm. A. marina–A. corniculatum, and Comm. K. candel–A. corniculatum .\\nThe tides in the coast of Zhenzhu Harbor are diurnal, with an average tidal range of 2.24 m, and\\nmangrove forests here are primarily younger shrubs with an average height of less than 3 m [ 7].\\nTherefore, the Zhenzhu Harbor is a typical area for the study of submerged mangrove forests, due to a\\nlarge area of pioneer mangrove trees and shrubs that would be entirely submerged during high tides\\n(Figure 1A,B). Information of MSI images we selected are shown in Table 2.Remote Sens. 2019 ,11, 2043 4 of 17\\nAdditionally, a ﬁeld survey of Zhenzhu Harbor was conducted during April 2017, in which 408\\nground truth samples were collected including samples of mangrove forest, open water, and other\\nland cover.\\nFigure 1. Snapshots of low- and high-tide Sentinel MSI images of study area (( A) during local low\\ntide all mangrove forests were emerged; ( B) during local high tide some of the mangrove forests were\\nsubmerged).\\nTable 2. Description of satellite data, including the path, row, date, time of acquisition, and tide level of\\nthe nearest tide station (Fangcheng Harbor Station, 108\\x0e140E, 21\\x0e280N).\\nSensor Path Row Date Time (hh:mm) Tide Height (m)\\nMSI 205 118 2017-12-17 11:23 \\x000.9\\nMSI 205 118 2017-09-28 16:37 1.8\\n2.3. Build a Reference Map\\nGround surveys were conducted along the coasts of Zhenzhu Harbor in November 2017. The\\nlocation of each sampling point was measured using a global positioning system (GPS), with an error\\nless than 1 m. The observations collected in the surveys contained 85 mangrove points and 81 water\\npoints. A vector ﬁle of ground survey points with the attributes of location (longitude and latitude),\\nland cover types, and photos was created with ArcGIS.\\nThe spectral curves of water, submerged mangrove forests, and emerged mangrove forests were\\nextracted from images. The workﬂow of discriminating these classes is shown in Figure 2. A reference\\nmap was built based on object-oriented methods and visual interpretation.\\nThe description of the object-oriented method can be found in Harayama and Jaquet [ 41]. The\\neCognition Developer 9.0, an image analysis program, was used to conduct object-oriented classiﬁcation.\\nVisual interpretation was performed to classify objects as either mangrove forests or water. To facilitateRemote Sens. 2019 ,11, 2043 5 of 17\\nvisual interpretation, a false color composite of MSI Bands 11 (centered 1610 nm), Band 8 (centered\\n842 nm), and Band 4 (centered 665 nm) was generated. This band combination that was deemed the\\nbest for detecting mangroves which appears dark green color [ 42]. Furthermore, in order to conduct the\\nadjustment in a robust manner, visual interpretation was performed by an experienced remote sensing\\nexpert who was familiar with this area. First, we identiﬁed mangrove forest and surrounding water\\nfrom the low-tide MSI image. Subsequently, a confusion matrix was generated using the independent\\nground-truth samples described in Section 2.2. With this matrix, we achieved an overall classiﬁcation\\naccuracy of 97% with a Kappa coe \\x0ecient of 0.92, which indicated excellent agreements between our\\nmapping results and ground-truth data. Therefore, mangrove forests identiﬁed with this method\\nwere assumed to cover entire area of local mangrove forests. Second, using the same techniques as\\nabove, mangrove forests were identiﬁed from the high-tide MSI image. Finally, the extent of the\\nsubmerged mangrove was determined by subtracting the high-tide from the low-tide mangrove forest\\nmap. Figure 3 shows the distributions of emerged mangrove forests and submerged mangrove forests\\nin the high-tidal MSI image.\\nFigure 2. Work ﬂow for identifying submerge mangrove forests.Remote Sens. 2019 ,11, 2043 6 of 17\\nFigure 3. Distribution of emerged and submerged mangrove forests in high-tide MSI image.\\n2.4. Theories\\nFigure 4 shows the ﬁeld measurements of spectral curves of the water, emerged vegetation,\\nand submerged vegetation, generated by Chen et al. (2018; Figure 4A) and Visser et al. (2015;\\nFigure 4B) [ 15,25]. As normal green plants, vegetation above the water surface showed high reﬂectance\\nin the spectral region of 770–890 nm. Waterbody is characterized by low reﬂectance in near infrared at\\n700 nm while emerged mangrove has a relatively high reﬂectance, which make them separable from\\neach other. However, when mangroves are submerged under water, the reﬂectance is largely reduced,\\ntherefore, it is di \\x0ecult to distinguish submerged vegetation from waterbody [ 15,25,43]. As measured,\\nwhen submerged vegetation are 43–51 cm below clear water, the NDVI value was close to zero, which\\nmeans no di \\x0berences were observed between the red band and NIR band [44].\\nHowever, by careful inspection of the spectral curves shown in Figure 4A,B, two reﬂectance\\npeaks ranging from approximately 690–740 nm and 810–830 nm were found, even for the curves of\\nvegetation located 40 cm below the water surface. These peaks result from the competing e \\x0bects\\nof the chlorophyll reﬂectance plateau and the absorption e \\x0bects of water located within submerged\\nvegetation and the surrounding water background. However, traditional multispectral satellite sensors\\ncould not capture these reﬂectance peaks. Fortunately, the MSI sensor has ﬁve channels that cover\\nthese regions. Figure 5 shows the typical spectral curves of water (WB), emerged mangrove forest\\n(EMF), and submerged mangrove forest (SMF) that are observed on the MSI image. As shown in\\nFigure 5, the emerged and shallow submerged mangrove forest pixels demonstrated a strong reﬂection\\nin the region of 660–900 nm, the absorption valleys appeared in bands 4 (centered wavelength 665 nm)\\nand 12 (centered 2160 nm). For the submerged mangrove forest (b) curves, a small reﬂectance peak\\nappeared in the 660–900 nm region; the absorption valley also appeared in bands 4 (centered 665 nm)\\nand 12 (centered 2160 nm). The reﬂectance of the water pixels shows a continuous decreasing tendency\\nbeginning with band 4 (central wavelength 665 nm). Therefore, comparing submerged curves to water\\ncurves, the higher reﬂectance in bands 5 (centered 705 nm), 6 (centered 740 nm), 7 (centered 783 nm),\\n8 (centered 842 nm), and 8A (centered 865 nm) could be used to distinguish submerged mangrove\\nforests from the water background.Remote Sens. 2019 ,11, 2043 7 of 17\\nFigure 4. The spectral curves of water, emerged, and submerged vegetation, as well as the absorption\\ncoe\\x0ecients of water (cm\\x001). ((A) ﬁeld-measurement [ 15]; (B) ﬁeld-measured of submerged vegetation’s\\nreﬂectance at 1.5, 16, and 40 cm below water surface [25]).\\nFigure 5. (A) Typical spectral curves of emerged (EMF), submerged mangrove forests (SMF) and water\\n(WB) in Sentinel-2A MSI image. ( B) EMF and SMF forests in Sentinel MSI image and ﬁeld photo. ( a)\\nRepresents shallow submerged mangrove forests (0–30 cm), ( b) Represents deep submerged mangrove\\nforests (30–60 cm).\\n2.5. Existing Vegetation Indices\\nPreviously, NDVI (Equation 1), LSWI (Equation 2), and MNDWI (Equation 3) and FAI (Equation\\n4) were used in detecting vegetation from water bodies [33,34,45].\\nNDVI =\\x1aNIR\\x00\\x1aRed\\n\\x1aNIR+\\x1aRed(1)\\nLSWI =\\x1aNIR\\x00\\x1aSWIR\\n\\x1aNIR+\\x1aSWIR(2)\\nMNDWI =\\x1aGreen\\x00\\x1aSWIR\\n\\x1aGreen +\\x1aSWIR(3)\\nFAI=\\x08\\x1a860\\x00[\\x1a1240+(\\x1a660\\x00\\x1a1240)\\x02(1240\\x00860)/(1240\\x00660)]\\t(4)\\nwhere\\x1aGreen ,\\x1aRed,\\x1aNIR, and\\x1aSWIR are the reﬂectance of the green, red, NIR, and SWIR, respectively.\\nHowever, these indices are not suitable for discerning submerged vegetation from water bodies,\\nbecause there are no obvious reﬂectance di \\x0berences in bands green, red, and SWIR between submerged\\nvegetation and water bodies (Figures 4 and 5).Remote Sens. 2019 ,11, 2043 8 of 17\\n2.6. Formulation of MFI\\nFor this study, according to the analysis in Section 2.4, the absorption valleys in band 4 (centered\\n665 nm) and band 12 (centered 2190 nm) could be used to form a baseline (Figure 6). In order to\\nenhance the stability of di \\x0berences between submerged mangrove forests and the water background,\\nthe average value of reﬂectance of band 5 (centered 705 nm), band 6 (centered 740 nm), band 7 (centered\\n783 nm), and band 8A (centered 865 nm) above the baseline, is deﬁned as MFI. Band 8 was excluded\\nbecause Bands 7 (centered 783 nm) and 8A (centered 865 nm) covered most of its spectra, and its\\nspectral range overlaps with the water absorption region. The mathematical formulation is\\nMFI =h\\n(\\x1a\\x151\\x00\\x1aB\\x151)+(\\x1a\\x152\\x00\\x1aB\\x152)+(\\x1a\\x153\\x00\\x1aB\\x153)+(\\x1a\\x154\\x00\\x1aB\\x154\\x11\\n]/4 (5)\\n\\x1aB\\x15i=\\x1a2190+(\\x1a665\\x00\\x1a2190)\\x02(2190\\x00\\x15i)/(2190\\x00665) (6)\\nwhere the \\x1a\\x15is the reﬂectance of the band center of \\x15, and iranged from 1 to 4; \\x151,\\x152,\\x153,\\x154represent\\nthe center wavelengths at 705, 740, 783 and 865 nm, respectively. \\x1aB\\x15iis the baseline reﬂectance in\\n\\x15i.\\x1a665and\\x1a2190are the reﬂectance of band 4 (centered at 665 nm) and 12 (centered at 2190 nm),\\nrespectively. Pixels with an MFI value above 0 are recognized as mangrove forests.\\nFigure 6. Baseline theory of establishing Mangrove Forest Index (MFI), including reﬂectance of\\nsubmerged mangrove forest and water.\\n2.7. Quantitative Comparison between MFI and Other VIs\\nIn this study, Jensen–Shannon divergence (JSD)—a measure of distance between a ﬁnite number\\nof distributions—was adopted to compare sensitivities of MFI and other VIs. The JSD ( D) quantiﬁes\\nthe di \\x0berence between two or more probability distributions. In this study, it was used to compare\\nthe di \\x0berences between submerged mangrove forests and water pixels in di \\x0berent VI images. The\\nDvalue, which was calculated in MATLAB, is deﬁned as follows: let p(1)\\x11(p(1)\\n1,p(1)\\n2,:::,p(1)\\nk)\\nand p(2)\\x11\\x12\\np(2)\\n1,p(2)\\n2,:::,p(2)\\nk\\x13\\ndenote two probability distributions satisfying the usual constraints\\nPk\\ni=1p(j)\\ni=1and 0\\x14p(j)\\ni\\x141for all i=1,2,:::,k and j=1,2; and let \\x19(1)and\\x19(2)denote the weights\\nof the distributions p(1)and p(2), satisfying the constraints \\x19(1)+\\x19(2)=1and 0\\x14\\x19(j)\\x141. Then theRemote Sens. 2019 ,11, 2043 9 of 17\\nJensen–Shannon divergence Dbetween the probability distributions p(1)and p(2)with weights \\x19(1)\\nand\\x19(2)is deﬁned by [46]:\\nDh\\np(1),p(2)i\\n\\x11Hh\\n\\x19(1)p(1)+\\x19(2)p(2)i\\n\\x00\\x10\\n\\x19(1)Hh\\np(1)i\\n+\\x19(2)Hh\\np(2)i\\x11\\n(7)\\nwhere\\nH[p]=\\x00Xk\\ni=1pilog2pi (8)\\ndenotes the Shannon entropy of the probability distribution p\\x11(p1,p2,:::pk).Dranging from 0–1, 0\\nmeans no di \\x0berence between distributions, 1 means the distributions are completely di \\x0berent.\\n3. Results\\n3.1. Quantitative Comparison of MFI, FAI, NDVI, LSWI, and MNDWI\\nTo compare the ability to distinguish submerged mangrove forests from the water background,\\nthe VIs values of all submerged mangrove forests (in total 12,001 pixels extracted in Section 2.3), and\\n22,668 pixels of water in the high-tidal MSI image (acquired on 28 September 2017) were calculated.\\nAdditionally, to make the di \\x0berent VIs comparable, the MFI and FAI were calculated to 10 times of their\\noriginal values. The boxplots of submerged mangrove forests and water pixels are shown in Figure 7.\\nFigure 7. Boxplot of di \\x0berent index values over submerged mangrove forest pixels and water pixels\\n(MFI and Floating Algae Index (FAI) are 10 times their original value. SMF means submerged mangrove\\nforest, WB means Water Body. The horizontal axis represents di \\x0berent indices).\\nAs shown in Figure 7, all submerged mangrove forest pixels have higher MFI values than those of\\nthe water background, the minimum value of submerged mangrove forests is equal to the maximal\\nvalue of water. Most of the water pixels are confused with submerged mangrove forests in FAI, NDVI,\\nand NDWI image. According to our calculations, the Dvalues of MFI, FAI, NDVI, LSWI, and MNDWI\\nare 0.209, 0.077, 0.012, 0.003, and 0.121, respectively, which means pixels of submerged mangrove\\nforests and water are better separated in an MFI image than other VIs.Remote Sens. 2019 ,11, 2043 10 of 17\\n3.2. Evaluation of MFI at Di \\x0berent Mangrove Forests around the World\\nGlobally, three selected mangrove forest sites were chosen to demonstrate the practical utility\\nof our newly formed index (MFI) in distinguishing mangrove forests from water background. They\\nare (a) Zhenzhu Harbor, Guangxi, China, (b) Dalhousie Island, Sundarbans, India, (c) Baia do Arraial,\\nAmazon Coast, Brazil. Locations are shown in Figure 8.\\nFigure 8. Global study sites of mangrove forests. (Displayed imagery: R:G:B =Sentinel MSI Band 8A:\\n4:3. ( a) Zhenzhu Harbor, Guangxi, China; ( b) Dalhousie Island, Sundarbans, India; ( c) Baia do Arraial,\\nAmazon Coast, Brazil).\\nClassiﬁcation accuracy assessment is essential for validating the performance of the MFI index.\\nIn this study, a table containing the overall accuracy, user’s accuracy, producer’s accuracy, and the\\nKappa coe \\x0ecient of each site were presented in Table 3. In Zhenzhu Harbor, the validation samples\\nwere collected from ﬁeld survey. In Dalhousie Island and Baja do Arraial, validation samples were\\nrandomly selected from Google Earth high-resolution images.Remote Sens. 2019 ,11, 2043 11 of 17\\nTable 3. Confusion matrix for worldwide study sites of mangrove forests, including overall accuracy,\\nproducer’s accuracy, user’s accuracy, and Kappa coe \\x0ecient.\\nZhenzhu Harbor\\nLand CoverClassiﬁcation Results\\nMangrove Water Producer’s Accuracy\\nMangrove 82 3 96.4%\\nWater 2 79 97.5%\\nUser’s accuracy 97.6% 96.3% –\\nOverall accuracy 97.0% Kappa coe \\x0ecient 0.94\\nDalhousie Island Mangrove Water Producer’s accuracy\\nMangrove 52 1 98.1%\\nWater 2 39 95.1%\\nUser’s accuracy 96.2% 97.5% –\\nOverall accuracy 96.8% Kappa coe \\x0ecient 0.93\\nBaja do Arraial Mangrove Water Producer’s accuracy\\nMangrove 30 3 90.9%\\nWater 3 36 92.3%\\nUser’s accuracy 90.9% 92.3% –\\nOverall accuracy 91.7% Kappa coe \\x0ecient 0.83\\n3.2.1. Zhenzhu Harbor, Guangxi, China\\nMFI was applied to the high-tidal Sentinel MSI image (acquired 2017-09-28). Figure 9 shows\\nthe MFI image (Figure 9A), mangrove forest distribution classiﬁed from MFI image (Figure 9B), and\\nreference map (Figure 9C) derived from low-tide Sentinel MSI images (described in Section 2.3).\\nAccording to the results shown in the reference map (Figure 9C), the total area of mangrove forests was\\n856.30 ha, with 107.05 ha of submerged and 749.25 ha of emerged mangrove forests. In Figure 9B, the\\ntotal area of mangrove forest we classiﬁed from the MFI image was 849.4 ha, which means 99% of the\\nmangrove forest pixels were successfully extracted from water background by the MFI. According to\\nTable 3, the overall accuracy of this mangrove map is 97% with a Kappa coe \\x0ecient of 0.94. In Zhenzhu\\nHarbor, the MFI value of emerged mangrove forests, submerged mangrove forests, and water pixels\\nrange from 0.19 to 0.30, \\x000.01 to 0.18, and\\x000.2 to\\x000.01.\\nFigure 9. Apply the MFI to extract mangrove forests in Zhenzhu Harbor, Guangxi, China. ( A) MFI\\nimage, ( B) mangrove forests extracted from MFI image, and ( C) reference map.\\n3.2.2. Dalhousie Island, Sundarbans, India\\nSundarbans has the biggest patch of mangrove forest ﬂourishing on the world’s largest delta\\n(Ganga–Bramhaputra–Meghna Delta; [ 47]). The tidal amplitude within the estuary ranges from 3.5\\nto 4 m, with seasonal variation between 1 and 6 m; mangrove forests are periodically submerged\\nduring high tide [ 48,49]. In this study, Dalhousie Island (located in the southern part of Sundarbans,\\nIndia) was chosen as a typical area to validate the performance of the MFI. Figure 10 shows a local\\nhigh-tidal MSI image (Figure 10A, captured on 2016-10-17), the MFI-derived image (Figure 10B), andRemote Sens. 2019 ,11, 2043 12 of 17\\nground-truth images obtained by Google Earth snapshot (Figure 10a–c). As shown in Figure 10A, in\\nmangrove swamps, a number of patches seem similar to seawater. In Figure 10a–c, although these\\npatches show white tones, they are lower and sparser mangrove forests that are intermittently ﬂooded\\nby tides. Fortunately, these patches have positive values in the MFI image (Figure 10B). According to\\nMondal and Saha (2018), Dalhousie Island had 5950 ha of mangrove forests on 2015-08-03 [ 50]. In the\\nMFI image, the extent of mangrove extracted by the MFI is 6105 ha (pixels with positive MFI values),\\naccounting for 102% of Mondal and Saha’s result. Although the MSI image was captured during high\\ntide, almost all the local mangrove forests were detected by the MFI. According to Table 3, the overall\\naccuracy of this mangrove map is 96.8%, with a Kappa coe \\x0ecient of 0.93. In Dalhousie Island, the MFI\\nvalue of emerged mangrove forests, submerged mangrove forests, and water pixels range from 0.11 to\\n0.25, 0 to 0.10, and –0.03 to 0.\\nFigure 10. Apply the MFI to extract mangrove forests in Dalhousie Island, Sundarbans, India. ( A)\\nSentinel MSI image (Band combination: R:G:B =8A: 4: 3); ( B) Sentinel MSI-based MFI image; ( a–c):\\nGoogle Earth snapshot.\\n3.2.3. Baia do Arraial, Amazon Coast, Brazil\\nBaia do Arraial is located along the south coasts of S ão Lu ís city, Brazil (Figure 11). The coastal\\nzone of S ão Lu ís is dominated by a semidiurnal tide; the high energy causes a maximum tidal height\\nof 8 m during the equinoctial spring tide. Therefore, numerous mangrove trees and shrubs would\\nbe submerged during high tides. As shown in Figure 11A, on 2018-06-14, patches in the northwest\\nand the middle of mangrove swamps were submerged; fortunately, these mangrove forests showed\\npositive values in Figure 11B, and the snapshot of Google Earth images conﬁrmed that these places\\nwere occupied by low mangrove forests. Therefore, we concluded that submerged mangrove forests\\nin Baia do Arraial could be detected by the MFI. According to Table 3, the overall accuracy of this\\nmangrove map is 91.7%, with a Kappa coe \\x0ecient of 0.83. In Baia do Arraial, the MFI values of emerged\\nmangrove forests, submerged mangrove forests, and water pixels range from 0.09 to 0.25, 0 to 0.09, and\\n\\x000.06 to 0.Remote Sens. 2019 ,11, 2043 13 of 17\\nFigure 11. Apply the MFI to extract mangrove forests in Baia do Arraial, Amazon Coast, Brazil. ( A)\\nSentinel MSI image (band combination: R:G:B =8A: 4: 3), ( B) Sentinel MSI based MFI image, ( a,b):\\nGoogle Earth snapshot.\\n4. Discussion\\n4.1. Advantages and Potential Applications of MFI\\nLocated along intertidal zones, mangrove forests are always relatively small patches; therefore,\\nmisclassiﬁcation of a small area would greatly a \\x0bect mapping results. The lack of full consideration\\nof tidal conditions would cause misclassiﬁcation between mangrove forests and water background.\\nTo accurately map and manage mangrove forests, in this study, we attempt to extract all mangrove\\nforests during local high tides. Undeniably, using VIs to extract mangrove forests is not new. All the\\ncommonly used indices are applicable to detecting emerged mangrove forests. However, during high\\ntides, according to our statistics in Figure 7, in LSWI, MNDWI, NDVI, and FAI images 27%, 8%, 19%,\\nand 5% of submerged pixels were mixed with water background. Furthermore, based on the result of\\nJensen–Shannon divergence, MFI greatly increased the distance of submerged mangrove forests and\\nwater. However, in the MFI image, nearly all the submerged pixels were completely separated from\\nthe water background. Furthermore, all traditional vegetation indices have a vital uncertainty, that\\nallow for the determination of the threshold of VIs. Fortunately, based on the theory of being above\\nthe baseline, one advantage of using the MFI in detecting mangrove forests is that the threshold is at\\nthe ﬁxed value of zero.\\nThis study provides an index built by Sentinel-2 MSI bands for discriminating submerged\\nmangrove forests from water background. It supports the ﬁndings of previous studies that the NIR\\nand red-edge provide great opportunities in discriminating between vegetation and water. Sentinel-2\\nMSI image contains ﬁve bands in NIR region, four of which were used to build the MFI. The FAI was\\nalso established based on baseline theory, but with one NIR band. However, according to Figure 7\\nand our statistics, unlike MFI (completely separated submerged mangrove forest and water), in the\\nFAI image, 5% of submerged mangrove forests pixels were mixed with water pixels. This is primarily\\nbecause unexpected ﬂuctuation in one NIR band could greatly a \\x0bect the value of the FAI. The four MSI\\nred-edge bands demonstrated relatively stable discrimination between submerged mangrove forest\\nand water.\\nTheoretically, the MFI concept can be applied to other sensors that contain spectral channels of red,\\nNIR, and SWIR, for example, the Landsat OLI sensor which has a red band ranging from 630 to 690 nm,\\nan NIR band ranging from 840 to 890 nm, and a SWIR band ranging from 2100 to 2300 nm. However,\\ndi\\x0berent sensors may acquire di \\x0berent MFI values due to the di \\x0berent ranges of red, NIR, and SWIR\\nbands. Furthermore, the performance of the Sentinel-2 MSI red-edge bands will also be present on\\nthe Sentinel-3 Ocean and Land Color Instrument (OLCI) sensor [ 51]. Therefore, the adaptability of\\nthe MFI to other remote sensing sensors still requires further examination. Moreover, the MFI was\\ndesigned based on the reﬂectance peak in the NIR spectral regions of green vegetation. Therefore,Remote Sens. 2019 ,11, 2043 14 of 17\\nthe MFI has great potential in detecting any submerged or emerged vegetation in aquatic environments,\\nsuch as ﬂoating algae and aquatic macrophytes. However, considering the various environments\\nwhere aquatic vegetation grows, the applicability of the MFI in detecting other aquatic vegetation still\\nwarrants further exploration.\\n4.2. Uncertainties Leading to Overestimation of Mangrove Forests Using the MFI\\nThis study demonstrates that there are abundant di \\x0berences in the spectral reﬂectance between\\nsubmerged mangrove forests and water bodies. In addition, the spectral curves of submerged and\\nemerged mangrove forests showed similar concave–convex characteristics (Figure 5). Therefore, the\\nMFI function can e \\x0eciently identify and detect mangrove forests from water background. However,\\nthe MFI was designed based on the reﬂectance peak between red and SWIR; any other vegetation that\\ncontains absorption signatures of chlorophyll in aquatic environment can also be detected [ 17,36,52].\\nHence, pixels containing ﬂoating vegetation (for example, algae) and other aquatic macrophytes (for\\nexample, Spartina alterniﬂora ) may be classiﬁed as mangrove forest. Additionally, due to limits in image\\nresolution, a small area of the water could still be classiﬁed as mangrove forests, due to having similar\\nspectral characteristics as nearby mangrove forests. These uncertainties can lead to overestimation of\\nmangrove forests by the MFI. In our application in Dalhousie Island, Sundarbans, India, the bias of\\narea of mangrove forests obtained by MFI is 2% larger.\\n4.3. Limitations Leading to Underestimation of Mangrove Forests Using the MFI\\nIn this study, MFI was created based on the typical reﬂectance curves of submerged mangrove\\nforests. However, the spectral curve of submerged mangrove forest can be a \\x0bected by several factors,\\nincluding water transparency (turbidity), distance that mangrove canopy under the water surface, and\\nthe coverage of mangrove forest [ 15]. Liew and Chang proved that the spectral curves of submerged\\nvegetation changes when water turbidity and depth change [ 53]. They demonstrated that with high\\nturbidity (50 nephelometric turbidity units), green vegetation could not be distinguished at a water\\ndepth of 0.5 m. In addition, with low turbidity (0.5 nephelometric turbidity units), typical vegetation\\nreﬂectance was undetectable at a water depth of 1 m. Chen et al. discovered that when submerged\\nvegetation coverage was less than 40%, it is di \\x0ecult to detect vegetation based on the NIR peak in\\nthe spectral reﬂectance curve [ 15]. Unfortunately, water ﬂow in mangrove swamps always has high\\nturbidity, and newly grown trees at the edge of mangrove forests always have low coverage. According\\nto our ﬁeld measurement, in Zhenzhu Harbor, submerged mangrove forests with a depth of 60 cm\\nunder the water surface would not be detected by MFI. Moreover, due to limits of image resolution,\\nsmall parts of the mangrove forests may be classiﬁed as water due to low tree coverage. As shown in\\nFigure 12, in Zhenzhu Harbor, low mangrove forests along tidal creeks were not identiﬁed by MFI.\\nThese limitations lead to underestimation of the areal extent of mangrove forests by the MFI.\\nFigure 12. Intermittently ﬂooded mangrove forests in local low tide period.\\n5. Conclusions\\nBased on the spectral response curves of submerged mangrove forests, a new vegetation index\\n(MFI) was developed to distinguish mangrove forests from the water background. To take fullRemote Sens. 2019 ,11, 2043 15 of 17\\nadvantage of the di \\x0berences in reﬂectance between submerged mangrove forests and the water\\nbackground, Sentinel-2 MSI bands, red and SWIR2 were selected to build a linear baseline, and the\\naverage reﬂectance value of four red-edge bands above the baseline was deﬁned as mangrove forest\\nindex (MFI). This new vegetation index is more advantageous in detecting submerged mangrove\\nforests than the traditional NDVI, LSWI, MNDWI, and FAI indices. According to the results of\\nJensen–Shannon divergence, MFI signiﬁcantly widens the distance of submerged mangrove forest and\\nwater pixels compared to other VIs (the Jensen-Shannon divergence values of MFI, FAI, NDVI, LSWI,\\nand MNDWI are 0.209, 0.077, 0.012, 0.003, and 0.121, respectively). Theoretically, 100% of submerged\\nmangrove forests could be extracted from MFI images. Practically, application of the MFI in three\\nglobal mangrove sites showed 99% to 102% of submerged mangrove forests were successfully extracted\\nfrom the MFI image. The overall accuracy of classiﬁcation results obtained from the MFI image ranged\\nfrom 91.7% to 97.6%. According to our ﬁeld measurements in Zhenzhu Harbor, MFI is insensitive to\\nmangrove forests with canopies under 60 cm of the water surface. There are some uncertainties and\\nlimitations, but the MFI was proven to be e \\x0bective in detecting the extent and condition of mangrove\\nforests from high-tide Sentinel MSI images. Although the repeatability and portability of the MFI is\\nstill a work in progress, this index brings great beneﬁts to remote sensing communities of coastal and\\naquatic vegetation studies.\\nAuthor Contributions: M.J. and Z.W. designed the research, process the data, and wrote the manuscript draft.\\nY.Z. helped with designed research and reviewed the manuscript. C.W. helped with image analysis, ﬁeldwork,\\nand reviewed the manuscript. D.M. helped with image analysis and reviewed the manuscript.\\nFunding: The work is supported by Science and Technology Basic Resources Investigation Program of China (No.\\n2017FY100706), the National Natural Science Foundation of China (No. 41601470, No. 41601406), the Strategic\\nPlanning Project of the Institute of Northeast Geography and Agroecology (IGA), Chinese Academy of Sciences\\n(No. Y6H2091000), and the Youth Innovation Promotion Association of Chinese Academy of Sciences (2017277,\\n2012178). This work is supported by Open Fund of State Laboratory of Information Engineering in Surveying,\\nMapping and Remote Sensing, Wuhan University (Grant No. 19I02).\\nAcknowledgments: The authors are grateful to the colleagues who participated in the ﬁeld surveys and\\ndata collection.\\nConﬂicts of Interest: The authors declare no conﬂict of interest.\\nReferences\\n1. Collins, D.S.; Avdis, A.; Allison, P .A.; Johnson, H.D.; Hill, J.; Piggott, M.D.; Hassan, M.H.A.; Damit, A.R.\\nTidal dynamics and mangrove carbon sequestration during the Oligo-Miocene in the South China Sea.\\nNat. Commun. 2017 ,8, 15698. [CrossRef] [PubMed]\\n2. Richards, D.R.; Friess, D.A. Rates and drivers of mangrove deforestation in Southeast Asia, 2000–2012.\\nProc. Natl. Acad. Sci. USA 2016 ,113, 344–349. [CrossRef] [PubMed]\\n3. Friess, D.A.; Webb, E.L. Variability in mangrove change estimates and implications for the assessment of\\necosystem service provision. Glob. Ecol. Biogeogr. 2014 ,23, 715–725. [CrossRef]\\n4. Kuenzer, C.; Bluemel, A.; Gebhardt, S.; Quoc, T.V .; Dech, S. Remote sensing of mangrove ecosystems:\\nA review. Remote Sens. 2011 ,3, 878–928. [CrossRef]\\n5. Hamilton, S.E.; Casey, D. Creation of a high spatio-temporal resolution global database of continuous\\nmangrove forest cover for the 21st century (CGMFC-21). Glob. Ecol. Biogeogr. 2016 ,25, 729–738. [CrossRef]\\n6. Giri, C.; Pengra, B.; Zhu, Z.; Singh, A.; Tieszen, L.L. Monitoring mangrove forest dynamics of the Sundarbans\\nin Bangladesh and India using multi-temporal satellite data from 1973 to 2000. Estuar. Coast. Shelf Sci. 2007 ,\\n73, 91–100. [CrossRef]\\n7. Li, M.; Lee, S. Mangroves of China: A brief review. For. Ecol. Manag. 1997 ,96, 241–259. [CrossRef]\\n8. Spalding, M.D.; Blasco, F.; Field, C.D. World Mangrove Atlas ; Routledge: London, UK, 1997.\\n9. Cardenas, N.Y.; Joyce, K.E.; Maier, S.W. Monitoring mangrove forests: Are we taking full advantage of\\ntechnology? Int. J. Appl. Earth Obs. Geoinf. 2017 ,63, 1–14. [CrossRef]\\n10. Rogers, K.; Lymburner, L.; Salum, R.; Brooke, B.P .; Woodro \\x0be, C.D. Mapping of mangrove extent and\\nzonation using high and low tide composites of Landsat data. Hydrobiologia 2017 ,803, 49–68. [CrossRef]Remote Sens. 2019 ,11, 2043 16 of 17\\n11. Jia, M.; Wang, Z.; Zhang, Y.; Mao, D.; Wang, C. Monitoring loss and recovery of mangrove forests during\\n42 years: The achievements of mangrove conservation in China. Int. J. Appl. Earth Obs. Geoinf. 2018 ,73,\\n535–545. [CrossRef]\\n12. Jia, M.; Wang, Z.; Zhang, Y.; Ren, C.; Song, K. Landsat-based estimation of mangrove forest loss and\\nrestoration in Guangxi province, China, inﬂuenced by human and natural factors. IEEE J. Sel. Top. Appl.\\nEarth Obs. Remote Sens. 2015 ,8, 311–323. [CrossRef]\\n13. Xia, Q.; Qin, C.-Z.; Li, H.; Huang, C.; Su, F.-Z. Mapping mangrove forests based on multi-tidal high-resolution\\nsatellite imagery. Remote Sens. 2018 ,10, 1343. [CrossRef]\\n14. Zhang, X.; Treitz, P .M.; Chen, D.; Quan, C.; Shi, L.; Li, X. Mapping mangrove forests using multi-tidal\\nremotely-sensed data and a decision-tree-based procedure. Int. J. Appl. Earth Obs. Geoinf. 2017 ,62, 201–214.\\n[CrossRef]\\n15. Chen, Q.; Yu, R.; Hao, Y.; Wu, L.; Zhang, W.; Zhang, Q.; Bu, X. A New Method for Mapping Aquatic\\nVegetation Especially Underwater Vegetation in Lake Ulansuhai Using GF-1 Satellite Data. Remote Sens.\\n2018 ,10, 1279. [CrossRef]\\n16. Silva, T.S.; Costa, M.P .; Melack, J.M.; Novo, E.M. Remote sensing of aquatic vegetation: Theory and\\napplications. Environ. Monit. Assess. 2008 ,140, 131–145. [CrossRef] [PubMed]\\n17. Gao, B.-C.; Li, R.-R. FVI—A Floating Vegetation Index Formed with Three Near-IR Channels in the 1.0–1.24\\n\\x16m Spectral Range for the Detection of Vegetation Floating over Water Surfaces. Remote Sens. 2018 ,10, 1421.\\n[CrossRef]\\n18. Sibanda, M.; Mutanga, O.; Dube, T.; S Vundla, T.; L Mafongoya, P . Estimating LAI and mapping canopy\\nstorage capacity for hydrological applications in wattle infested ecosystems using Sentinel-2 MSI derived\\nred edge bands. GISci. Remote Sens. 2019 ,56, 68–86. [CrossRef]\\n19. Williams, D.J.; Rybicki, N.B.; Lombana, A.V .; O’Brien, T.M.; Gomez, R.B. Preliminary investigation of\\nsubmerged aquatic vegetation mapping using hyperspectral remote sensing. In Coastal Monitoring through\\nPartnerships ; Springer: Berlin, Germany, 2003; pp. 383–392.\\n20. Luo, J.; Li, X.; Ma, R.; Li, F.; Duan, H.; Hu, W.; Qin, B.; Huang, W. Applying remote sensing techniques to\\nmonitoring seasonal and interannual changes of aquatic vegetation in Taihu Lake, China. Ecol. Indic. 2016 ,\\n60, 503–513. [CrossRef]\\n21. Ma, R.; Duan, H.; Liu, Q.; Loiselle, S.A. Approximate bottom contribution to remote sensing reﬂectance in\\nTaihu Lake, China. J. Great Lakes Res. 2011 ,37, 18–25. [CrossRef]\\n22. Pu, R.; Bell, S.; Meyer, C.; Baggett, L.; Zhao, Y. Mapping and assessing seagrass along the western coast of\\nFlorida using Landsat TM and EO-1 ALI /Hyperion imagery. Estuar. Coast. Shelf Sci. 2012 ,115, 234–245.\\n[CrossRef]\\n23. Purnamasayangsukasih, P .R.; Norizah, K.; Ismail, A.A.; Shamsudin, I. A review of uses of satellite imagery\\nin monitoring mangrove forests. In Proceedings of the IOP Conference Series: Earth and Environmental\\nScience, Prague, Czech Republic, 12–19 July 2016; p. 012034.\\n24. Zhao, D.; Jiang, H.; Yang, T.; Cai, Y.; Xu, D.; An, S. Remote sensing of aquatic vegetation distribution in Taihu\\nLake using an improved classiﬁcation tree with modiﬁed thresholds. J. Environ. Manag. 2012 ,95, 98–107.\\n[CrossRef] [PubMed]\\n25. Visser, F.; Buis, K.; Verschoren, V .; Meire, P . Depth estimation of submerged aquatic vegetation in clear water\\nstreams using low-altitude optical remote sensing. Sensors 2015 ,15, 25287–25312. [CrossRef] [PubMed]\\n26. Heumann, B.W. An object-based classiﬁcation of mangroves using a hybrid decision tree—Support vector\\nmachine approach. Remote Sens. 2011 ,3, 2440–2460. [CrossRef]\\n27. Heumann, B.W. Satellite remote sensing of mangrove forests: Recent advances and future opportunities.\\nProg. Phys. Geogr. 2011 ,35, 87–108. [CrossRef]\\n28. Wang, T.; Zhang, H.; Lin, H.; Fang, C. Textural–spectral feature-based species classiﬁcation of mangroves in\\nMai Po Nature Reserve from Worldview-3 imagery. Remote Sens. 2016 ,8, 24. [CrossRef]\\n29. Wan, L.; Zhang, H.; Wang, T.; Li, G.; Lin, H. Mangrove species discrimination from very high resolution\\nimagery using gaussian markov random ﬁeld model. Wetlands 2018 ,38, 861–874. [CrossRef]\\n30. Huete, A.; Justice, C.; Van Leeuwen, W. MODIS vegetation index (MOD 13) algorithm theoretical basis\\ndocument (ATBD) Version 3.0. EOS Proj. O \\x0b.1999 , 2–3.Remote Sens. 2019 ,11, 2043 17 of 17\\n31. Matsushita, B.; Yang, W.; Chen, J.; Onda, Y.; Qiu, G. Sensitivity of the enhanced vegetation index (EVI) and\\nnormalized di \\x0berence vegetation index (NDVI) to topographic e \\x0bects: A case study in high-density cypress\\nforest. Sensors 2007 ,7, 2636–2651. [CrossRef] [PubMed]\\n32. Gao, B.-C. NDWI—A normalized di \\x0berence water index for remote sensing of vegetation liquid water from\\nspace. Remote Sens. Environ. 1996 ,58, 257–266. [CrossRef]\\n33. Xiao, X.; Boles, S.; Liu, J.; Zhuang, D.; Frolking, S.; Li, C.; Salas, W.; Moore, B., III. Mapping paddy rice\\nagriculture in southern China using multi-temporal MODIS images. Remote Sens. Environ. 2005 ,95, 480–492.\\n[CrossRef]\\n34. Xu, H. Modiﬁcation of normalised di \\x0berence water index (NDWI) to enhance open water features in remotely\\nsensed imagery. Int. J. Remote Sens. 2006 ,27, 3025–3033. [CrossRef]\\n35. Gower, J.; Hu, C.; Borstad, G.; King, S. Ocean color satellites show extensive lines of ﬂoating Sargassum in\\nthe Gulf of Mexico. IEEE Trans. Geosci. Remote Sens. 2006 ,44, 3619–3625. [CrossRef]\\n36. Hu, C. A novel ocean color index to detect ﬂoating algae in the global oceans. Remote Sens. Environ. 2009 ,\\n113, 2118–2129. [CrossRef]\\n37. Li, S.; Ganguly, S.; Dungan, J.L.; Wang, W.; Nemani, R.R. Sentinel-2 MSI radiometric characterization and\\ncross-calibration with Landsat-8 OLI. Adv. Remote Sens 2017 ,6, 147. [CrossRef]\\n38. Wang, Q.; Blackburn, G.A.; Onojeghuo, A.O.; Dash, J.; Zhou, L.; Zhang, Y.; Atkinson, P .M. Fusion of Landsat\\n8 OLI and Sentinel-2 MSI data. IEEE Trans. Geosci. Remote Sens. 2017 ,55, 3885–3899. [CrossRef]\\n39. Clevers, J.G.; Kooistra, L.; van den Brande, M.M. Using Sentinel-2 data for retrieving LAI and leaf and\\ncanopy chlorophyll content of a potato crop. Remote Sens. 2017 ,9, 405. [CrossRef]\\n40. Quintano, C.; Fern ández-Manso, A.; Fern ández-Manso, O. Combination of Landsat and Sentinel-2 MSI data\\nfor initial assessing of burn severity. Int. J. Appl. Earth Obs. Geoinf. 2018 ,64, 221–225. [CrossRef]\\n41. Harayama, A.; Jaquet, J.-M. Multi-Source Object-Oriented Classiﬁcation of Landcover Using Very High Resolution\\nImagery and Digital Elevation Model ; UNEP: Geneva, Switzerland, 2004.\\n42. Spalding, M. World Atlas of Mangroves ; Routledge: London, UK, 2010.\\n43. Han, L.; Rundquist, D. The spectral responses of Ceratophyllum demersum at varying depths in an\\nexperimental tank. Int. J. Remote Sens. 2003 ,24, 859–864. [CrossRef]\\n44. Cho, H.J.; Kirui, P .; Natarajan, H. Test of multi-spectral vegetation index for ﬂoating and canopy-forming\\nsubmerged vegetation. Int. J. Environ. Res. Public Health 2008 ,5, 477–483. [CrossRef]\\n45. Tucker, C.J. Red and photographic infrared linear combinations for monitoring vegetation. Remote Sens.\\nEnviron. 1979 ,8, 127–150. [CrossRef]\\n46. Lin, J. Divergence measures based on the Shannon entropy. IEEE Trans. Inf. Theory 1991 ,37, 145–151. [CrossRef]\\n47. Manna, S.; Raychaudhuri, B. Mapping distribution of Sundarban mangroves using Sentinel-2 data and new\\nspectral metric for detecting their health condition. Geocarto Int. 2018 , 1–30. [CrossRef]\\n48. Ghosh, A.; Schmidt, S.; Fickert, T.; Nüsser, M. The Indian Sundarban mangrove forests: History, utilization,\\nconservation strategies and local perception. Diversity 2015 ,7, 149–169. [CrossRef]\\n49. Islam, M.T. Vegetation changes of Sundarbans based on Landsat Imagery analysis between 1975 and 2006.\\nActa Geogr. Debrecina Landsc. Environ. Ser. 2014 ,8, 1–9.\\n50. Mondal, B.; Saha, A.K. Spatio-Temporal Analysis of Mangrove Loss in Vulnerable Islands of Sundarban World\\nHeritage Site, India. In Proceedings of the Annual International Conference on Geographic Information\\nScience, Lund, Sweden, 12–15 June 2018; Springer: Cham, Switzerland, 2018; pp. 93–109.\\n51. Clevers, J.G.; Gitelson, A.A. Remote estimation of crop and grass chlorophyll and nitrogen content using\\nred-edge bands on Sentinel-2 and-3. Int. J. Appl. Earth Obs. Geoinf. 2013 ,23, 344–351. [CrossRef]\\n52. Cho, H.J.; Lu, D. A water-depth correction algorithm for submerged vegetation spectra. Remote Sens. Lett.\\n2010 ,1, 29–35. [CrossRef]\\n53. Liew, S.C.; Chang, C.W. Detecting submerged aquatic vegetation with 8-band WorldView-2 satellite images.\\nIn Proceedings of the 2012 IEEE International Geoscience and Remote Sensing Symposium (IGARSS), Munich,\\nGermany, 22–27 July 2012; pp. 2560–2562.\\n©2019 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access\\narticle distributed under the terms and conditions of the Creative Commons Attribution\\n(CC BY) license (http: //creativecommons.org /licenses /by/4.0/).'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "NivPMpnyM57Z",
        "outputId": "3117b5ef-ea25-474c-8b5b-26ebcbf72be1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'remote sensing  \\nArticle\\nThe Global Mangrove Watch—A New 2010 Global\\nBaseline of Mangrove Extent\\nPete Bunting1,*\\n, Ake Rosenqvist2, Richard M. Lucas1,3, Lisa-Maria Rebelo4\\n,\\nLammert Hilarides5, Nathan Thomas6, Andy Hardy1\\n, Takuya Itoh7,\\nMasanobu Shimada8and C. Max Finlayson9\\n1Department of Geography and Earth Sciences, Aberystwyth University, Aberystwyth SY23 3DB, UK;\\nrichard.lucas@aber.ac.uk (R.M.L.); ajh13@aber.ac.uk (A.H.)\\n2Solo Earth Observation (soloEO), Tokyo 104-0054, Japan; ake.rosenqvist@soloEO.com\\n3School of Biological, Earth and Environmental Sciences (BEES), University of New South Wales (UNSW),\\nHigh Street, Kensington, NSW 2052, Australia\\n4International Water Management Institute, Regional Office for SE Asia and The Mekong,\\nP.O. Box 4199, Vientiane; l.rebelo@cgiar.org\\n5Wetlands International, 6700AL Wageningen, The Netherlands; Lammert.Hilarides@wetlands.org\\n6Earth System Science Interdicsiplinary Center, University of Maryland/NASA Goddard Space Flight Center,\\nCollege Park, MD 20742, USA; nathan.m.thomas@nasa.gov\\n7Remote Sensing Technology Center of Japan (RESTEC), Tsukuba Office, Ibaraki 305-8505, Japan;\\nitoh_takuya@restec.or.jp\\n8School of Science and Engineering, Tokyo Denki University, Saitama 350-0394, Japan;\\nshimada@g.dendai.ac.jp\\n9Institute for Land, Water and Society, Charles Sturt University, Albury, NSW 2640, Australia;\\nmfinlayson@csu.edu.au\\n*Correspondence: pete.bunting@aber.ac.uk; Tel.: +44-1970-622615\\nReceived: 31 July 2018 ; Accepted:18 October 2018; Published: 22 October 2018\\n/gid00030/gid00035/gid00032/gid00030/gid00038/gid00001/gid00033/gid00042/gid00045 /gid00001\\n/gid00048/gid00043/gid00031/gid00028/gid00047/gid00032/gid00046\\nAbstract: This study presents a new global baseline of mangrove extent for 2010 and has been\\nreleased as the first output of the Global Mangrove Watch (GMW) initiative. This is the first study\\nto apply a globally consistent and automated method for mapping mangroves, identifying a global\\nextent of 137,600 km2. The overall accuracy for mangrove extent was 94.0% with a 99% likelihood that\\nthe true value is between 93.6–94.5%, using 53,878 accuracy points across 20 sites distributed globally.\\nUsing the geographic regions of the Ramsar Convention on Wetlands, Asia has the highest proportion\\nof mangroves with 38.7% of the global total, while Latin America and the Caribbean have 20.3%,\\nAfrica has 20.0%, Oceania has 11.9%, North America has 8.4% and the European Overseas Territories\\nhave 0.7%. The methodology developed is primarily based on the classification of ALOS PALSAR\\nand Landsat sensor data, where a habitat mask was first generated, within which the classification\\nof mangrove was undertaken using the Extremely Randomized Trees classifier. This new globally\\nconsistent baseline will also form the basis of a mangrove monitoring system using JAXA JERS-1\\nSAR, ALOS PALSAR and ALOS-2 PALSAR-2 radar data to assess mangrove change from 1996 to\\nthe present. However, when using the product, users should note that a minimum mapping unit\\nof 1 ha is recommended and that the error increases in regions of disturbance and where narrow\\nstrips or smaller fragmented areas of mangroves are present. Artefacts due to cloud cover and the\\nLandsat-7 SLC-off error are also present in some areas, particularly regions of West Africa due to the\\nlack of Landsat-5 data and persistence cloud cover. In the future, consideration will be given to the\\nproduction of a new global baseline based on 10 m Sentinel-2 composites.\\nKeywords: mangrove; extent; global; baseline; mapping; ALOS PALSAR; landsat; ramsar; global\\nmangrove watch; K&C\\nRemote Sens. 2018,10, 1669; doi:10.3390/rs10101669 www.mdpi.com/journal/remotesensingRemote Sens. 2018,10, 1669 2 of 19\\n1. Introduction\\nMangroves are forested wetlands that are uniquely adapted to the intertidal zone. Found in the\\ncoastal zones of more than 118 countries in the tropics, subtropics and temperate regions [1–3],\\nmangroves have (for centuries) provided natural resources to local populations, including food\\n(particularly fish and invertebrates) and timber. However, through processes such as population\\nincreases, industrialisation, urban expansion and globalisation, their extent has been reduced [ 4] and\\nmany have been fragmented or degraded [ 5], particularly in Southeast Asia, where about one third\\n(32%) of the world’s mangroves are located [ 6]. Many of the mangrove areas that have remained\\nrelatively intact are those that are remote, inaccessible, protected within conservation reserves or\\nreceive national protection, for example in Australia. Globally, mangroves are being increasingly\\naffected by climatic fluctuations, including those induced by human activities [ 5]. At the same\\ntime, mangroves are receiving greater recognition for their role in food provision, coastal protection\\n(e.g., from large storms), reserves of biodiversity [ 7] and as a large carbon store [ 8]. Hence, there are\\nnumerous and increasing efforts to ensure protection and restoration across their range. A fundamental\\nrequirement for mangrove protection and restoration is information about current and historical\\nmangrove distributions and conditions. While critical for informing efforts that support conservation,\\nsustainable management, and restoration of these ecosystems, data on mangrove status and extent\\nare necessary to meet reporting requirements for signatories to the Ramsar Convention on Wetlands\\nand other countries with mangroves in their territories who are striving to meet the Sustainable\\nDevelopment Goals [5,9].\\nAt a global level, maps of mangrove extent have previously been generated by Spalding et al. for\\n1960–1996 [ 3] and 1999–2003 [ 2], by curating the best available national and regional maps, and by\\nthe United States Geological Survey (USGS; [ 1]) for 2000, based on the classification of Landsat sensor\\ndata primarily from 1997–2000. The FAO [ 4,10,11] have also conducted surveys to estimate global\\nextent for 1980, 1990 and 2000 and, in the later studies, both the FAO and Spalding et al. [2]referred\\nto the 2000 Giri et al. [1] to fill in gaps in coverage. The map of Giri et al. [1]has been regarded as the\\nmost globally consistent because of the standardised use of Landsat sensor data and methodology\\nwithin a defined period but, in some cases, the contribution of local to regionally-derived maps\\nto Spalding et al. [2] results in better mapping (depending on the scales and methods used). Hence,\\nwhilst the maps of mangrove area are broadly in agreement, many differences exist in terms of area\\nand boundary locations with these sometimes exaggerated by differences in accuracy in the geometric\\nlocation, scale and generalisation of the map products. The maps generated are also historical (currently\\nby at least two decades) and are unable to be easily updated and certainly not on a regular (e.g., annual)\\nbasis. Rates of mangrove loss can also then not be determined as the products from different years are\\nbased on different methods.\\nTo address the need for timely information on mangroves at a global level, the Japan Aerospace\\nExploration Agency (JAXA) Kyoto & Carbon (K&C) Initiative formulated the Global Mangrove Watch\\n(GMW), which aimed to produce consistent 25 m spatial resolution maps of mangrove extent across\\ntheir range by generating a baseline map for 2010. For mapping, Japanese L-band Synthetic Aperture\\nRadar (SAR) data were considered most appropriate given their global coverage and sensitivity\\nto the woody components of mangroves [ 12]. However, a limitation is that mangroves are often\\ndifficult to distinguish from other land covers (particularly forests and plantations) on the landward\\nmargins. For this reason, Landsat sensor data were integrated into the analysis to improve the baseline\\nmap. The mapping was also confined to locations with conditions considered suitable to support\\nmangroves. The objective of the GMW is to provide the information needed by a wide range of users,\\nincluding wetland and forest managers, civil society organisations, contracting partners of the Ramsar\\nConvention, and countries with mangroves in their territories.\\nMany studies have used Earth Observation (EO) data to map mangrove extent. At a global level,\\nthe study of Giri et al. [1]was the first, with this using an unsupervised classification approach and\\nmanual selection of classes associated with mangroves. Many studies have used the Giri et al. [1]Remote Sens. 2018,10, 1669 3 of 19\\nproduct as a basis for further analysis. For example, Hamilton and Casey [13]intersected the\\nGiri et al. [1] map with the forest cover change of Hansen et al. [14]to assess changes in mangrove\\nextent. Thomas et al. [6]was the first to consider L-band SAR for global assessment of mangrove\\nchange, which was assessed visually by on a 1\\x0e\\x021\\x0egrid overlain onto a composite of Japanese Earth\\nResources Satellite (JERS-1) SAR from 1996 and Advanced Land Observing Satellite (ALOS PALSAR)\\ndata from 2007 and 2010. Causes of change were also reviewed based on features including shape and\\ncontext. Other studies have been more focused on local sites, such as a single delta (e.g., the Mangoky\\nRiver delta, Madagascar [ 15], Mekong Delta, Vietnam [ 16]) or countries (e.g., Mozambique [ 17],\\nPhilippines’ [ 18], Kenya [ 19], and Mexico [ 20]). Methods adopted have varied. The majority have\\nused optical (primarily Landsat) datasets (e.g., [ 15,17–19]), while a few have fused optical and SAR\\ndata (e.g., [ 21,22]). In terms of analysis, a broad range of techniques have been used, including object\\norientated methods making use of image segmentation (e.g., [ 23]), rule based classifiers (e.g., [ 21]),\\nunsupervised classifiers (e.g., [ 17,18,24]) and machine learning methods (e.g., [ 22,23]). While there\\nis no clear dominant direction in terms of methodology for assessing mangrove extent, a significant\\ngap is the lack of studies that have sought to develop and apply a single consistent methodology that\\nis repeatable over large geographic areas, including at the global level. Therefore, this study aims to\\nprovide a new updated baseline of global mangrove extent, which can be used as a basis for studying\\nmangrove change and uses a single globally consistent methodology.\\n2. Methods\\nThe new global mangrove baseline has been generated using a combination of Synthetic Aperture\\nRadar (SAR) from the Advanced Land Observing Satellite (ALOS) Phased-Array L-band Synthetic\\nAperture Radar (PALSAR) and optical satellite data from Landsat-5 Thematic Mapper (TM) and\\nLandsat-7 Enhanced TM (ETM+). The overall approach followed four stages: (a) extraction of a\\ncoastal water mask from the PALSAR data; (b) generation of a mangrove “habitat” layer that identified\\nareas that were actually or potentially able to support mangroves; (c) generation of an initial baseline\\nclassification using the PALSAR data only; and (d) refinement of the initial baseline classification using\\nLandsat sensor composites to improve the distinction of the landward border between mangroves and\\nother terrestrial land covers. A final quality assurance (QA) of the resulting baseline product was then\\nundertaken through visual assessment and, where appropriate, errors were corrected. An overview of\\nthe methods for producing the new mangrove baseline is shown in Figure 1.\\nUnless otherwise stated, all data processing was undertaken using the open source Remote\\nSensing and GIS Software Library (RSGISLib [ 25]), the KEA file format [ 26], the Scikit-Learn [ 27]\\nmachine learning library and scripted in python as outlined by Clewley et al. [28].\\n2.1. Datasets\\nUsing data acquired in 2010, a baseline map of mangrove extent was generated by integrating\\nALOS PALSAR and a composite of Landsat sensor data and referencing the 2000 Shuttle Radar\\nTopographic Mission (SRTM) 30 m Digital Elevation Model data and existing products delineating\\nshorelines, surface water occurrence and previous attempts to delineate global mangrove extents.\\nThese datasets are summarised in Table 1\\nFrom the global shoreline dataset, a global ocean regions dataset was derived to identify oceanic\\nwater bodies. The shoreline dataset was rasterised onto the same pixel grid as the ALOS PALSAR data\\nand oceanic water was defined as pixels that were 200 pixels ( \\x185000 m) from the defined shoreline.Remote Sens. 2018,10, 1669 4 of 19\\nMangrove BaselineCoastal MaskMangrove ‘Habitat’Mangrove Baseline (2010) #1Water OccurrenceBathymetryShoreline2010 PALSARExtremely Randomized Trees ClassiﬁcationDist. Giri et al Dist. Mangrove AtlasLat/LongDist. WaterDist. OceanElevationExtremely Randomized Trees ClassiﬁcationGiri 2000Mangrove AtlasDist. Shoreline2010 PALSARExtremely Randomized Trees ClassiﬁcationMangrove Baseline (2010) #22010 Landsat CompositeExtremely Randomized Trees ClassiﬁcationMerge into Global ProductQuality Assurance\\nFigure 1. Overview of the methodology for producing a global mangrove baseline. The numbers\\nreference the section number within the article, while the main flow of boxes indicate data dependency\\nbetween the stages (e.g., the coastal water mask is used to defined the mangrove habitat mask).\\nTable 1. Details of the datasets and sources used for this project.\\nDataset Period Resolution Source\\nALOS PALSAR 2010 25 m JAXA\\nLandsat TM and ETM+ 2009–2011 30 m USGS\\nShuttle Radar Topography Mission (SRTM) 2000 30 m NASA\\nWater Occurrence 1984–2016 30 m JRC [29]\\nGlobal Distribution of Mangroves USGS (v 1.3) 1997–2000 30 m Giri et al. [1]\\nWorld Atlas of Mangroves (v 1.1) 1999–2003 1:1,000,000 Spalding et al. [2]\\nGlobal Self-consistent Hierarchical\\nHigh-resolution Shorelines (v 2.3.5)- “Full Resolution’ [30,31]\\nGEBCO gridded bathymetry 2014 30 arc-seconds [32]\\nAll data were re-sampled or rasterised onto the same 0.8 arc-second pixel grid as the ALOS\\nPALSAR data. For the SRTM data cubic spline interpolation was used, while for other continuous data\\n(e.g., Landsat) a cubic convolution was applied and for categorical data nearest neighbour interpolation\\nwas used.\\n2.1.1. ALOS PALSAR\\nThe ALOS PALSAR dual polarisation (HH+HV) backscatter data used were provided by JAXA\\nas1\\x0e\\x021\\x0emosaic tiles. The nominal spatial resolution was 25 m (0.8 arc seconds) and data were\\nprovided in the WGS84 (EPSG:4326) coordinate system. The mosaics are openly available in the public\\ndomain (http://www.eorc.jaxa.jp/ALOS/en/palsar_fnf/fnf_index.htm). The processing undertaken\\nto produce the tiled mosaics is detailed in Shimada et al. [33]. Global mosaics from JERS-1 SAR, ALOS\\nPALSAR and ALOS-2 PALSAR-2 were available for 1996, annually from 2007 to 2010 and from 2015 to\\n2017. However, the 2010 mosaic was the most complete in terms of temporal consistency and spatial\\ncoverage and therefore was defined as the baseline (reference) year.\\n2.1.2. Landsat Composites\\nAlthough the ALOS PALSAR dual polarisation L-band SAR data provided a reasonable level\\nof discrimination of mangroves from other land cover types (particularly bare ground), there was\\nsome confusion with other wetland or forest types. This was particularly the case for certain\\ntypes of adjoining terrestrial forests and wetlands with similar structure to mangroves. However,\\nmangroves were distinct from many of these land covers within the Landsat sensor data, particularly inRemote Sens. 2018,10, 1669 5 of 19\\nthe near infrared and shortwave infrared wavelength regions. For this reason, composite images were\\ngenerated using Landsat sensor data acquired for 2010, although 2009 and 2011 images were also used,\\nwhere necessary, to provide sufficient imagery for the processing. In order to minimise the impact\\nof the Landsat 7 scan-line (SLC-off) error, which results in no-data striping in the imagery, Landsat 5\\ndata were primarily selected when available. To identify the scenes to download for each Landsat\\nrow/path, the following sequence of rules were applied:\\n1. Identify 10 Landsat 5 scenes with less than 10% cloud cover from 2010.\\n2. If less than 10 scenes available, then add Landsat 7 scenes with less than 10% cloud cover\\nfrom 2010.\\n3. If less than 5 scenes, then add Landsat 5 and 7 scenes from 2010 with less than 50% cloud up to a\\nmaximum of 15 scenes.\\n4. If less than 5 scenes, then extend time range to 2009–2011 and repeat Steps 1–3.\\nA total of 15,346 top-of-atmosphere Landsat scenes from 1766 row/paths were downloaded\\nusing the Google Cloud API (https://cloud.google.com/storage/docs/public-datasets/landsat).\\nThe images where processed to surface reflectance, cloud masked and topographically corrected using\\nthe “Atmospheric and Radiometric Correction of Satellite Imagery” (ARCSI [ 34]) software. ARCSI\\nderives a scene based aerosol optical depth (AOD) value using a dark object subtraction (DOS [ 35])\\nwhere a numerical inversion of the 6S [ 36] atmospheric model is applied to derive an AOD value\\nbased on the Blue wavelength. The 30 m (1 arc-second) SRTM elevation model was used to construct a\\nlook-up table (LUT) for correction with respect to elevation, which was applied subsequently to the\\ninput image to derive standardised (i.e., topographically corrected) reflectance using the approach\\nof Shepherd and Dymond [37]. The FMASK [ 38,39] cloud masking algorithm was applied for removal\\nof cloud and cloud shadow.\\nTo allow fusion with the ALOS PALSAR data, the resulting Landsat data were re-sampled,\\nusing cubic convolution, to match the 0.8 arc-second pixel grid of the ALOS PALSAR data. A maximum\\nNDVI compositing [ 40,41] processing chain was then applied using RSGISLib [ 25] at a project level\\n(see Section 2.2) to generate a single Landsat composite image corresponding with the project region\\ndefined using the ALOS PALSAR data.\\n2.2. Project Region Definition\\nTo undertake the processing, 128 project regions were defined that grouped the 1\\x0e\\x021\\x0etiles\\nsuch that: (a) no continuous area of mangroves was split by a project border; (b) the mangroves\\nwithin a project were considered to be contained within a similar bio-geographic region and (c) the\\ncomputational requirements of processing the projects were appropriate (i.e., balancing speed of\\nprocessing with available computing resource).\\nThe projects were defined by the union of Giri et al. [1]and Spalding et al. [2]datasets, where each\\nwere buffered by 0.1\\x0eand touching or overlapping polygons merged. The resulting polygons where\\nclustered using the approach outlined in Bunting et al. [42]where the minimum spanning tree was\\ncreated and edges with a length >0.5\\x0eor greater than 1 standard deviation of the edge lengths in\\nthe tree removed creating individual clusters. The resulting groups where then assessed, with small\\nregions merged into larger regions and large regions split when these were deemed too large for\\nefficient computational processing. This resulted in 131 project regions globally, although, for three,\\nthere were no ALOS PALSAR data and so they were excluded. The resulting 128 projects where\\nintersected with the 1\\x0e\\x021\\x0etile grid and grouped into 12 geographic regions (Figure 2) to create a\\nhierarchical numbering system.Remote Sens. 2018,10, 1669 6 of 19\\nFigure 2. GMW project regions: ( A) the 12 top level regions; and ( B) an example of the individual\\nprojects for the South American region.\\n2.3. Coastal Mask\\nMangroves are found within a coastal environment and therefore a key component of defining the\\nmangrove habitat mask was to define a coastal water mask. To achieve this, a water mask was defined\\nusing a per-pixel Extremely Randomized Trees classification using Scikit-Learn [ 27] and RSGISLib [ 25]\\nsoftware. The number of estimators for the Extremely Randomized Trees classifier was defined as 500\\nfollowing a grid search sensitivity analysis. The classification was performed using the ALOS PALSAR\\nHH and HV polarisations, the ratio of HH/HV, local incident angle and acquisition date.\\nThe key step in defining the coastal water mask was to define the training samples and regions\\nto be classified, which was performed automatically. An initial water mask was produced using a\\nthreshold of > 20water occurrences, and this was subsequently intersected with the oceanic region\\n(Section 2.1) to identify oceanic water. A coastal region was then defined as the area 20 pixels ( \\x18500 m)\\neither side of the shoreline with a bathymetry depth of > \\x00100m. Additional regions based on 80 pixels\\n(\\x182000 m) either side of the shoreline and a water occurrence < 80were added to this mask, with this\\nthen defining the region to be classified. 100,000 training pixels were then extracted randomly for land\\nand water from regions between > 20(\\x18500 m) and < 80(\\x182000 m) pixels away from the shoreline,\\nwith this defined as water or land using the water mask retrieved from the water occurrence layer.\\nFollowing the classification, a refinement was performed to remove small features, which required\\nclumping the classification to identify connected regions of a single class. Clumps classified as\\nland with an area of < 20pixels ( \\x1812,500 m2) and > 20water occurrence observations were assigned\\nto the water class, while water regions with an area of < 50pixels ( \\x1831,250 m2) were assigned to\\nland. These thresholds were identified through a sensitivity analysis and by visually assessing the\\nresulting maps.Remote Sens. 2018,10, 1669 7 of 19\\nThe thresholds used for generating the coastal mask were identified through an iterative sensitivity\\nanalysis based on a visual inspection of the resulting maps for a number of projects and sites globally\\nrepresenting a range of mangrove habitats.\\n2.4. Mangrove Habitat\\nMangroves exist within a specific ecological niche, which can be used to eliminate much of the area\\nwhere they will not be found. To define the region to be classified, and from which the non-mangrove\\npixels were selected, the following rules were defined, applied on a per-project basis. First, the SRTM\\nelevation needed to be less than 110% of the 99th percentile of the elevation of mangrove pixels. If the\\nresulting threshold was less than 5 m the threshold was set to 30 m, remembering that the SRTM is a\\nsurface model and therefore includes a component of vegetation height. The second rule, defined that\\nthe distance from the coastal water mask needed to be less than 110% of the 99th percentile of the\\ndistance of the mangrove pixels.\\nWithin the region defined above, a classification was subsequently performed. In total, 100,000\\nmangrove training pixels were randomly extracted from a union of the existing global mangrove\\nmaps from Giri et al. [1] and Spalding et al. [2], while 100,000 non-mangrove training samples were\\nrandomly extracted from within the region but outside of the mangrove union. If less than 100,000\\nmangrove pixels were available, then the number of samples selected for both classes was equal to the\\nnumber of mangrove pixels within the project.\\nThe classification was performed using the Extremely Randomized Trees classifier,\\nwith 100 estimators, defined through the use of a grid search sensitivity analysis of classifier\\nparameters. The input variables to the classification were: (a) pixel longitude and latitude; (b) distance\\nto water (defined using the coastal mask); (c) surface elevation defined by the SRTM; (d) distance to\\nthe oceanic layer; and (e) distances to the mangrove extents of Giri et al. [1]and Spalding et al. [2].\\nThe resulting habitat mask was visually checked and missing regions, including those that were not\\nidentified in the Giri et al. [1] and Spalding et al. [2] products, were added manually.\\nThe mangrove habitat layer (to be available at http://www.globalmangrovewatch.org) defines\\nthe maximum possible extent of mangrove habitat and therefore would not be needed to re-calculated\\nfor any subsequent mangrove mapping efforts.\\n2.5. Baseline Classification\\nThe new baseline was classified in two independent steps: first using the ALOS PALSAR and then\\nthe Landsat data. The ALOS PALSAR data were geographically contained entirely within the projects,\\nwhich allowed complete classification, but there were occasional gaps in the coverage of the Landsat\\nsensor data primarily because of cloud cover. In these gaps, the classification was based solely on the\\nALOS PALSAR data.\\n2.5.1. Classification: ALOS PALSAR\\nThe classification was undertaken using the Extremely Randomized Trees classifier, based on\\n100 estimators that were also defined through a grid search sensitivity analysis. The input variables\\nwere ALOS PALSAR HH and HV data (transformed to log unit dB), the ratio of HH/HV, pixel longitude\\nand latitude and the mangrove probability. Mangrove probability was defined using the union of\\nmangrove extent and generating a multi-dimensional histogram for the HH, HV and HH/HV data for\\nmangroves (defined using Giri et al. [1]) with a bin width of 0.25. The histogram was converted to a\\nprobability distribution function, which was used to calculate a probability of mangroves occurring in\\neach pixel.\\nTraining samples where defined through random sampling where 100,000 mangrove and\\nnon-mangrove samples were taken, resulting in 200,000 in total per project. For mangrove, 20,000\\nsamples were extracted from the intersection of the Giri et al. [1]and Spalding et al. [2]products and\\nthe remaining 80,000 were taken from the union of the two products. The non-mangrove samples wereRemote Sens. 2018,10, 1669 8 of 19\\nalso split, with 20,000 from within the habitat mask and 80,000 outside. The region outside the habitat\\nmask, within which training samples were selected, was defined as < 150pixels ( \\x183750 m) from the\\nunion of the mangrove products over areas of water and < 250pixels ( \\x186250 m) over terrestrial areas.\\nThe training points were visually checked and edited with reference to Google Earth Imagery as well\\nas the ALOS PALSAR and Landsat sensor imagery. In total, 20 M training points were defined globally\\nacross the 128 projects.\\n2.5.2. Classification: Landsat\\nUsing only a classification of ALOS PALSAR data, a consistent over-classification of the area of\\nmangroves was observed with this attributed to similarities in the structure and moisture content\\nof wetlands and forest cover types (indicated earlier). Therefore, a further refinement using optical\\nimagery was deemed necessary. The second classification iteration used the same training samples\\nas the ALOS PALSAR classification but samples without valid Landsat sensor data were removed.\\nUsing the Blue, Green, Red, Near-Infrared (NIR), Shortwave Infrared 1 (SWIR1) and SWIR2 spectral\\nbands, the Extremely Randomized Trees classifier, again using 100 estimators identified through a\\nsensitivity analysis, was applied to generate the final classification.\\n2.6. Merging into a Global Product\\nThe resulting project based analysis was compiled into a single global product for 2010 on a\\n1\\x0e\\x021\\x0etile basis. A few project regions shared individual tiles and these needed to be merged,\\nwhich was undertaken using a union operation.\\n2.7. Quality Assurance\\nFollowing the automated analysis, an extensive quality assurance (QA) process was undertaken.\\nDuring this process, the product was visually checked against the ALOS PALSAR and Landsat sensor\\ndata as well as contemporary (2010) Google Earth imagery. Where significant errors of omission and\\ncommission were identified, polygons were drawn and edits applied.\\n2.8. Accuracy Assessment\\nTo assess the overall accuracy of the product, a point-based accuracy assessment was undertaken.\\nFor the accuracy assessment, a stratified random sample was undertaken within each project using the\\nwater, mangrove and terrestrial non-mangrove classes, within a 50 pixels ( \\x181250 m) buffer from the\\nmangrove regions and within the mangrove habitat region. The number of accuracy samples, for each\\nclass, was 0.5% of the number of mangrove pixels, unless the resulting number of samples was less\\nthan 1000 in which case a 1% sample was taken.\\nWithin the projects, sites were selected (Figure 3 and Table 2) based on available local knowledge\\nand in some cases high resolution data. The accuracy assessment was undertaken using a custom\\nQGIS plugin that guides the operator to each point, providing a simple interface to decide between\\nclasses. The imagery used for reference included high resolution Google Earth imagery, custom high\\nresolution imagery, GMW Landsat image composites and ALOS PALSAR 2010 data.\\nTable 2. Regions where the accuracy assessment was undertaken and the number of accuracy samples\\nwhich were used.\\nSite Number Points\\nAustralia 4347\\nFiji 6487\\nHaiti 1356\\nIndonesia (1) 1343\\nIndonesia (2) 3717Remote Sens. 2018,10, 1669 9 of 19\\nTable 2. Cont.\\nSite Number Points\\nIndonesia (3) 144\\nJapan/Okinawa 2742\\nMexico (1) 6948\\nMexico (2) 2167\\nMyanmar 1106\\nPapua New Guinea 854\\nSamoa 90\\nSaudi Arabia 339\\nIndia 910\\nTanzania (Rufiji Delta) 3449\\nTonga 72\\nUSA (Mississippi Delta) 4590\\nUSA (West Florida) 5615\\nVenezuela 1793\\nVietnam 5809\\nTotal 53,878\\nVersion September 8, 2018 submitted to Remote Sens. 9 of 19\\nTable 2. Regions where the accuracy assessment was undertaken and the number of accuracy samples\\nwhich were used.\\nSite Number Points\\nAustralia 4347\\nFiji 6487\\nHaiti 1356\\nIndonesia (1) 1343\\nIndonesia (2) 3717\\nIndonesia (3) 144\\nJapan/Okinawa 2742\\nMexico (1) 6948\\nMexico (2) 2167\\nMyanmar 1106\\nPapua New Guinea 854\\nSamoa 90\\nSaudi Arabia 339\\nIndia 910\\nTanzania (Rufiji Delta) 3449\\nTonga 72\\nUSA (Mississippi Delta) 4590\\nUSA (West Florida) 5615\\nVenezuela 1793\\nVietnam 5809\\nTotal 53878\\n-20-20002020-180\\n-180-160\\n-160-140\\n-140-120\\n-120-100\\n-100-80\\n-80-60\\n-60-40\\n-40-20\\n-200\\n020\\n2040\\n4060\\n6080\\n80100\\n100120\\n120140\\n140160\\n160180\\n180\\nFigure 3. Distribution of sites used to undertake the accuracy assessment.\\n(23.4◦S). Asia is estimated to account for 38.7 % of the world’s mangroves, with Southeast Asia alone 294\\nrepresenting almost a third (32.2 %). The Americas are estimated to comprise 28.7 %, and Africa and 295\\nOceania 20.0 % and 11.9 %, respectively. European Overseas Territories account for 0.7 %. 296\\nTable 3 shows the extent of mangroves for the six Ramsar regions, Asia is the region with the 297\\nlargest area of mangroves (53,278 km2) with Latin America and the Caribbean (previously referred to 298\\nas the Neotropics) (27,940 km2) and Africa (27,465 km2) regions having the similar amounts. While 299\\nin terms of individual countries (Table 4) Indonesia contain 19.5 % of the worlds mangroves and the 300\\nnext three highest, by area, Brazil, Australia and Mexico combined contain 22.3 %. 301\\n3.2. Accuracy Assessment 302\\nThe overall accuracy (Table 5) of the classification was 95.3 %, with a 99 % likelihood that 303\\nthe confidence interval, using the Wilson score interval [43], was between 4.5–5.0 %. Therefore, 304\\nthe overall accuracy was in the range 95.0–95.5 %. 53,878 sample points (Table 2) were used for 305\\nthe accuracy assessment, where the points were manually allocated to the classes of mangroves, 306\\nwater and terrestrial (other). In terms of mangroves, the main confusion was with other terrestrial 307\\nFigure 3. Distribution of sites used to undertake the accuracy assessment.\\n3. Results\\n3.1. Mangrove Baseline\\nThe resulting baseline map of global mangrove extent gives an estimated total mangrove area\\nin 2010 of 137,600 km2. A Mollweide Equal Area projection was used for all area calculations.\\nFigure 4 illustrates the global distribution of mangroves, which can be found as far north as 32.3\\x0eN\\n(Bermuda) and as far south as 38.9\\x0eS (Australia). Figure 5 illustrates the spatial detail within the\\nmap. Approximately 96% are found between the Tropic of Cancer ( 23.4\\x0eN) and Tropic of Capricorn\\n(23.4\\x0eS). Asia is estimated to account for 38.7% of the world’s mangroves, with Southeast Asia alone\\nrepresenting almost a third (32.2%). The Americas are estimated to comprise 28.7%, and Africa and\\nOceania 20.0% and 11.9%, respectively. European Overseas Territories account for 0.7%.\\nTable 3 shows the extent of mangroves for the six Ramsar regions. Asia is the region with the\\nlargest area of mangroves (53,278 km2) with Latin America and the Caribbean (previously referred to\\nas the Neotropics) (27,940 km2) and Africa (27,465 km2) regions having similar amounts. In terms of\\nindividual countries (Table 4), Indonesia contains 19.5% of the worlds mangroves and the next three\\nhighest, by area, Brazil, Australia and Mexico combined contain 22.3%.\\n3.2. Accuracy Assessment\\nThe overall accuracy (Table 5) of the classification was 95.3%, with a 99% likelihood that the\\nconfidence interval, using the Wilson score interval [ 43], was 4.5–5.0%. Therefore, the overall\\naccuracy was in the range 95.0–95.5%. In total, 53,878 sample points (Table 2) were used for the\\naccuracy assessment, where the points were manually allocated to the classes of mangroves, water andRemote Sens. 2018,10, 1669 10 of 19\\nterrestrial (other). In terms of mangroves, the main confusion was with other terrestrial vegetation,\\ndemonstrating that 97.5% of the areas classified as mangroves were correct with the confusion resulting\\nin a producers accuracy of 94.0%. Therefore, there is a 99% likelihood that the confidence interval for\\nthe overall mangrove accuracy was between 93.6–94.5%.\\nFigure 4. GMW mangrove baseline for 2010 and distribution of mangroves in longitude and latitude\\n(WGS-84; epsg:4326).\\nFigure 5. Example GMW v2.0 maps, using the Open Street Map (https://www.openstreetmap.org) data\\nas background mapping. From west to east: ( A) Central America (Honduras/Nicaragua); ( B) Africa\\n(Madagascar); and ( C) Australia (Queensland). The maps are presented in WGS-84 (epsg:4326) with\\ncoordinates in decimal degrees (valid for all figures below).\\nTable 3. GMW v2.0 baseline extents for the six Ramsar regions.\\nRegion GMW v2.0 (km2) Percentage of Global (%)\\nAfrica 27,465 20.0\\nAsia 53,278 38.7\\nEurope (Overseas Territories) 1026 0.7\\nLatin America and the Caribbean 27,939 20.3\\nNorth America 11,563 8.4\\nOceania 16,329 11.9\\nTotal 137,600\\nThe most common errors observed within the GMW baseline are associated with fine-scale\\nfeatures (e.g., riverine, aquaculture and fine coastal fringes; Figure 6), which was particularly the\\ncase for areas with a high degree of anthropogenic fragmentation. As the minimum feature size of\\nobjects identifiable within the ALOS PALSAR and Landsat sensor data encompassed multiple pixels,Remote Sens. 2018,10, 1669 11 of 19\\na recommended minimum mapping unit of 1 ha (i.e., 8 pixels) for reliable mapping is considered to be\\nthe most appropriate for end users.\\nTable 4. GMW v2.0 baseline extents for the world’s Top 10 countries with mangroves.\\nCountry GMW v2.0 (km2) Percentage of Global (%)\\nIndonesia 26,890 19.5\\nBrazil 11,072 8.1\\nAustralia 10,060 7.3\\nMexico 9537 6.9\\nNigeria 6958 5.1\\nMalaysia 5201 3.8\\nMyanmar 5011 3.6\\nPapua New Guinea 4762 3.5\\nBangladesh 4163 3.0\\nIndia 3521 2.6\\nTable 5. Accuracy assessment of the GMW v2.0 baseline.\\nMangroves Water Terrestrial Other User’s\\nMangroves 18,246 98 370 97.5%\\nWater 191 16,463 101 98.3%\\nTerrestrial Other 969 828 16,612 90.2%\\nProducer’s 94.0% 94.7% 97.2% 95.3%\\nFigure 6. Anthropogenic disturbance near Surabaya in Eastern Java, Indonesia. The background\\nimagery is the 2010 Landsat composite generated for this study, visualised using the NIR, SWIR and\\nRed wavelength bands. ( A) The Landsat composite, where the mangroves appear orange within the\\nband combination: and ( B) the Landsat composite with the GMW v2.0 baseline displayed over the top,\\nin green.\\n3.3. Comparison to Existing Maps\\nAlthough the time period for which they refer and methodology for production differ,\\na comparison between the GMW 2010 baseline and the 2000 Giri et al. [1](1997–2000) and\\nSpalding et al. [2] (1999–2003) datasets was undertaken (Table 6) for the six Ramsar regions.\\nThe Giri et al. [1] and Spalding et al. [2]datasets both represent a period of around 2000 while the\\nGMW product is for 2010 so some differences in area were expected. Although the global total\\nestimates of the 2010 GMW v2.0 baseline and the 2000 Giri et al. [1]datasets are very close (137,600Remote Sens. 2018,10, 1669 12 of 19\\nversus 137,760 km2), significant differences (>10%) between the datasets can be observed at a regional\\nlevel that are unlikely to be attributed to actual changes. These differences are, in part, due to errors\\nand missing regions in the products (e.g., Figure 7).\\n-0.50-0.75103.25103.25\\n103.50103.50\\n103.75103.75\\n103.25103.25\\n103.50103.50\\n103.75103.75\\n-0.50-0.75103.25103.25\\n103.50103.50\\n103.75103.75ABC\\nFigure 7. Riau/Jambi in Sumatra, Indonesia: ( A) GMW v2.0 baseline; ( B) Giri et al. [1]; and\\n(C) Spalding et al. [2] , illustrating differences between the three datasets. Background maps: Open\\nStreet Map (https://www.openstreetmap.org).\\nVisually, there is often a high degree of similarity between the products (see, for example, Figure 8).\\nHowever, numerical comparison of the Giri et al. [1]and Spalding et al. [2]products demonstrated\\nsignificant differences between these two products where, for instance, the global estimates of\\nmangrove extent equate to 137,760 km2versus 152,361 km2, respectively. The corresponding FAO [11]\\nestimates for 2000 and 2005 are 157,400 km2and 152,310 km2, respectively. This highlights a\\nsignificant uncertainty in our knowledge of global mangrove extent. Through a visual comparison, it\\nis considered that Spalding et al. [2]often overestimates the overall mangrove extent (e.g., Figure 9),\\nalthough there are also regions of missing data (e.g., Figure 7). At a regional scale, the errors\\nassociated with the Spalding et al. [2]dataset are relatively clear. For instance, the Spalding et al. [2]\\ndataset demonstrates that the region covering Latin America and the Caribbean accounts for 23.1%\\nof the World’s mangroves compared with 20.3% denoted by the GMW v2.0 baseline. Similarly,\\nthe Spalding et al. [2] dataset demonstrates that the Oceania region accounts for 7.7% of the world’s\\nmangroves, compared to 11.9% that is denoted in this study and in the Giri et al. [1] dataset.\\nTable 6. Mangrove extent comparison for the six Ramsar regions between the GMW v2.0 baseline,\\nGiri et al. [1] (v1.3; released 2015) and Spalding et al. [2](v2.0; released 2017). Figures for the latter\\ntwo were calculated from datasets downloaded from the UN Ocean Data Viewer (http://data.unep-\\nwcmc.org), and thus differ marginally from figures published by Giri et al. [1]and Spalding et al. [2]\\n(in brackets). It should be recognised that the comparison between these products should not be used\\nto infer changes in mangrove extent, as the differences rather can be considered to be predominately\\ndue to the mapping methodology and accuracy.\\nRegionGMW v2.0 (km2)\\n2010Giri et al. [1] (km2)\\n1997–2000Spalding et al. [2] (km2)\\n1999–2003\\nAfrica 27,465 (20.0%) 26,342 (19.1%) 31,149 (20.5%)\\nAsia 53,278 (38.7%) 55,068 (40.0%) 60,435 (39.7%)\\nEurope (Overseas Terr.) 1026 (0.7%) 1427 (1.0%) 1194 (0.8%)\\nLatin America and the Caribbean 27,939 (20.3%) 28,643 (20.8%) 35,113 (23.1%)\\nNorth America 11,563 (8.4%) 9739 (7.1%) 12,492 (8.2%)\\nOceania 16,329 (11.9%) 16,380 (11.9%) 11,735 (7.7%)\\nTotal 137,600 137,599 (137,760) 152,118 (152,361)Remote Sens. 2018,10, 1669 13 of 19\\n4.254.00117.25117.25\\n117.50117.50\\n117.75117.75\\n117.25117.25\\n117.50117.50\\n117.75117.75\\n4.254.00117.25117.25\\n117.50117.50\\n117.75117.75ABC\\nFigure 8. Border of North Kalimantan, Indonesia, and Sabah, Malaysia, illustrating a typical region\\nwith good correspondence between the GMW v2.0 baseline and the Giri et al. [1]andSpalding et al. [2]\\nproducts: ( A) GMW v2.0 baseline; ( B) Giri et al. [1]; and ( C) Spalding et al. [2]. Background maps:\\nOpen Street Map.\\n13.40\\n-87.50-87.50\\n-87.45-87.45\\n-87.50-87.50\\n-87.45-87.45\\n13.40\\n-87.50-87.50\\n-87.45-87.45ABC\\nFigure 9. Atlántico Norte, Nicaragua: ( A) GMW v2.0 baseline; ( B) Giri et al. [1]; and ( C) Spalding et al. [2],\\nillustrating a region where the Spalding et al. [2]is generalised and overestimates the mangroves extent\\ncompared to Giri et al. [1]and the GMW v2.0 baseline. In this example, the Giri et al. [1]product has\\nmore detail than the GMW v2.0 baseline. Background maps: Open Street Map.\\n4. Discussion\\n4.1. Methods of Mapping Mangroves\\nOur results have yielded an updated global mangrove baseline, with an accuracy in excess of 90%.\\nThis new global baseline represents an improvement on existing global maps (e.g., Giri et al. [1]) for\\nmany regions across the world. This includes the successful mapping of mangroves for areas that were\\nfound to be absent in other existing products (e.g., Figure 7). The method made use of the existing\\nGiri et al. [1] and Spalding et al. [2]datasets to automatically generate classifier training samples that\\nwere subsequently visually checked. This approach produced a new mangrove extent yielding a total\\narea approximately equal to that of Giri et al. [1], while displaying significant regional variations. It\\nshould be noted that, due to the methodological differences in the generation of the GMW, Giri et al. [1]\\nand Spalding et al. [2]datasets, they cannot be used to infer indications of changes between their\\nrespective baseline years. The majority of mangrove area can be found in Asia, as identified by Giri\\net al. [1], with an approximately equal proportion distributed between Africa and Latin America and\\nthe Caribbean.\\nThis mangrove baseline was derived using publicly open imagery from the ALOS PALSAR and\\nLandsat sensors. These sensors are complimentary and were used in combination to achieve theRemote Sens. 2018,10, 1669 14 of 19\\nupdated baseline. The radar and optical imagery measure different properties of the forest and\\nwere used together to attain the baseline with high accuracy. The optical data is sensitive to the\\nbio-chemical (e.g., photosynthesis) properties of the forest and the radar is sensitive to the physical\\n(e.g., woody biomass) of the forest. In combination, these provide a more complete description of the\\nforest than from one dataset alone. The ALOS PALSAR data have the advantages of being cloud-free\\nand therefore each path is a consistent date rather than composited from a number of dates as with the\\nLandsat sensor data. This study also benefited from the availability of a number of additional global\\ndatasets, such as the water occurrence dataset [ 29] and shorelines [ 30,31], bathymetry [ 32] and the\\nSRTM elevation model.\\nThe study has produced a new baseline of global mangrove extent for 2010. The date of the\\nbaseline was driven by the availability of the ALOS PALSAR data, which was most complete for\\n2010. However, the availability of Landsat data in 2010 is poor with Landsat 5 TM data not available\\nglobally, with particular sparsity of data throughout Africa. The Landsat 7 ETM+ suffered with the\\nSLC-off failure (Figure 10). Given the importance of the Landsat sensor data to the classification of\\nmangroves, future studies would be recommended to prioritise the availability of suitability optical\\ndata (i.e., Landsat-8 and Sentinel-2). Additionally, the increased spatial resolution (10 m) of Sentinel-2\\nis expected to improve the mapping of fine features (e.g., riverine, aquaculture and fine coastal fringes)\\nand disturbed areas where the error in the GMW v2.0 baseline are highest.\\nFigure 10. Douala, Cameroon: ( A) the Landsat Composite; and ( B) the Landsat composite with\\nthe GMW v2.0 baseline overlaid in green, illustrating an area with poor Landsat coverage due to\\ncloud cover, lack of Landsat-5 data and influence of the Landsat-7 SLC-off artefact. The 2010 Landsat\\ncomposite generated for this study is visualised using the NIR, SWIR and Red wavelength bands.\\nThe updated baseline is able to suit the requirements and needs of policy and decision makers.\\nThese data are aimed to support a wide range of international initiatives and users, including wetland\\nmanagers, government bodies, civil society users and Ramsar Convention contracting parties.\\nAn up-to-date baseline is of critical importance for the inclusion of mangroves in these and future\\ninitiatives, such as REDD+. However, while a baseline is highly useful, the measurement of change in\\nmangrove extent using a consistent global methodology would be a very significant further advance\\nand direction for future work.\\n4.2. Forming a Monitoring System\\nThis Global Mangrove Watch map represents the extent and distribution for 2010, but is also a\\nbaseline from which a monitoring system can be built (Figure 11). Thomas et al. [22]demonstrated a\\nnovel “map-to-image” method to update mangrove baselines using time-series radar imagery with aRemote Sens. 2018,10, 1669 15 of 19\\nhigh degree of accuracy. By focussing on the mapping of changes away from the baseline, the trend in\\nchange is more consistent than comparing independently classified baselines. The “map-to-image”\\nmethod is also directly applicable at the global level and can be used to iteratively derive baselines\\nback in time using historical data and into the future with the continued acquisition of current\\nsensors and anticipated launch of future satellites. Being derived from, and therefore spatially\\nregistered to the ALOS PALSAR data, this new GMW v2.0 baseline constitutes an ideal basis for\\nsuch a monitoring system using the Japanese JERS-1 SAR (ca. 1996), ALOS PALSAR (2007–2010)\\nand ALOS-2 PALSAR-2 (2015–present) imagery, enabling maps of mangrove extent to be generated\\nfor a number of epochs. Data availability is expected to continue and increase into the future with\\nanticipated data from ALOS-4 PALSAR-3, as well as other globally available and near-future datasets\\n(e.g., Sentinel-1, SAOCOM-1A/1B, NISAR and Tandem-L). The global mangrove baseline detailed\\nin this paper, in combination with the novel “map-to-image” change detection technique outlined\\nin Thomas et al. [22], can therefore be used to used to form an operational global mangrove monitoring\\nsystem for driving policy and informing management decisions.\\nFigure 11. A flowchart of the proposed monitoring system which could be built on the 2010 GMW v2.0\\nbaseline using the methodology of Thomas et al. [22].\\n4.3. Cautions and Caveats\\nThe minimum size of mangrove region that is considered to be reliably identifiable within\\nthe ALOS PALSAR and Landsat sensor data are those than occupy multiple pixels and therefore\\na recommended minimum mapping unit of 1 ha (i.e., 8 pixels) for reliable mapping was used and\\nis advocated. Errors associated with the minimum feature size are particularly evident in areas of\\ndisturbance, such as around aquaculture ponds (e.g., Figure 12) as well as in riverine mangroves that\\nform narrow shoreline fringes.\\nThe Landsat image composites include artefacts (e.g., Figure 10) as a result of persistent cloud\\ncover and the Landsat-7 SLC-off error. This has particularly effected areas in West Africa (e.g., Niger\\nDelta and Cameroon) where cloud cover is frequent and Landsat-5 data were not available for 2010.\\nFuture work should focus on determining an optimal year for the production of an optical image\\ncomposite. For instance, data quality and availability is likely to be greater in the years after Landsat-8\\nwas launched (2013). Similarly, the availability of Sentinel-2 imagery (particularly since 2017 with\\nthe launch of Sentinel-2B) is considered a significant opportunity for further improvements, with a\\nresolution of 10 m aiding the mapping of smaller fringing and fragmented mangroves and the increased\\ntemporal resolution improves the quality of cloud-free composites.\\nThere are also some areas where mangroves are known to have been omitted in this version (v2.0)\\nof the GMW dataset, due to satellite data unavailability, including: Andaman and Nicobar Islands\\n(India), Bermuda (UK), Europa Island (France), Fiji, east of Anti-meridian, Guam and Saipan (USA),\\nKiribati, Maldives, Peru (south of latitude S4) and Wallis and Futuna Islands (France). While these\\nare not significant in terms of mangrove extent globally, which is the focus of this paper, they will be\\nincluded in the release of future GMW datasets.Remote Sens. 2018,10, 1669 16 of 19\\nVersion September 8, 2018 submitted to Remote Sens. 16 of 19\\nFigure 12. A drone photograph looking over part of the Xuân Th/uni1EE7y National Park, on the Red\\nRiver Delta, Vietnam (March 2018). The photograph illustrates an area of aquaculture with highly\\nfragmented mangroves.\\nthe launch of Sentinel-2B) is considered a significant opportunity for further improvements, with 412\\na resolution of 10 m aiding the mapping of smaller fringing features and the increase temporal 413\\nresolution aiding the generation of cloud free composites. 414\\nThere are also some areas where mangroves are known to have been omitted in this version 415\\n(v2.0) of the GMW dataset, due to satellite data unavailability, including: Andaman and Nicobar 416\\nIslands (India), Bermuda (U.K.), Europa Island (France), Fiji, east of Anti-meridian, Guam and Saipan 417\\n(U.S.A.), Kiribati, Maldives, Peru (south of latitude S4) and Wallis and Futuna Islands (France). While 418\\nthese are not significant in terms of mangrove extent globally, which is the focus of this paper, they 419\\nwill be included in the release of future GMW datasets. 420\\n5. Conclusions 421\\nThis study is the first to establish a global baseline map of mangrove extent from Earth 422\\nObservation data, using a globally consistent methodology that is automated and reproducible. To 423\\nproduce the baseline a series of steps were undertaken: a) classification of coastal water; b) definition 424\\nof mangrove habitat regions; c) classification of mangrove areas using the ALOS PALSAR data; d) 425\\nrefinement of the mangrove extent map using a classification of a Landsat composite and e) finally a 426\\nmanual quality assurance process was undertaken where edits where applied to improve the overall 427\\nquality of the mangrove extent map. The new global mangrove map represents an improvement on 428\\nexisting products and provides a basis for assessing change over all mangrove regions with a precision 429\\nof approximately 1 ha. 430\\nThe new global mangrove map demonstrated a high degree of accuracy with a 99 % likelihood 431\\nthat the confidence interval for the overall mangrove accuracy was between 93.6–94.5 %. The baseline 432\\nhas mapped 137,600 km2of mangroves with 38.7 % found in Asia, 20.3 % in Latin America and the 433\\nCaribbean, 20 % in Africa, 11.9 % in Oceania, 8.4 % in North America and 0.7 % in the European 434\\nOverseas Territories. This new globally consistent baseline can form the basis of an operational 435\\nmangrove monitoring system using the JAXA JERS-1 SAR, ALOS PALSAR and ALOS-2 PALSAR-2 436\\nto assess global mangrove change from 1996 to present, providing a valuable tool for policy makers 437\\nand land managers. 438\\nFigure 12. A drone photograph looking over part of the Xuân Th/uni1EE7y National Park, on the Red\\nRiver Delta, Vietnam (March 2018). The photograph illustrates an area of aquaculture with highly\\nfragmented mangroves.\\n5. Conclusions\\nThis study is the first to establish a global baseline map of mangrove extent from Earth Observation\\ndata, using a globally consistent methodology that is automated and reproducible. To produce the\\nbaseline, the following steps were undertaken: (a) classification of coastal water; (b) definition of\\nmangrove habitat regions; (c) classification of mangrove areas using the ALOS PALSAR data; (d)\\nrefinement of the mangrove extent map using a classification of a Landsat composite; and (e) a manual\\nquality assurance process where edits were applied to improve the overall quality of the mangrove\\nextent map. The new global mangrove map represents an improvement on existing products and\\nprovides a basis for assessing change over all mangrove regions with a precision of approximately 1 ha.\\nThe new global mangrove map demonstrated a high degree of accuracy with a 99% likelihood that\\nthe confidence interval for the overall mangrove accuracy was 93.6–94.5%. The baseline has mapped\\n137,600 km2of mangrove with 38.7% found in Asia, 20.3% in Latin America and the Caribbean, 20%\\nin Africa, 11.9% in Oceania, 8.4% in North America and 0.7% in the European Overseas Territories.\\nThis new globally consistent baseline can form the basis of an operational mangrove monitoring system\\nusing the JAXA JERS-1 SAR, ALOS PALSAR and ALOS-2 PALSAR-2 to assess global mangrove change\\nfrom 1996 to present, providing a valuable tool for policy makers and land managers.Remote Sens. 2018,10, 1669 17 of 19\\nAuthor Contributions: Conceptualisation, A.R., R.M.L., L.-M.R., M.S. and C.M.F.; Data curation, A.R., R.M.L.,\\nL.H., T.I. and M.S.; Funding acquisition, P.B. and L.H.; Methodology, P.B., A.R., R.M.L., N.T. and A.H.; Project\\nadministration, A.R.; Resources, L.H., T.I., M.S. and C.M.F.; Software, P.B. and N.T.; Validation, P.B., A.R., R.M.L.\\nand A.H.; Writing—Original draft, P.B. and A.R.; and Writing—Review and editing, P.B., A.R., R.M.L., L.-M.R.,\\nL.H., N.T. and A.H.\\nFunding: Funding was provided for this study through the “Mangrove Capital Africa” project funded by DOB\\nEcology and the RCUK NERC funded project “MOnitoring Mangrove ExteNT & Services (MOMENTS): What is\\ncontrolling Tipping Points?” as part of the Newton Fund (NE/P014127/1).\\nAcknowledgments: This project was undertaken in part within the framework of the JAXA Kyoto & Carbon\\nInitiative. JAXA and RESTEC are thanked for the provision of the SAR datasets used within this study.\\nSuperComputing Wales (SCW) are also thanked for supporting the project through the provision of the High\\nPerformance Computing (HPC) facility on which all the data were analysed.\\nConflicts of Interest: The authors declare no conflict of interest.\\nReferences\\n1. Giri, C.; Ochieng, E.; Tieszen, L.L.; Zhu, Z.; Singh, A.; Loveland, T.; Masek, J.; Duke, N. Status and distribution\\nof mangrove forests of the world using earth observation satellite data. Glob. Ecol. Biogeogr. 2011,20, 154–159.\\n[CrossRef]\\n2. Spalding, M.; Kainuma, M.; Collins, L. World Atlas of Mangroves (Version 3) ; Routledge: London, UK, 2010.\\n3. Spalding, M.; Blasco, F.; Field, C. World Atlas of Mangroves ; The International Society for Mangrove\\nEcosystems: Okinawa, Japan, 1997.\\n4. FAO. Loss of Mangroves Alarming ; Food and Agriculture Organization of the United Nations: Rome, Italy, 2008.\\n5. Roma ˜nach, S.S.; DeAngelis, D.L.; Koh, H.L.; Li, Y.; Teh, S.Y.; Raja Barizan, R.S.; Zhai, L. Conservation and\\nrestoration of mangroves: Global status, perspectives, and prognosis. Ocean Coast. Manag. 2018,154, 72–82.\\n[CrossRef]\\n6. Thomas, N.; Lucas, R.; Bunting, P.; Hardy, A.; Rosenqvist, A.; Simard, M. Distribution and drivers of global\\nmangrove forest change, 1996–2010. PLoS ONE 2017,12, e0179302. [CrossRef] [PubMed]\\n7. Malik, A.; Fensholt, R.; Mertz, O. Mangrove exploitation effects on biodiversity and ecosystem services.\\nBiodivers. Conserv. 2015,24, 3543–3557. [CrossRef]\\n8. Donato, D.C.; Kauffman, J.B.; Murdiyarso, D.; Kurnianto, S.; Stidham, M.; Kanninen, M. Mangroves among\\nthe most carbon-rich forests in the tropics. Nat. Geosci. 2011,4, 293–297. [CrossRef]\\n9. Swamy, L.; Drazen, E.; Johnson, W.R.; Bukoski, J.J. The future of tropical forests under the United Nations\\nSustainable Development Goals. J. Sustain. For. 2017,37, 221–256. [CrossRef]\\n10. FAO. Status and Trends in Mangrove Area Extent Worldwide, by M.L. Wilkie and S. Fortuna ; FAO: Rome, Italy,\\n2003.\\n11. FAO. The World’s Mangroves 1980–2005 ; Food and Agriculture Organization of the United Nations: Rome,\\nItaly, 2007.\\n12. Lucas, R.M.; Rebelo, L.M.; Rosenqvist, A.; Itoh, T.; Shimada, M.; Simard, M.; Souza-Filho, P.W.; Thomas, N.;\\nTrettin, C.; Accad, A.; et al. Contribution of L-band SAR to systematic global mangrove monitoring.\\nMar. Freshw. Res. 2014,65, 589–603. [CrossRef]\\n13. Hamilton, S.E.; Casey, D. Creation of a high spatio-temporal resolution global database of continuous\\nmangrove forest cover for the 21st century (CGMFC-21). Glob. Ecol. Biogeogr. 2016,25, 729–738. [CrossRef]\\n14. Hansen, M.C.; Potapov, P.V.; Moore, R.; Hancher, M.; Turubanova, S.A.; Tyukavina, A.; Thau, D.;\\nStehman, S.V.; Goetz, S.J.; Loveland, T.R.; et al. High-Resolution Global Maps of 21st-Century Forest\\nCover Change. Science 2013,342, 850–853. [CrossRef] [PubMed]\\n15. Rakotomavo, A.; Fromard, F. Dynamics of mangrove forests in the Mangoky River delta, Madagascar,\\nunder the influence of natural and human factors. For. Ecol. Manag. 2010,259, 1161–1169. [CrossRef]\\n16. Tong, P.H.S.; Auda, Y.; Populus, J.; Aizpuru, M.; Habshi, A.A.; Blasco, F. Assessment from space of\\nmangroves evolution in the Mekong Delta, in relation to extensive shrimp farming. Int. J. Remote Sens. 2004,\\n25, 4795–4812. [CrossRef]\\n17. Ferreira, M.A.; Andrade, F.; Bandeira, S.O.; Cardoso, P.; Mendes, R.N.; Paula, J. Analysis of cover change\\n(1995–2005) of Tanzania/Mozambique trans-boundary mangroves using Landsat imagery. Aquat. Conserv.\\n2009,19, S38–S45. [CrossRef]Remote Sens. 2018,10, 1669 18 of 19\\n18. Long, J.B.; Giri, C. Mapping the Philippines’ Mangrove Forests Using Landsat Imagery. Sensors 2011,\\n11, 2972–2981. [CrossRef] [PubMed]\\n19. Kirui, K.B.; Kairo, J.G.; Bosire, J.; Viergever, K.M.; Rudra, S.; Huxham, M.; Briers, R.A. Mapping of mangrove\\nforest land cover change along the Kenya coastline using Landsat imagery. Ocean Coast. Manag. 2013,\\n83, 19–24. [CrossRef]\\n20. CONABIO. Distribución de los Manglares en México en 2015’, Escala: 1:50000. EdicióN: 1 ; Comisión Nacional\\npara el Conocimiento y Uso de la Biodiversidad. Sistema de Monitoreo de los Manglares de México (SMMM):\\nCiudad de México, Mexico, 2016.\\n21. Nascimento, W.R., Jr.; Souza Filho, P.W.M.; Proisy, C.; Lucas, R.M.; Rosenqvist, A. Mapping changes in\\nthe largest continuous Amazonian mangrove belt using object-based classification of multisensor satellite\\nimagery. Estuar. Coast. Shelf Sci. 2013,117, 83–93. [CrossRef]\\n22. Thomas, N.; Bunting, P.; Hardy, A.; Lucas, R.; Rosenqvist, A.; Fatoyinbo, T. Mapping mangrove baseline and\\ntime-series change extent: A global monitoring approach. Remote Sens. 2018,10, 1466. [CrossRef]\\n23. Heumann, B.W. An Object-Based Classification of Mangroves Using a Hybrid Decision Tree—Support\\nVector Machine Approach. Remote Sens. 2011,3, 2440–2460. [CrossRef]\\n24. Kovacs, J.M.; de Santiago, F.F.; Bastien, J.; Lafrance, P. An Assessment of Mangroves in Guinea, West Africa,\\nUsing a Field and Remote Sensing Based Approach. Wetlands 2010,30, 773–782. [CrossRef]\\n25. Bunting, P.; Clewley, D.; Lucas, R.M.; Gillingham, S. The Remote Sensing and GIS Software Library\\n(RSGISLib). Comput. Geosci. 2014,62, 216–226. [CrossRef]\\n26. Bunting, P.; Gillingham, S. The KEA image file format. Comput. Geosci. 2013,57, 54–58. [CrossRef]\\n27. Pedregosa, F.; Varoquaux, G.; Gramfort, A.; Michel, V.; Thirion, B.; Grisel, O.; Blondel, M.; Prettenhofer, P.;\\nWeiss, R.; Dubourg, V.; et al. Scikit-learn: Machine Learning in Python. J. Mach. Learn. Res. 2011,\\n12, 2825–2830.\\n28. Clewley, D.; Bunting, P.; Shepherd, J.; Gillingham, S.; Flood, N.; Dymond, J.; Lucas, R.; Armston, J.;\\nMoghaddam, M. A Python-Based Open Source System for Geographic Object-Based Image Analysis\\n(GEOBIA) Utilizing Raster Attribute Tables. Remote Sens. 2014,6, 6111–6135. [CrossRef]\\n29. Cottam, A.; Gorelick, N.; Belward, A.S.; Pekel, J.F. High-resolution mapping of global surface water and its\\nlong-term changes. Nature 2016,540, 1–19.\\n30. Soluri, E.A.; Woodson, V.A. World Vector Shoreline. Int. Hydrogr. Rev. 1990,1, 27–35.\\n31. Wessel, P.; Smith, W.H.F. A global, self-consistent, hierarchical, high-resolution shoreline database.\\nJ. Geophys. Res. 1996,101, 8741–8743. [CrossRef]\\n32. Weatherall, P.; Marks, K.M.; Jakobsson, M.; Schmitt, T.; Tani, S.; Arndt, J.E.; Rovere, M.; Chayes, D.; Ferrini, V.;\\nWigley, R. A new digital bathymetric model of the world’s oceans. Earth Space Sci. 2015,2, 331–345.\\n[CrossRef]\\n33. Shimada, M.; Itoh, T.; Motohka, T.; Watanabe, M.; Shiraishi, T.; Thapa, R.; Lucas, R. New global\\nforest/non-forest maps from ALOS PALSAR data (2007–2010). Remote Sens. Environ. 2014,155, 13–31.\\n[CrossRef]\\n34. Bunting, P.; Clewley, D. Atmospheric and Radiometric Correction of Satellite Imagery (ARCSI). 2018.\\nAvailable online: https://arcsi.remotesensing.info (accessed on 21 October 2018).\\n35. Chavez, P.S., Jr. An improved dark-object subtraction technique for atmospheric scattering correction of\\nmultispectral data. Remote Sens. Environ. 1988,24, 459–479. [CrossRef]\\n36. Vermote, E.; Tanre, D.; Deuze, J.; Herman, M.; Morcrette, J. Second Simulation of the Satellite Signal in the\\nSolar Spectrum, 6S: An overview. IEEE Trans. Geosci. Remote Sens. 1997,35, 675–686. [CrossRef]\\n37. Shepherd, J.D.; Dymond, J.R. Correcting satellite imagery for the variance of reflectance and illumination\\nwith topography. Int. J. Remote Sens. 2003,24, 3503–3514. [CrossRef]\\n38. Zhu, Z.; Woodcock, C.E. Object-based cloud and cloud shadow detection in Landsat imagery.\\nRemote Sens. Environ. 2012,118, 83–94. [CrossRef]\\n39. Zhu, Z.; Wang, S.; Woodcock, C.E. Improvement and expansion of the Fmask algorithm: cloud, cloud\\nshadow, and snow detection for Landsats 4–7, 8, and Sentinel 2 images. Remote Sens. Environ. 2015,\\n159, 269–277. [CrossRef]\\n40. Holben, B.N. Characteristics of maximum-value composite images from temporal AVHRR data. Int. J.\\nRemote Sens. 1986,7, 1417–1434. [CrossRef]Remote Sens. 2018,10, 1669 19 of 19\\n41. Ramoino, F.; Tutunaru, F.; Pera, F.; Arino, O. Ten-Meter Sentinel-2A Cloud-Free Composite—Southern Africa\\n2016. Remote Sens. 2017,9, 652. [CrossRef]\\n42. Bunting, P.; Lucas, R.; Jones, K.; Bean, A. Characterisation and mapping of forest communities by clustering\\nindividual tree crowns. Remote Sens. Environ. 2010,114, 2536–2547. [CrossRef]\\n43. Wilson, E.B. Probable inference, the law of succession, and statistical inference. J. Am. Stat. Assoc. 1927,\\n22, 209–212. [CrossRef]\\nc\\r2018 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access\\narticle distributed under the terms and conditions of the Creative Commons Attribution\\n(CC BY) license (http://creativecommons.org/licenses/by/4.0/).'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PyPDF2 import PdfReader"
      ],
      "metadata": {
        "id": "M3BHmUwuOJsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_text_data = []"
      ],
      "metadata": {
        "id": "6iyyL5QpOYQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for filename in os.listdir(pdf_dir):\n",
        "    if filename.endswith('.pdf'):\n",
        "        file_path = os.path.join(pdf_dir, filename)\n",
        "        with open(file_path, 'rb') as file:\n",
        "            pdf = PdfReader(file)\n",
        "            text = \"\"\n",
        "            for page_num in range(len(pdf.pages)):\n",
        "                page = pdf.pages[page_num]\n",
        "                text += page.extract_text()\n",
        "            pdf_text_data.append({'Filename': filename, 'Text': text})"
      ],
      "metadata": {
        "id": "TxrLwi9mObys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall pycryptodome pyPDF2\n",
        "!pip install pycryptodome pyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8V8bm040Oht5",
        "outputId": "2fa57417-3eec-44e0-ca38-4fd5b2946c1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: pycryptodome 3.20.0\n",
            "Uninstalling pycryptodome-3.20.0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.10/dist-packages/Crypto/*\n",
            "    /usr/local/lib/python3.10/dist-packages/pycryptodome-3.20.0.dist-info/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled pycryptodome-3.20.0\n",
            "Found existing installation: PyPDF2 3.0.1\n",
            "Uninstalling PyPDF2-3.0.1:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.10/dist-packages/PyPDF2/*\n",
            "    /usr/local/lib/python3.10/dist-packages/pypdf2-3.0.1.dist-info/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled PyPDF2-3.0.1\n",
            "Collecting pycryptodome\n",
            "  Using cached pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "Collecting pyPDF2\n",
            "  Using cached pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "Installing collected packages: pyPDF2, pycryptodome\n",
            "Successfully installed pyPDF2-3.0.1 pycryptodome-3.20.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader"
      ],
      "metadata": {
        "id": "0XFCSwOvPZoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List to store PDF text data\n",
        "pdf_text_data = []"
      ],
      "metadata": {
        "id": "hGV75agePdQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for filename in os.listdir(pdf_dir):\n",
        "    if filename.endswith('.pdf'):\n",
        "        file_path = os.path.join(pdf_dir, filename)\n",
        "        with open(file_path, 'rb') as file:\n",
        "            pdf = PdfReader(file)\n",
        "            text = \"\"\n",
        "            for page_num in range(len(pdf.pages)):\n",
        "                page = pdf.pages[page_num]\n",
        "                text += page.extract_text()\n",
        "            pdf_text_data.append({'Filename': filename, 'Text': text})"
      ],
      "metadata": {
        "id": "frop02WpPiDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(pdf_text_data)"
      ],
      "metadata": {
        "id": "y8v-rCgDPnQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "HQ1IQ8URRy6i",
        "outputId": "c2848a4b-838e-4d99-e57a-976ddf8da659"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Filename  \\\n",
              "0  The-global-mangrove-watch-a-ne-4abecf89-c8a2-4...   \n",
              "1  A-New-Vegetation-Index-to-Dete-35086913-d72d-4...   \n",
              "2                                             Ai.pdf   \n",
              "\n",
              "                                                Text  \n",
              "0  remote sensing  \\nArticle\\nThe Global Mangrove...  \n",
              "1  remote sensing  \\nArticle\\nA New Vegetation In...  \n",
              "2  Extinguished philosophies lie about the cradle...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9eb9c281-d85b-4d2b-b5b7-5d167421c4a3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Filename</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The-global-mangrove-watch-a-ne-4abecf89-c8a2-4...</td>\n",
              "      <td>remote sensing  \\nArticle\\nThe Global Mangrove...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A-New-Vegetation-Index-to-Dete-35086913-d72d-4...</td>\n",
              "      <td>remote sensing  \\nArticle\\nA New Vegetation In...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ai.pdf</td>\n",
              "      <td>Extinguished philosophies lie about the cradle...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9eb9c281-d85b-4d2b-b5b7-5d167421c4a3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9eb9c281-d85b-4d2b-b5b7-5d167421c4a3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9eb9c281-d85b-4d2b-b5b7-5d167421c4a3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-55b15e92-8489-4249-b923-1acd5c5f8102\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-55b15e92-8489-4249-b923-1acd5c5f8102')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-55b15e92-8489-4249-b923-1acd5c5f8102 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Filename\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"The-global-mangrove-watch-a-ne-4abecf89-c8a2-4e96-9c66-98c850be668f.pdf\",\n          \"A-New-Vegetation-Index-to-Dete-35086913-d72d-4d90-b224-4bd93a517488.pdf\",\n          \"Ai.pdf\"\n        ],\n        \"num_unique_values\": 3,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"remote sensing  \\nArticle\\nThe Global Mangrove Watch\\u2014A New 2010 Global\\nBaseline of Mangrove Extent\\nPete Bunting1,*\\n, Ake Rosenqvist2, Richard M. Lucas1,3, Lisa-Maria Rebelo4\\n,\\nLammert Hilarides5, Nathan Thomas6, Andy Hardy1\\n, Takuya Itoh7,\\nMasanobu Shimada8and C. Max Finlayson9\\n1Department of Geography and Earth Sciences, Aberystwyth University, Aberystwyth SY23 3DB, UK;\\nrichard.lucas@aber.ac.uk (R.M.L.); ajh13@aber.ac.uk (A.H.)\\n2Solo Earth Observation (soloEO), Tokyo 104-0054, Japan; ake.rosenqvist@soloEO.com\\n3School of Biological, Earth and Environmental Sciences (BEES), University of New South Wales (UNSW),\\nHigh Street, Kensington, NSW 2052, Australia\\n4International Water Management Institute, Regional Office for SE Asia and The Mekong,\\nP.O. Box 4199, Vientiane; l.rebelo@cgiar.org\\n5Wetlands International, 6700AL Wageningen, The Netherlands; Lammert.Hilarides@wetlands.org\\n6Earth System Science Interdicsiplinary Center, University of Maryland/NASA Goddard Space Flight Center,\\nCollege Park, MD 20742, USA; nathan.m.thomas@nasa.gov\\n7Remote Sensing Technology Center of Japan (RESTEC), Tsukuba Office, Ibaraki 305-8505, Japan;\\nitoh_takuya@restec.or.jp\\n8School of Science and Engineering, Tokyo Denki University, Saitama 350-0394, Japan;\\nshimada@g.dendai.ac.jp\\n9Institute for Land, Water and Society, Charles Sturt University, Albury, NSW 2640, Australia;\\nmfinlayson@csu.edu.au\\n*Correspondence: pete.bunting@aber.ac.uk; Tel.: +44-1970-622615\\nReceived: 31 July 2018 ; Accepted:18 October 2018; Published: 22 October 2018\\n/gid00030/gid00035/gid00032/gid00030/gid00038/gid00001/gid00033/gid00042/gid00045 /gid00001\\n/gid00048/gid00043/gid00031/gid00028/gid00047/gid00032/gid00046\\nAbstract: This study presents a new global baseline of mangrove extent for 2010 and has been\\nreleased as the first output of the Global Mangrove Watch (GMW) initiative. This is the first study\\nto apply a globally consistent and automated method for mapping mangroves, identifying a global\\nextent of 137,600 km2. The overall accuracy for mangrove extent was 94.0% with a 99% likelihood that\\nthe true value is between 93.6\\u201394.5%, using 53,878 accuracy points across 20 sites distributed globally.\\nUsing the geographic regions of the Ramsar Convention on Wetlands, Asia has the highest proportion\\nof mangroves with 38.7% of the global total, while Latin America and the Caribbean have 20.3%,\\nAfrica has 20.0%, Oceania has 11.9%, North America has 8.4% and the European Overseas Territories\\nhave 0.7%. The methodology developed is primarily based on the classification of ALOS PALSAR\\nand Landsat sensor data, where a habitat mask was first generated, within which the classification\\nof mangrove was undertaken using the Extremely Randomized Trees classifier. This new globally\\nconsistent baseline will also form the basis of a mangrove monitoring system using JAXA JERS-1\\nSAR, ALOS PALSAR and ALOS-2 PALSAR-2 radar data to assess mangrove change from 1996 to\\nthe present. However, when using the product, users should note that a minimum mapping unit\\nof 1 ha is recommended and that the error increases in regions of disturbance and where narrow\\nstrips or smaller fragmented areas of mangroves are present. Artefacts due to cloud cover and the\\nLandsat-7 SLC-off error are also present in some areas, particularly regions of West Africa due to the\\nlack of Landsat-5 data and persistence cloud cover. In the future, consideration will be given to the\\nproduction of a new global baseline based on 10 m Sentinel-2 composites.\\nKeywords: mangrove; extent; global; baseline; mapping; ALOS PALSAR; landsat; ramsar; global\\nmangrove watch; K&C\\nRemote Sens. 2018,10, 1669; doi:10.3390/rs10101669 www.mdpi.com/journal/remotesensingRemote Sens. 2018,10, 1669 2 of 19\\n1. Introduction\\nMangroves are forested wetlands that are uniquely adapted to the intertidal zone. Found in the\\ncoastal zones of more than 118 countries in the tropics, subtropics and temperate regions [1\\u20133],\\nmangroves have (for centuries) provided natural resources to local populations, including food\\n(particularly fish and invertebrates) and timber. However, through processes such as population\\nincreases, industrialisation, urban expansion and globalisation, their extent has been reduced [ 4] and\\nmany have been fragmented or degraded [ 5], particularly in Southeast Asia, where about one third\\n(32%) of the world\\u2019s mangroves are located [ 6]. Many of the mangrove areas that have remained\\nrelatively intact are those that are remote, inaccessible, protected within conservation reserves or\\nreceive national protection, for example in Australia. Globally, mangroves are being increasingly\\naffected by climatic fluctuations, including those induced by human activities [ 5]. At the same\\ntime, mangroves are receiving greater recognition for their role in food provision, coastal protection\\n(e.g., from large storms), reserves of biodiversity [ 7] and as a large carbon store [ 8]. Hence, there are\\nnumerous and increasing efforts to ensure protection and restoration across their range. A fundamental\\nrequirement for mangrove protection and restoration is information about current and historical\\nmangrove distributions and conditions. While critical for informing efforts that support conservation,\\nsustainable management, and restoration of these ecosystems, data on mangrove status and extent\\nare necessary to meet reporting requirements for signatories to the Ramsar Convention on Wetlands\\nand other countries with mangroves in their territories who are striving to meet the Sustainable\\nDevelopment Goals [5,9].\\nAt a global level, maps of mangrove extent have previously been generated by Spalding et al. for\\n1960\\u20131996 [ 3] and 1999\\u20132003 [ 2], by curating the best available national and regional maps, and by\\nthe United States Geological Survey (USGS; [ 1]) for 2000, based on the classification of Landsat sensor\\ndata primarily from 1997\\u20132000. The FAO [ 4,10,11] have also conducted surveys to estimate global\\nextent for 1980, 1990 and 2000 and, in the later studies, both the FAO and Spalding et al. [2]referred\\nto the 2000 Giri et al. [1] to fill in gaps in coverage. The map of Giri et al. [1]has been regarded as the\\nmost globally consistent because of the standardised use of Landsat sensor data and methodology\\nwithin a defined period but, in some cases, the contribution of local to regionally-derived maps\\nto Spalding et al. [2] results in better mapping (depending on the scales and methods used). Hence,\\nwhilst the maps of mangrove area are broadly in agreement, many differences exist in terms of area\\nand boundary locations with these sometimes exaggerated by differences in accuracy in the geometric\\nlocation, scale and generalisation of the map products. The maps generated are also historical (currently\\nby at least two decades) and are unable to be easily updated and certainly not on a regular (e.g., annual)\\nbasis. Rates of mangrove loss can also then not be determined as the products from different years are\\nbased on different methods.\\nTo address the need for timely information on mangroves at a global level, the Japan Aerospace\\nExploration Agency (JAXA) Kyoto & Carbon (K&C) Initiative formulated the Global Mangrove Watch\\n(GMW), which aimed to produce consistent 25 m spatial resolution maps of mangrove extent across\\ntheir range by generating a baseline map for 2010. For mapping, Japanese L-band Synthetic Aperture\\nRadar (SAR) data were considered most appropriate given their global coverage and sensitivity\\nto the woody components of mangroves [ 12]. However, a limitation is that mangroves are often\\ndifficult to distinguish from other land covers (particularly forests and plantations) on the landward\\nmargins. For this reason, Landsat sensor data were integrated into the analysis to improve the baseline\\nmap. The mapping was also confined to locations with conditions considered suitable to support\\nmangroves. The objective of the GMW is to provide the information needed by a wide range of users,\\nincluding wetland and forest managers, civil society organisations, contracting partners of the Ramsar\\nConvention, and countries with mangroves in their territories.\\nMany studies have used Earth Observation (EO) data to map mangrove extent. At a global level,\\nthe study of Giri et al. [1]was the first, with this using an unsupervised classification approach and\\nmanual selection of classes associated with mangroves. Many studies have used the Giri et al. [1]Remote Sens. 2018,10, 1669 3 of 19\\nproduct as a basis for further analysis. For example, Hamilton and Casey [13]intersected the\\nGiri et al. [1] map with the forest cover change of Hansen et al. [14]to assess changes in mangrove\\nextent. Thomas et al. [6]was the first to consider L-band SAR for global assessment of mangrove\\nchange, which was assessed visually by on a 1\\u000e\\u00021\\u000egrid overlain onto a composite of Japanese Earth\\nResources Satellite (JERS-1) SAR from 1996 and Advanced Land Observing Satellite (ALOS PALSAR)\\ndata from 2007 and 2010. Causes of change were also reviewed based on features including shape and\\ncontext. Other studies have been more focused on local sites, such as a single delta (e.g., the Mangoky\\nRiver delta, Madagascar [ 15], Mekong Delta, Vietnam [ 16]) or countries (e.g., Mozambique [ 17],\\nPhilippines\\u2019 [ 18], Kenya [ 19], and Mexico [ 20]). Methods adopted have varied. The majority have\\nused optical (primarily Landsat) datasets (e.g., [ 15,17\\u201319]), while a few have fused optical and SAR\\ndata (e.g., [ 21,22]). In terms of analysis, a broad range of techniques have been used, including object\\norientated methods making use of image segmentation (e.g., [ 23]), rule based classifiers (e.g., [ 21]),\\nunsupervised classifiers (e.g., [ 17,18,24]) and machine learning methods (e.g., [ 22,23]). While there\\nis no clear dominant direction in terms of methodology for assessing mangrove extent, a significant\\ngap is the lack of studies that have sought to develop and apply a single consistent methodology that\\nis repeatable over large geographic areas, including at the global level. Therefore, this study aims to\\nprovide a new updated baseline of global mangrove extent, which can be used as a basis for studying\\nmangrove change and uses a single globally consistent methodology.\\n2. Methods\\nThe new global mangrove baseline has been generated using a combination of Synthetic Aperture\\nRadar (SAR) from the Advanced Land Observing Satellite (ALOS) Phased-Array L-band Synthetic\\nAperture Radar (PALSAR) and optical satellite data from Landsat-5 Thematic Mapper (TM) and\\nLandsat-7 Enhanced TM (ETM+). The overall approach followed four stages: (a) extraction of a\\ncoastal water mask from the PALSAR data; (b) generation of a mangrove \\u201chabitat\\u201d layer that identified\\nareas that were actually or potentially able to support mangroves; (c) generation of an initial baseline\\nclassification using the PALSAR data only; and (d) refinement of the initial baseline classification using\\nLandsat sensor composites to improve the distinction of the landward border between mangroves and\\nother terrestrial land covers. A final quality assurance (QA) of the resulting baseline product was then\\nundertaken through visual assessment and, where appropriate, errors were corrected. An overview of\\nthe methods for producing the new mangrove baseline is shown in Figure 1.\\nUnless otherwise stated, all data processing was undertaken using the open source Remote\\nSensing and GIS Software Library (RSGISLib [ 25]), the KEA file format [ 26], the Scikit-Learn [ 27]\\nmachine learning library and scripted in python as outlined by Clewley et al. [28].\\n2.1. Datasets\\nUsing data acquired in 2010, a baseline map of mangrove extent was generated by integrating\\nALOS PALSAR and a composite of Landsat sensor data and referencing the 2000 Shuttle Radar\\nTopographic Mission (SRTM) 30 m Digital Elevation Model data and existing products delineating\\nshorelines, surface water occurrence and previous attempts to delineate global mangrove extents.\\nThese datasets are summarised in Table 1\\nFrom the global shoreline dataset, a global ocean regions dataset was derived to identify oceanic\\nwater bodies. The shoreline dataset was rasterised onto the same pixel grid as the ALOS PALSAR data\\nand oceanic water was defined as pixels that were 200 pixels ( \\u00185000 m) from the defined shoreline.Remote Sens. 2018,10, 1669 4 of 19\\nMangrove BaselineCoastal MaskMangrove \\u2018Habitat\\u2019Mangrove Baseline (2010) #1Water OccurrenceBathymetryShoreline2010 PALSARExtremely Randomized Trees Classi\\ufb01cationDist. Giri et al Dist. Mangrove AtlasLat/LongDist. WaterDist. OceanElevationExtremely Randomized Trees Classi\\ufb01cationGiri 2000Mangrove AtlasDist. Shoreline2010 PALSARExtremely Randomized Trees Classi\\ufb01cationMangrove Baseline (2010) #22010 Landsat CompositeExtremely Randomized Trees Classi\\ufb01cationMerge into Global ProductQuality Assurance\\nFigure 1. Overview of the methodology for producing a global mangrove baseline. The numbers\\nreference the section number within the article, while the main flow of boxes indicate data dependency\\nbetween the stages (e.g., the coastal water mask is used to defined the mangrove habitat mask).\\nTable 1. Details of the datasets and sources used for this project.\\nDataset Period Resolution Source\\nALOS PALSAR 2010 25 m JAXA\\nLandsat TM and ETM+ 2009\\u20132011 30 m USGS\\nShuttle Radar Topography Mission (SRTM) 2000 30 m NASA\\nWater Occurrence 1984\\u20132016 30 m JRC [29]\\nGlobal Distribution of Mangroves USGS (v 1.3) 1997\\u20132000 30 m Giri et al. [1]\\nWorld Atlas of Mangroves (v 1.1) 1999\\u20132003 1:1,000,000 Spalding et al. [2]\\nGlobal Self-consistent Hierarchical\\nHigh-resolution Shorelines (v 2.3.5)- \\u201cFull Resolution\\u2019 [30,31]\\nGEBCO gridded bathymetry 2014 30 arc-seconds [32]\\nAll data were re-sampled or rasterised onto the same 0.8 arc-second pixel grid as the ALOS\\nPALSAR data. For the SRTM data cubic spline interpolation was used, while for other continuous data\\n(e.g., Landsat) a cubic convolution was applied and for categorical data nearest neighbour interpolation\\nwas used.\\n2.1.1. ALOS PALSAR\\nThe ALOS PALSAR dual polarisation (HH+HV) backscatter data used were provided by JAXA\\nas1\\u000e\\u00021\\u000emosaic tiles. The nominal spatial resolution was 25 m (0.8 arc seconds) and data were\\nprovided in the WGS84 (EPSG:4326) coordinate system. The mosaics are openly available in the public\\ndomain (http://www.eorc.jaxa.jp/ALOS/en/palsar_fnf/fnf_index.htm). The processing undertaken\\nto produce the tiled mosaics is detailed in Shimada et al. [33]. Global mosaics from JERS-1 SAR, ALOS\\nPALSAR and ALOS-2 PALSAR-2 were available for 1996, annually from 2007 to 2010 and from 2015 to\\n2017. However, the 2010 mosaic was the most complete in terms of temporal consistency and spatial\\ncoverage and therefore was defined as the baseline (reference) year.\\n2.1.2. Landsat Composites\\nAlthough the ALOS PALSAR dual polarisation L-band SAR data provided a reasonable level\\nof discrimination of mangroves from other land cover types (particularly bare ground), there was\\nsome confusion with other wetland or forest types. This was particularly the case for certain\\ntypes of adjoining terrestrial forests and wetlands with similar structure to mangroves. However,\\nmangroves were distinct from many of these land covers within the Landsat sensor data, particularly inRemote Sens. 2018,10, 1669 5 of 19\\nthe near infrared and shortwave infrared wavelength regions. For this reason, composite images were\\ngenerated using Landsat sensor data acquired for 2010, although 2009 and 2011 images were also used,\\nwhere necessary, to provide sufficient imagery for the processing. In order to minimise the impact\\nof the Landsat 7 scan-line (SLC-off) error, which results in no-data striping in the imagery, Landsat 5\\ndata were primarily selected when available. To identify the scenes to download for each Landsat\\nrow/path, the following sequence of rules were applied:\\n1. Identify 10 Landsat 5 scenes with less than 10% cloud cover from 2010.\\n2. If less than 10 scenes available, then add Landsat 7 scenes with less than 10% cloud cover\\nfrom 2010.\\n3. If less than 5 scenes, then add Landsat 5 and 7 scenes from 2010 with less than 50% cloud up to a\\nmaximum of 15 scenes.\\n4. If less than 5 scenes, then extend time range to 2009\\u20132011 and repeat Steps 1\\u20133.\\nA total of 15,346 top-of-atmosphere Landsat scenes from 1766 row/paths were downloaded\\nusing the Google Cloud API (https://cloud.google.com/storage/docs/public-datasets/landsat).\\nThe images where processed to surface reflectance, cloud masked and topographically corrected using\\nthe \\u201cAtmospheric and Radiometric Correction of Satellite Imagery\\u201d (ARCSI [ 34]) software. ARCSI\\nderives a scene based aerosol optical depth (AOD) value using a dark object subtraction (DOS [ 35])\\nwhere a numerical inversion of the 6S [ 36] atmospheric model is applied to derive an AOD value\\nbased on the Blue wavelength. The 30 m (1 arc-second) SRTM elevation model was used to construct a\\nlook-up table (LUT) for correction with respect to elevation, which was applied subsequently to the\\ninput image to derive standardised (i.e., topographically corrected) reflectance using the approach\\nof Shepherd and Dymond [37]. The FMASK [ 38,39] cloud masking algorithm was applied for removal\\nof cloud and cloud shadow.\\nTo allow fusion with the ALOS PALSAR data, the resulting Landsat data were re-sampled,\\nusing cubic convolution, to match the 0.8 arc-second pixel grid of the ALOS PALSAR data. A maximum\\nNDVI compositing [ 40,41] processing chain was then applied using RSGISLib [ 25] at a project level\\n(see Section 2.2) to generate a single Landsat composite image corresponding with the project region\\ndefined using the ALOS PALSAR data.\\n2.2. Project Region Definition\\nTo undertake the processing, 128 project regions were defined that grouped the 1\\u000e\\u00021\\u000etiles\\nsuch that: (a) no continuous area of mangroves was split by a project border; (b) the mangroves\\nwithin a project were considered to be contained within a similar bio-geographic region and (c) the\\ncomputational requirements of processing the projects were appropriate (i.e., balancing speed of\\nprocessing with available computing resource).\\nThe projects were defined by the union of Giri et al. [1]and Spalding et al. [2]datasets, where each\\nwere buffered by 0.1\\u000eand touching or overlapping polygons merged. The resulting polygons where\\nclustered using the approach outlined in Bunting et al. [42]where the minimum spanning tree was\\ncreated and edges with a length >0.5\\u000eor greater than 1 standard deviation of the edge lengths in\\nthe tree removed creating individual clusters. The resulting groups where then assessed, with small\\nregions merged into larger regions and large regions split when these were deemed too large for\\nefficient computational processing. This resulted in 131 project regions globally, although, for three,\\nthere were no ALOS PALSAR data and so they were excluded. The resulting 128 projects where\\nintersected with the 1\\u000e\\u00021\\u000etile grid and grouped into 12 geographic regions (Figure 2) to create a\\nhierarchical numbering system.Remote Sens. 2018,10, 1669 6 of 19\\nFigure 2. GMW project regions: ( A) the 12 top level regions; and ( B) an example of the individual\\nprojects for the South American region.\\n2.3. Coastal Mask\\nMangroves are found within a coastal environment and therefore a key component of defining the\\nmangrove habitat mask was to define a coastal water mask. To achieve this, a water mask was defined\\nusing a per-pixel Extremely Randomized Trees classification using Scikit-Learn [ 27] and RSGISLib [ 25]\\nsoftware. The number of estimators for the Extremely Randomized Trees classifier was defined as 500\\nfollowing a grid search sensitivity analysis. The classification was performed using the ALOS PALSAR\\nHH and HV polarisations, the ratio of HH/HV, local incident angle and acquisition date.\\nThe key step in defining the coastal water mask was to define the training samples and regions\\nto be classified, which was performed automatically. An initial water mask was produced using a\\nthreshold of > 20water occurrences, and this was subsequently intersected with the oceanic region\\n(Section 2.1) to identify oceanic water. A coastal region was then defined as the area 20 pixels ( \\u0018500 m)\\neither side of the shoreline with a bathymetry depth of > \\u0000100m. Additional regions based on 80 pixels\\n(\\u00182000 m) either side of the shoreline and a water occurrence < 80were added to this mask, with this\\nthen defining the region to be classified. 100,000 training pixels were then extracted randomly for land\\nand water from regions between > 20(\\u0018500 m) and < 80(\\u00182000 m) pixels away from the shoreline,\\nwith this defined as water or land using the water mask retrieved from the water occurrence layer.\\nFollowing the classification, a refinement was performed to remove small features, which required\\nclumping the classification to identify connected regions of a single class. Clumps classified as\\nland with an area of < 20pixels ( \\u001812,500 m2) and > 20water occurrence observations were assigned\\nto the water class, while water regions with an area of < 50pixels ( \\u001831,250 m2) were assigned to\\nland. These thresholds were identified through a sensitivity analysis and by visually assessing the\\nresulting maps.Remote Sens. 2018,10, 1669 7 of 19\\nThe thresholds used for generating the coastal mask were identified through an iterative sensitivity\\nanalysis based on a visual inspection of the resulting maps for a number of projects and sites globally\\nrepresenting a range of mangrove habitats.\\n2.4. Mangrove Habitat\\nMangroves exist within a specific ecological niche, which can be used to eliminate much of the area\\nwhere they will not be found. To define the region to be classified, and from which the non-mangrove\\npixels were selected, the following rules were defined, applied on a per-project basis. First, the SRTM\\nelevation needed to be less than 110% of the 99th percentile of the elevation of mangrove pixels. If the\\nresulting threshold was less than 5 m the threshold was set to 30 m, remembering that the SRTM is a\\nsurface model and therefore includes a component of vegetation height. The second rule, defined that\\nthe distance from the coastal water mask needed to be less than 110% of the 99th percentile of the\\ndistance of the mangrove pixels.\\nWithin the region defined above, a classification was subsequently performed. In total, 100,000\\nmangrove training pixels were randomly extracted from a union of the existing global mangrove\\nmaps from Giri et al. [1] and Spalding et al. [2], while 100,000 non-mangrove training samples were\\nrandomly extracted from within the region but outside of the mangrove union. If less than 100,000\\nmangrove pixels were available, then the number of samples selected for both classes was equal to the\\nnumber of mangrove pixels within the project.\\nThe classification was performed using the Extremely Randomized Trees classifier,\\nwith 100 estimators, defined through the use of a grid search sensitivity analysis of classifier\\nparameters. The input variables to the classification were: (a) pixel longitude and latitude; (b) distance\\nto water (defined using the coastal mask); (c) surface elevation defined by the SRTM; (d) distance to\\nthe oceanic layer; and (e) distances to the mangrove extents of Giri et al. [1]and Spalding et al. [2].\\nThe resulting habitat mask was visually checked and missing regions, including those that were not\\nidentified in the Giri et al. [1] and Spalding et al. [2] products, were added manually.\\nThe mangrove habitat layer (to be available at http://www.globalmangrovewatch.org) defines\\nthe maximum possible extent of mangrove habitat and therefore would not be needed to re-calculated\\nfor any subsequent mangrove mapping efforts.\\n2.5. Baseline Classification\\nThe new baseline was classified in two independent steps: first using the ALOS PALSAR and then\\nthe Landsat data. The ALOS PALSAR data were geographically contained entirely within the projects,\\nwhich allowed complete classification, but there were occasional gaps in the coverage of the Landsat\\nsensor data primarily because of cloud cover. In these gaps, the classification was based solely on the\\nALOS PALSAR data.\\n2.5.1. Classification: ALOS PALSAR\\nThe classification was undertaken using the Extremely Randomized Trees classifier, based on\\n100 estimators that were also defined through a grid search sensitivity analysis. The input variables\\nwere ALOS PALSAR HH and HV data (transformed to log unit dB), the ratio of HH/HV, pixel longitude\\nand latitude and the mangrove probability. Mangrove probability was defined using the union of\\nmangrove extent and generating a multi-dimensional histogram for the HH, HV and HH/HV data for\\nmangroves (defined using Giri et al. [1]) with a bin width of 0.25. The histogram was converted to a\\nprobability distribution function, which was used to calculate a probability of mangroves occurring in\\neach pixel.\\nTraining samples where defined through random sampling where 100,000 mangrove and\\nnon-mangrove samples were taken, resulting in 200,000 in total per project. For mangrove, 20,000\\nsamples were extracted from the intersection of the Giri et al. [1]and Spalding et al. [2]products and\\nthe remaining 80,000 were taken from the union of the two products. The non-mangrove samples wereRemote Sens. 2018,10, 1669 8 of 19\\nalso split, with 20,000 from within the habitat mask and 80,000 outside. The region outside the habitat\\nmask, within which training samples were selected, was defined as < 150pixels ( \\u00183750 m) from the\\nunion of the mangrove products over areas of water and < 250pixels ( \\u00186250 m) over terrestrial areas.\\nThe training points were visually checked and edited with reference to Google Earth Imagery as well\\nas the ALOS PALSAR and Landsat sensor imagery. In total, 20 M training points were defined globally\\nacross the 128 projects.\\n2.5.2. Classification: Landsat\\nUsing only a classification of ALOS PALSAR data, a consistent over-classification of the area of\\nmangroves was observed with this attributed to similarities in the structure and moisture content\\nof wetlands and forest cover types (indicated earlier). Therefore, a further refinement using optical\\nimagery was deemed necessary. The second classification iteration used the same training samples\\nas the ALOS PALSAR classification but samples without valid Landsat sensor data were removed.\\nUsing the Blue, Green, Red, Near-Infrared (NIR), Shortwave Infrared 1 (SWIR1) and SWIR2 spectral\\nbands, the Extremely Randomized Trees classifier, again using 100 estimators identified through a\\nsensitivity analysis, was applied to generate the final classification.\\n2.6. Merging into a Global Product\\nThe resulting project based analysis was compiled into a single global product for 2010 on a\\n1\\u000e\\u00021\\u000etile basis. A few project regions shared individual tiles and these needed to be merged,\\nwhich was undertaken using a union operation.\\n2.7. Quality Assurance\\nFollowing the automated analysis, an extensive quality assurance (QA) process was undertaken.\\nDuring this process, the product was visually checked against the ALOS PALSAR and Landsat sensor\\ndata as well as contemporary (2010) Google Earth imagery. Where significant errors of omission and\\ncommission were identified, polygons were drawn and edits applied.\\n2.8. Accuracy Assessment\\nTo assess the overall accuracy of the product, a point-based accuracy assessment was undertaken.\\nFor the accuracy assessment, a stratified random sample was undertaken within each project using the\\nwater, mangrove and terrestrial non-mangrove classes, within a 50 pixels ( \\u00181250 m) buffer from the\\nmangrove regions and within the mangrove habitat region. The number of accuracy samples, for each\\nclass, was 0.5% of the number of mangrove pixels, unless the resulting number of samples was less\\nthan 1000 in which case a 1% sample was taken.\\nWithin the projects, sites were selected (Figure 3 and Table 2) based on available local knowledge\\nand in some cases high resolution data. The accuracy assessment was undertaken using a custom\\nQGIS plugin that guides the operator to each point, providing a simple interface to decide between\\nclasses. The imagery used for reference included high resolution Google Earth imagery, custom high\\nresolution imagery, GMW Landsat image composites and ALOS PALSAR 2010 data.\\nTable 2. Regions where the accuracy assessment was undertaken and the number of accuracy samples\\nwhich were used.\\nSite Number Points\\nAustralia 4347\\nFiji 6487\\nHaiti 1356\\nIndonesia (1) 1343\\nIndonesia (2) 3717Remote Sens. 2018,10, 1669 9 of 19\\nTable 2. Cont.\\nSite Number Points\\nIndonesia (3) 144\\nJapan/Okinawa 2742\\nMexico (1) 6948\\nMexico (2) 2167\\nMyanmar 1106\\nPapua New Guinea 854\\nSamoa 90\\nSaudi Arabia 339\\nIndia 910\\nTanzania (Rufiji Delta) 3449\\nTonga 72\\nUSA (Mississippi Delta) 4590\\nUSA (West Florida) 5615\\nVenezuela 1793\\nVietnam 5809\\nTotal 53,878\\nVersion September 8, 2018 submitted to Remote Sens. 9 of 19\\nTable 2. Regions where the accuracy assessment was undertaken and the number of accuracy samples\\nwhich were used.\\nSite Number Points\\nAustralia 4347\\nFiji 6487\\nHaiti 1356\\nIndonesia (1) 1343\\nIndonesia (2) 3717\\nIndonesia (3) 144\\nJapan/Okinawa 2742\\nMexico (1) 6948\\nMexico (2) 2167\\nMyanmar 1106\\nPapua New Guinea 854\\nSamoa 90\\nSaudi Arabia 339\\nIndia 910\\nTanzania (Rufiji Delta) 3449\\nTonga 72\\nUSA (Mississippi Delta) 4590\\nUSA (West Florida) 5615\\nVenezuela 1793\\nVietnam 5809\\nTotal 53878\\n-20-20002020-180\\n-180-160\\n-160-140\\n-140-120\\n-120-100\\n-100-80\\n-80-60\\n-60-40\\n-40-20\\n-200\\n020\\n2040\\n4060\\n6080\\n80100\\n100120\\n120140\\n140160\\n160180\\n180\\nFigure 3. Distribution of sites used to undertake the accuracy assessment.\\n(23.4\\u25e6S). Asia is estimated to account for 38.7 % of the world\\u2019s mangroves, with Southeast Asia alone 294\\nrepresenting almost a third (32.2 %). The Americas are estimated to comprise 28.7 %, and Africa and 295\\nOceania 20.0 % and 11.9 %, respectively. European Overseas Territories account for 0.7 %. 296\\nTable 3 shows the extent of mangroves for the six Ramsar regions, Asia is the region with the 297\\nlargest area of mangroves (53,278 km2) with Latin America and the Caribbean (previously referred to 298\\nas the Neotropics) (27,940 km2) and Africa (27,465 km2) regions having the similar amounts. While 299\\nin terms of individual countries (Table 4) Indonesia contain 19.5 % of the worlds mangroves and the 300\\nnext three highest, by area, Brazil, Australia and Mexico combined contain 22.3 %. 301\\n3.2. Accuracy Assessment 302\\nThe overall accuracy (Table 5) of the classification was 95.3 %, with a 99 % likelihood that 303\\nthe confidence interval, using the Wilson score interval [43], was between 4.5\\u20135.0 %. Therefore, 304\\nthe overall accuracy was in the range 95.0\\u201395.5 %. 53,878 sample points (Table 2) were used for 305\\nthe accuracy assessment, where the points were manually allocated to the classes of mangroves, 306\\nwater and terrestrial (other). In terms of mangroves, the main confusion was with other terrestrial 307\\nFigure 3. Distribution of sites used to undertake the accuracy assessment.\\n3. Results\\n3.1. Mangrove Baseline\\nThe resulting baseline map of global mangrove extent gives an estimated total mangrove area\\nin 2010 of 137,600 km2. A Mollweide Equal Area projection was used for all area calculations.\\nFigure 4 illustrates the global distribution of mangroves, which can be found as far north as 32.3\\u000eN\\n(Bermuda) and as far south as 38.9\\u000eS (Australia). Figure 5 illustrates the spatial detail within the\\nmap. Approximately 96% are found between the Tropic of Cancer ( 23.4\\u000eN) and Tropic of Capricorn\\n(23.4\\u000eS). Asia is estimated to account for 38.7% of the world\\u2019s mangroves, with Southeast Asia alone\\nrepresenting almost a third (32.2%). The Americas are estimated to comprise 28.7%, and Africa and\\nOceania 20.0% and 11.9%, respectively. European Overseas Territories account for 0.7%.\\nTable 3 shows the extent of mangroves for the six Ramsar regions. Asia is the region with the\\nlargest area of mangroves (53,278 km2) with Latin America and the Caribbean (previously referred to\\nas the Neotropics) (27,940 km2) and Africa (27,465 km2) regions having similar amounts. In terms of\\nindividual countries (Table 4), Indonesia contains 19.5% of the worlds mangroves and the next three\\nhighest, by area, Brazil, Australia and Mexico combined contain 22.3%.\\n3.2. Accuracy Assessment\\nThe overall accuracy (Table 5) of the classification was 95.3%, with a 99% likelihood that the\\nconfidence interval, using the Wilson score interval [ 43], was 4.5\\u20135.0%. Therefore, the overall\\naccuracy was in the range 95.0\\u201395.5%. In total, 53,878 sample points (Table 2) were used for the\\naccuracy assessment, where the points were manually allocated to the classes of mangroves, water andRemote Sens. 2018,10, 1669 10 of 19\\nterrestrial (other). In terms of mangroves, the main confusion was with other terrestrial vegetation,\\ndemonstrating that 97.5% of the areas classified as mangroves were correct with the confusion resulting\\nin a producers accuracy of 94.0%. Therefore, there is a 99% likelihood that the confidence interval for\\nthe overall mangrove accuracy was between 93.6\\u201394.5%.\\nFigure 4. GMW mangrove baseline for 2010 and distribution of mangroves in longitude and latitude\\n(WGS-84; epsg:4326).\\nFigure 5. Example GMW v2.0 maps, using the Open Street Map (https://www.openstreetmap.org) data\\nas background mapping. From west to east: ( A) Central America (Honduras/Nicaragua); ( B) Africa\\n(Madagascar); and ( C) Australia (Queensland). The maps are presented in WGS-84 (epsg:4326) with\\ncoordinates in decimal degrees (valid for all figures below).\\nTable 3. GMW v2.0 baseline extents for the six Ramsar regions.\\nRegion GMW v2.0 (km2) Percentage of Global (%)\\nAfrica 27,465 20.0\\nAsia 53,278 38.7\\nEurope (Overseas Territories) 1026 0.7\\nLatin America and the Caribbean 27,939 20.3\\nNorth America 11,563 8.4\\nOceania 16,329 11.9\\nTotal 137,600\\nThe most common errors observed within the GMW baseline are associated with fine-scale\\nfeatures (e.g., riverine, aquaculture and fine coastal fringes; Figure 6), which was particularly the\\ncase for areas with a high degree of anthropogenic fragmentation. As the minimum feature size of\\nobjects identifiable within the ALOS PALSAR and Landsat sensor data encompassed multiple pixels,Remote Sens. 2018,10, 1669 11 of 19\\na recommended minimum mapping unit of 1 ha (i.e., 8 pixels) for reliable mapping is considered to be\\nthe most appropriate for end users.\\nTable 4. GMW v2.0 baseline extents for the world\\u2019s Top 10 countries with mangroves.\\nCountry GMW v2.0 (km2) Percentage of Global (%)\\nIndonesia 26,890 19.5\\nBrazil 11,072 8.1\\nAustralia 10,060 7.3\\nMexico 9537 6.9\\nNigeria 6958 5.1\\nMalaysia 5201 3.8\\nMyanmar 5011 3.6\\nPapua New Guinea 4762 3.5\\nBangladesh 4163 3.0\\nIndia 3521 2.6\\nTable 5. Accuracy assessment of the GMW v2.0 baseline.\\nMangroves Water Terrestrial Other User\\u2019s\\nMangroves 18,246 98 370 97.5%\\nWater 191 16,463 101 98.3%\\nTerrestrial Other 969 828 16,612 90.2%\\nProducer\\u2019s 94.0% 94.7% 97.2% 95.3%\\nFigure 6. Anthropogenic disturbance near Surabaya in Eastern Java, Indonesia. The background\\nimagery is the 2010 Landsat composite generated for this study, visualised using the NIR, SWIR and\\nRed wavelength bands. ( A) The Landsat composite, where the mangroves appear orange within the\\nband combination: and ( B) the Landsat composite with the GMW v2.0 baseline displayed over the top,\\nin green.\\n3.3. Comparison to Existing Maps\\nAlthough the time period for which they refer and methodology for production differ,\\na comparison between the GMW 2010 baseline and the 2000 Giri et al. [1](1997\\u20132000) and\\nSpalding et al. [2] (1999\\u20132003) datasets was undertaken (Table 6) for the six Ramsar regions.\\nThe Giri et al. [1] and Spalding et al. [2]datasets both represent a period of around 2000 while the\\nGMW product is for 2010 so some differences in area were expected. Although the global total\\nestimates of the 2010 GMW v2.0 baseline and the 2000 Giri et al. [1]datasets are very close (137,600Remote Sens. 2018,10, 1669 12 of 19\\nversus 137,760 km2), significant differences (>10%) between the datasets can be observed at a regional\\nlevel that are unlikely to be attributed to actual changes. These differences are, in part, due to errors\\nand missing regions in the products (e.g., Figure 7).\\n-0.50-0.75103.25103.25\\n103.50103.50\\n103.75103.75\\n103.25103.25\\n103.50103.50\\n103.75103.75\\n-0.50-0.75103.25103.25\\n103.50103.50\\n103.75103.75ABC\\nFigure 7. Riau/Jambi in Sumatra, Indonesia: ( A) GMW v2.0 baseline; ( B) Giri et al. [1]; and\\n(C) Spalding et al. [2] , illustrating differences between the three datasets. Background maps: Open\\nStreet Map (https://www.openstreetmap.org).\\nVisually, there is often a high degree of similarity between the products (see, for example, Figure 8).\\nHowever, numerical comparison of the Giri et al. [1]and Spalding et al. [2]products demonstrated\\nsignificant differences between these two products where, for instance, the global estimates of\\nmangrove extent equate to 137,760 km2versus 152,361 km2, respectively. The corresponding FAO [11]\\nestimates for 2000 and 2005 are 157,400 km2and 152,310 km2, respectively. This highlights a\\nsignificant uncertainty in our knowledge of global mangrove extent. Through a visual comparison, it\\nis considered that Spalding et al. [2]often overestimates the overall mangrove extent (e.g., Figure 9),\\nalthough there are also regions of missing data (e.g., Figure 7). At a regional scale, the errors\\nassociated with the Spalding et al. [2]dataset are relatively clear. For instance, the Spalding et al. [2]\\ndataset demonstrates that the region covering Latin America and the Caribbean accounts for 23.1%\\nof the World\\u2019s mangroves compared with 20.3% denoted by the GMW v2.0 baseline. Similarly,\\nthe Spalding et al. [2] dataset demonstrates that the Oceania region accounts for 7.7% of the world\\u2019s\\nmangroves, compared to 11.9% that is denoted in this study and in the Giri et al. [1] dataset.\\nTable 6. Mangrove extent comparison for the six Ramsar regions between the GMW v2.0 baseline,\\nGiri et al. [1] (v1.3; released 2015) and Spalding et al. [2](v2.0; released 2017). Figures for the latter\\ntwo were calculated from datasets downloaded from the UN Ocean Data Viewer (http://data.unep-\\nwcmc.org), and thus differ marginally from figures published by Giri et al. [1]and Spalding et al. [2]\\n(in brackets). It should be recognised that the comparison between these products should not be used\\nto infer changes in mangrove extent, as the differences rather can be considered to be predominately\\ndue to the mapping methodology and accuracy.\\nRegionGMW v2.0 (km2)\\n2010Giri et al. [1] (km2)\\n1997\\u20132000Spalding et al. [2] (km2)\\n1999\\u20132003\\nAfrica 27,465 (20.0%) 26,342 (19.1%) 31,149 (20.5%)\\nAsia 53,278 (38.7%) 55,068 (40.0%) 60,435 (39.7%)\\nEurope (Overseas Terr.) 1026 (0.7%) 1427 (1.0%) 1194 (0.8%)\\nLatin America and the Caribbean 27,939 (20.3%) 28,643 (20.8%) 35,113 (23.1%)\\nNorth America 11,563 (8.4%) 9739 (7.1%) 12,492 (8.2%)\\nOceania 16,329 (11.9%) 16,380 (11.9%) 11,735 (7.7%)\\nTotal 137,600 137,599 (137,760) 152,118 (152,361)Remote Sens. 2018,10, 1669 13 of 19\\n4.254.00117.25117.25\\n117.50117.50\\n117.75117.75\\n117.25117.25\\n117.50117.50\\n117.75117.75\\n4.254.00117.25117.25\\n117.50117.50\\n117.75117.75ABC\\nFigure 8. Border of North Kalimantan, Indonesia, and Sabah, Malaysia, illustrating a typical region\\nwith good correspondence between the GMW v2.0 baseline and the Giri et al. [1]andSpalding et al. [2]\\nproducts: ( A) GMW v2.0 baseline; ( B) Giri et al. [1]; and ( C) Spalding et al. [2]. Background maps:\\nOpen Street Map.\\n13.40\\n-87.50-87.50\\n-87.45-87.45\\n-87.50-87.50\\n-87.45-87.45\\n13.40\\n-87.50-87.50\\n-87.45-87.45ABC\\nFigure 9. Atl\\u00e1ntico Norte, Nicaragua: ( A) GMW v2.0 baseline; ( B) Giri et al. [1]; and ( C) Spalding et al. [2],\\nillustrating a region where the Spalding et al. [2]is generalised and overestimates the mangroves extent\\ncompared to Giri et al. [1]and the GMW v2.0 baseline. In this example, the Giri et al. [1]product has\\nmore detail than the GMW v2.0 baseline. Background maps: Open Street Map.\\n4. Discussion\\n4.1. Methods of Mapping Mangroves\\nOur results have yielded an updated global mangrove baseline, with an accuracy in excess of 90%.\\nThis new global baseline represents an improvement on existing global maps (e.g., Giri et al. [1]) for\\nmany regions across the world. This includes the successful mapping of mangroves for areas that were\\nfound to be absent in other existing products (e.g., Figure 7). The method made use of the existing\\nGiri et al. [1] and Spalding et al. [2]datasets to automatically generate classifier training samples that\\nwere subsequently visually checked. This approach produced a new mangrove extent yielding a total\\narea approximately equal to that of Giri et al. [1], while displaying significant regional variations. It\\nshould be noted that, due to the methodological differences in the generation of the GMW, Giri et al. [1]\\nand Spalding et al. [2]datasets, they cannot be used to infer indications of changes between their\\nrespective baseline years. The majority of mangrove area can be found in Asia, as identified by Giri\\net al. [1], with an approximately equal proportion distributed between Africa and Latin America and\\nthe Caribbean.\\nThis mangrove baseline was derived using publicly open imagery from the ALOS PALSAR and\\nLandsat sensors. These sensors are complimentary and were used in combination to achieve theRemote Sens. 2018,10, 1669 14 of 19\\nupdated baseline. The radar and optical imagery measure different properties of the forest and\\nwere used together to attain the baseline with high accuracy. The optical data is sensitive to the\\nbio-chemical (e.g., photosynthesis) properties of the forest and the radar is sensitive to the physical\\n(e.g., woody biomass) of the forest. In combination, these provide a more complete description of the\\nforest than from one dataset alone. The ALOS PALSAR data have the advantages of being cloud-free\\nand therefore each path is a consistent date rather than composited from a number of dates as with the\\nLandsat sensor data. This study also benefited from the availability of a number of additional global\\ndatasets, such as the water occurrence dataset [ 29] and shorelines [ 30,31], bathymetry [ 32] and the\\nSRTM elevation model.\\nThe study has produced a new baseline of global mangrove extent for 2010. The date of the\\nbaseline was driven by the availability of the ALOS PALSAR data, which was most complete for\\n2010. However, the availability of Landsat data in 2010 is poor with Landsat 5 TM data not available\\nglobally, with particular sparsity of data throughout Africa. The Landsat 7 ETM+ suffered with the\\nSLC-off failure (Figure 10). Given the importance of the Landsat sensor data to the classification of\\nmangroves, future studies would be recommended to prioritise the availability of suitability optical\\ndata (i.e., Landsat-8 and Sentinel-2). Additionally, the increased spatial resolution (10 m) of Sentinel-2\\nis expected to improve the mapping of fine features (e.g., riverine, aquaculture and fine coastal fringes)\\nand disturbed areas where the error in the GMW v2.0 baseline are highest.\\nFigure 10. Douala, Cameroon: ( A) the Landsat Composite; and ( B) the Landsat composite with\\nthe GMW v2.0 baseline overlaid in green, illustrating an area with poor Landsat coverage due to\\ncloud cover, lack of Landsat-5 data and influence of the Landsat-7 SLC-off artefact. The 2010 Landsat\\ncomposite generated for this study is visualised using the NIR, SWIR and Red wavelength bands.\\nThe updated baseline is able to suit the requirements and needs of policy and decision makers.\\nThese data are aimed to support a wide range of international initiatives and users, including wetland\\nmanagers, government bodies, civil society users and Ramsar Convention contracting parties.\\nAn up-to-date baseline is of critical importance for the inclusion of mangroves in these and future\\ninitiatives, such as REDD+. However, while a baseline is highly useful, the measurement of change in\\nmangrove extent using a consistent global methodology would be a very significant further advance\\nand direction for future work.\\n4.2. Forming a Monitoring System\\nThis Global Mangrove Watch map represents the extent and distribution for 2010, but is also a\\nbaseline from which a monitoring system can be built (Figure 11). Thomas et al. [22]demonstrated a\\nnovel \\u201cmap-to-image\\u201d method to update mangrove baselines using time-series radar imagery with aRemote Sens. 2018,10, 1669 15 of 19\\nhigh degree of accuracy. By focussing on the mapping of changes away from the baseline, the trend in\\nchange is more consistent than comparing independently classified baselines. The \\u201cmap-to-image\\u201d\\nmethod is also directly applicable at the global level and can be used to iteratively derive baselines\\nback in time using historical data and into the future with the continued acquisition of current\\nsensors and anticipated launch of future satellites. Being derived from, and therefore spatially\\nregistered to the ALOS PALSAR data, this new GMW v2.0 baseline constitutes an ideal basis for\\nsuch a monitoring system using the Japanese JERS-1 SAR (ca. 1996), ALOS PALSAR (2007\\u20132010)\\nand ALOS-2 PALSAR-2 (2015\\u2013present) imagery, enabling maps of mangrove extent to be generated\\nfor a number of epochs. Data availability is expected to continue and increase into the future with\\nanticipated data from ALOS-4 PALSAR-3, as well as other globally available and near-future datasets\\n(e.g., Sentinel-1, SAOCOM-1A/1B, NISAR and Tandem-L). The global mangrove baseline detailed\\nin this paper, in combination with the novel \\u201cmap-to-image\\u201d change detection technique outlined\\nin Thomas et al. [22], can therefore be used to used to form an operational global mangrove monitoring\\nsystem for driving policy and informing management decisions.\\nFigure 11. A flowchart of the proposed monitoring system which could be built on the 2010 GMW v2.0\\nbaseline using the methodology of Thomas et al. [22].\\n4.3. Cautions and Caveats\\nThe minimum size of mangrove region that is considered to be reliably identifiable within\\nthe ALOS PALSAR and Landsat sensor data are those than occupy multiple pixels and therefore\\na recommended minimum mapping unit of 1 ha (i.e., 8 pixels) for reliable mapping was used and\\nis advocated. Errors associated with the minimum feature size are particularly evident in areas of\\ndisturbance, such as around aquaculture ponds (e.g., Figure 12) as well as in riverine mangroves that\\nform narrow shoreline fringes.\\nThe Landsat image composites include artefacts (e.g., Figure 10) as a result of persistent cloud\\ncover and the Landsat-7 SLC-off error. This has particularly effected areas in West Africa (e.g., Niger\\nDelta and Cameroon) where cloud cover is frequent and Landsat-5 data were not available for 2010.\\nFuture work should focus on determining an optimal year for the production of an optical image\\ncomposite. For instance, data quality and availability is likely to be greater in the years after Landsat-8\\nwas launched (2013). Similarly, the availability of Sentinel-2 imagery (particularly since 2017 with\\nthe launch of Sentinel-2B) is considered a significant opportunity for further improvements, with a\\nresolution of 10 m aiding the mapping of smaller fringing and fragmented mangroves and the increased\\ntemporal resolution improves the quality of cloud-free composites.\\nThere are also some areas where mangroves are known to have been omitted in this version (v2.0)\\nof the GMW dataset, due to satellite data unavailability, including: Andaman and Nicobar Islands\\n(India), Bermuda (UK), Europa Island (France), Fiji, east of Anti-meridian, Guam and Saipan (USA),\\nKiribati, Maldives, Peru (south of latitude S4) and Wallis and Futuna Islands (France). While these\\nare not significant in terms of mangrove extent globally, which is the focus of this paper, they will be\\nincluded in the release of future GMW datasets.Remote Sens. 2018,10, 1669 16 of 19\\nVersion September 8, 2018 submitted to Remote Sens. 16 of 19\\nFigure 12. A drone photograph looking over part of the Xu\\u00e2n Th/uni1EE7y National Park, on the Red\\nRiver Delta, Vietnam (March 2018). The photograph illustrates an area of aquaculture with highly\\nfragmented mangroves.\\nthe launch of Sentinel-2B) is considered a significant opportunity for further improvements, with 412\\na resolution of 10 m aiding the mapping of smaller fringing features and the increase temporal 413\\nresolution aiding the generation of cloud free composites. 414\\nThere are also some areas where mangroves are known to have been omitted in this version 415\\n(v2.0) of the GMW dataset, due to satellite data unavailability, including: Andaman and Nicobar 416\\nIslands (India), Bermuda (U.K.), Europa Island (France), Fiji, east of Anti-meridian, Guam and Saipan 417\\n(U.S.A.), Kiribati, Maldives, Peru (south of latitude S4) and Wallis and Futuna Islands (France). While 418\\nthese are not significant in terms of mangrove extent globally, which is the focus of this paper, they 419\\nwill be included in the release of future GMW datasets. 420\\n5. Conclusions 421\\nThis study is the first to establish a global baseline map of mangrove extent from Earth 422\\nObservation data, using a globally consistent methodology that is automated and reproducible. To 423\\nproduce the baseline a series of steps were undertaken: a) classification of coastal water; b) definition 424\\nof mangrove habitat regions; c) classification of mangrove areas using the ALOS PALSAR data; d) 425\\nrefinement of the mangrove extent map using a classification of a Landsat composite and e) finally a 426\\nmanual quality assurance process was undertaken where edits where applied to improve the overall 427\\nquality of the mangrove extent map. The new global mangrove map represents an improvement on 428\\nexisting products and provides a basis for assessing change over all mangrove regions with a precision 429\\nof approximately 1 ha. 430\\nThe new global mangrove map demonstrated a high degree of accuracy with a 99 % likelihood 431\\nthat the confidence interval for the overall mangrove accuracy was between 93.6\\u201394.5 %. The baseline 432\\nhas mapped 137,600 km2of mangroves with 38.7 % found in Asia, 20.3 % in Latin America and the 433\\nCaribbean, 20 % in Africa, 11.9 % in Oceania, 8.4 % in North America and 0.7 % in the European 434\\nOverseas Territories. This new globally consistent baseline can form the basis of an operational 435\\nmangrove monitoring system using the JAXA JERS-1 SAR, ALOS PALSAR and ALOS-2 PALSAR-2 436\\nto assess global mangrove change from 1996 to present, providing a valuable tool for policy makers 437\\nand land managers. 438\\nFigure 12. A drone photograph looking over part of the Xu\\u00e2n Th/uni1EE7y National Park, on the Red\\nRiver Delta, Vietnam (March 2018). The photograph illustrates an area of aquaculture with highly\\nfragmented mangroves.\\n5. Conclusions\\nThis study is the first to establish a global baseline map of mangrove extent from Earth Observation\\ndata, using a globally consistent methodology that is automated and reproducible. To produce the\\nbaseline, the following steps were undertaken: (a) classification of coastal water; (b) definition of\\nmangrove habitat regions; (c) classification of mangrove areas using the ALOS PALSAR data; (d)\\nrefinement of the mangrove extent map using a classification of a Landsat composite; and (e) a manual\\nquality assurance process where edits were applied to improve the overall quality of the mangrove\\nextent map. The new global mangrove map represents an improvement on existing products and\\nprovides a basis for assessing change over all mangrove regions with a precision of approximately 1 ha.\\nThe new global mangrove map demonstrated a high degree of accuracy with a 99% likelihood that\\nthe confidence interval for the overall mangrove accuracy was 93.6\\u201394.5%. The baseline has mapped\\n137,600 km2of mangrove with 38.7% found in Asia, 20.3% in Latin America and the Caribbean, 20%\\nin Africa, 11.9% in Oceania, 8.4% in North America and 0.7% in the European Overseas Territories.\\nThis new globally consistent baseline can form the basis of an operational mangrove monitoring system\\nusing the JAXA JERS-1 SAR, ALOS PALSAR and ALOS-2 PALSAR-2 to assess global mangrove change\\nfrom 1996 to present, providing a valuable tool for policy makers and land managers.Remote Sens. 2018,10, 1669 17 of 19\\nAuthor Contributions: Conceptualisation, A.R., R.M.L., L.-M.R., M.S. and C.M.F.; Data curation, A.R., R.M.L.,\\nL.H., T.I. and M.S.; Funding acquisition, P.B. and L.H.; Methodology, P.B., A.R., R.M.L., N.T. and A.H.; Project\\nadministration, A.R.; Resources, L.H., T.I., M.S. and C.M.F.; Software, P.B. and N.T.; Validation, P.B., A.R., R.M.L.\\nand A.H.; Writing\\u2014Original draft, P.B. and A.R.; and Writing\\u2014Review and editing, P.B., A.R., R.M.L., L.-M.R.,\\nL.H., N.T. and A.H.\\nFunding: Funding was provided for this study through the \\u201cMangrove Capital Africa\\u201d project funded by DOB\\nEcology and the RCUK NERC funded project \\u201cMOnitoring Mangrove ExteNT & Services (MOMENTS): What is\\ncontrolling Tipping Points?\\u201d as part of the Newton Fund (NE/P014127/1).\\nAcknowledgments: This project was undertaken in part within the framework of the JAXA Kyoto & Carbon\\nInitiative. JAXA and RESTEC are thanked for the provision of the SAR datasets used within this study.\\nSuperComputing Wales (SCW) are also thanked for supporting the project through the provision of the High\\nPerformance Computing (HPC) facility on which all the data were analysed.\\nConflicts of Interest: The authors declare no conflict of interest.\\nReferences\\n1. Giri, C.; Ochieng, E.; Tieszen, L.L.; Zhu, Z.; Singh, A.; Loveland, T.; Masek, J.; Duke, N. Status and distribution\\nof mangrove forests of the world using earth observation satellite data. Glob. Ecol. Biogeogr. 2011,20, 154\\u2013159.\\n[CrossRef]\\n2. Spalding, M.; Kainuma, M.; Collins, L. World Atlas of Mangroves (Version 3) ; Routledge: London, UK, 2010.\\n3. Spalding, M.; Blasco, F.; Field, C. World Atlas of Mangroves ; The International Society for Mangrove\\nEcosystems: Okinawa, Japan, 1997.\\n4. FAO. Loss of Mangroves Alarming ; Food and Agriculture Organization of the United Nations: Rome, Italy, 2008.\\n5. Roma \\u02dcnach, S.S.; DeAngelis, D.L.; Koh, H.L.; Li, Y.; Teh, S.Y.; Raja Barizan, R.S.; Zhai, L. Conservation and\\nrestoration of mangroves: Global status, perspectives, and prognosis. Ocean Coast. Manag. 2018,154, 72\\u201382.\\n[CrossRef]\\n6. Thomas, N.; Lucas, R.; Bunting, P.; Hardy, A.; Rosenqvist, A.; Simard, M. Distribution and drivers of global\\nmangrove forest change, 1996\\u20132010. PLoS ONE 2017,12, e0179302. [CrossRef] [PubMed]\\n7. Malik, A.; Fensholt, R.; Mertz, O. Mangrove exploitation effects on biodiversity and ecosystem services.\\nBiodivers. Conserv. 2015,24, 3543\\u20133557. [CrossRef]\\n8. Donato, D.C.; Kauffman, J.B.; Murdiyarso, D.; Kurnianto, S.; Stidham, M.; Kanninen, M. Mangroves among\\nthe most carbon-rich forests in the tropics. Nat. Geosci. 2011,4, 293\\u2013297. [CrossRef]\\n9. Swamy, L.; Drazen, E.; Johnson, W.R.; Bukoski, J.J. The future of tropical forests under the United Nations\\nSustainable Development Goals. J. Sustain. For. 2017,37, 221\\u2013256. [CrossRef]\\n10. FAO. Status and Trends in Mangrove Area Extent Worldwide, by M.L. Wilkie and S. Fortuna ; FAO: Rome, Italy,\\n2003.\\n11. FAO. The World\\u2019s Mangroves 1980\\u20132005 ; Food and Agriculture Organization of the United Nations: Rome,\\nItaly, 2007.\\n12. Lucas, R.M.; Rebelo, L.M.; Rosenqvist, A.; Itoh, T.; Shimada, M.; Simard, M.; Souza-Filho, P.W.; Thomas, N.;\\nTrettin, C.; Accad, A.; et al. Contribution of L-band SAR to systematic global mangrove monitoring.\\nMar. Freshw. Res. 2014,65, 589\\u2013603. [CrossRef]\\n13. Hamilton, S.E.; Casey, D. Creation of a high spatio-temporal resolution global database of continuous\\nmangrove forest cover for the 21st century (CGMFC-21). Glob. Ecol. Biogeogr. 2016,25, 729\\u2013738. [CrossRef]\\n14. Hansen, M.C.; Potapov, P.V.; Moore, R.; Hancher, M.; Turubanova, S.A.; Tyukavina, A.; Thau, D.;\\nStehman, S.V.; Goetz, S.J.; Loveland, T.R.; et al. High-Resolution Global Maps of 21st-Century Forest\\nCover Change. Science 2013,342, 850\\u2013853. [CrossRef] [PubMed]\\n15. Rakotomavo, A.; Fromard, F. Dynamics of mangrove forests in the Mangoky River delta, Madagascar,\\nunder the influence of natural and human factors. For. Ecol. Manag. 2010,259, 1161\\u20131169. [CrossRef]\\n16. Tong, P.H.S.; Auda, Y.; Populus, J.; Aizpuru, M.; Habshi, A.A.; Blasco, F. Assessment from space of\\nmangroves evolution in the Mekong Delta, in relation to extensive shrimp farming. Int. J. Remote Sens. 2004,\\n25, 4795\\u20134812. [CrossRef]\\n17. Ferreira, M.A.; Andrade, F.; Bandeira, S.O.; Cardoso, P.; Mendes, R.N.; Paula, J. Analysis of cover change\\n(1995\\u20132005) of Tanzania/Mozambique trans-boundary mangroves using Landsat imagery. Aquat. Conserv.\\n2009,19, S38\\u2013S45. [CrossRef]Remote Sens. 2018,10, 1669 18 of 19\\n18. Long, J.B.; Giri, C. Mapping the Philippines\\u2019 Mangrove Forests Using Landsat Imagery. Sensors 2011,\\n11, 2972\\u20132981. [CrossRef] [PubMed]\\n19. Kirui, K.B.; Kairo, J.G.; Bosire, J.; Viergever, K.M.; Rudra, S.; Huxham, M.; Briers, R.A. Mapping of mangrove\\nforest land cover change along the Kenya coastline using Landsat imagery. Ocean Coast. Manag. 2013,\\n83, 19\\u201324. [CrossRef]\\n20. CONABIO. Distribuci\\u00f3n de los Manglares en M\\u00e9xico en 2015\\u2019, Escala: 1:50000. Edici\\u00f3N: 1 ; Comisi\\u00f3n Nacional\\npara el Conocimiento y Uso de la Biodiversidad. Sistema de Monitoreo de los Manglares de M\\u00e9xico (SMMM):\\nCiudad de M\\u00e9xico, Mexico, 2016.\\n21. Nascimento, W.R., Jr.; Souza Filho, P.W.M.; Proisy, C.; Lucas, R.M.; Rosenqvist, A. Mapping changes in\\nthe largest continuous Amazonian mangrove belt using object-based classification of multisensor satellite\\nimagery. Estuar. Coast. Shelf Sci. 2013,117, 83\\u201393. [CrossRef]\\n22. Thomas, N.; Bunting, P.; Hardy, A.; Lucas, R.; Rosenqvist, A.; Fatoyinbo, T. Mapping mangrove baseline and\\ntime-series change extent: A global monitoring approach. Remote Sens. 2018,10, 1466. [CrossRef]\\n23. Heumann, B.W. An Object-Based Classification of Mangroves Using a Hybrid Decision Tree\\u2014Support\\nVector Machine Approach. Remote Sens. 2011,3, 2440\\u20132460. [CrossRef]\\n24. Kovacs, J.M.; de Santiago, F.F.; Bastien, J.; Lafrance, P. An Assessment of Mangroves in Guinea, West Africa,\\nUsing a Field and Remote Sensing Based Approach. Wetlands 2010,30, 773\\u2013782. [CrossRef]\\n25. Bunting, P.; Clewley, D.; Lucas, R.M.; Gillingham, S. The Remote Sensing and GIS Software Library\\n(RSGISLib). Comput. Geosci. 2014,62, 216\\u2013226. [CrossRef]\\n26. Bunting, P.; Gillingham, S. The KEA image file format. Comput. Geosci. 2013,57, 54\\u201358. [CrossRef]\\n27. Pedregosa, F.; Varoquaux, G.; Gramfort, A.; Michel, V.; Thirion, B.; Grisel, O.; Blondel, M.; Prettenhofer, P.;\\nWeiss, R.; Dubourg, V.; et al. Scikit-learn: Machine Learning in Python. J. Mach. Learn. Res. 2011,\\n12, 2825\\u20132830.\\n28. Clewley, D.; Bunting, P.; Shepherd, J.; Gillingham, S.; Flood, N.; Dymond, J.; Lucas, R.; Armston, J.;\\nMoghaddam, M. A Python-Based Open Source System for Geographic Object-Based Image Analysis\\n(GEOBIA) Utilizing Raster Attribute Tables. Remote Sens. 2014,6, 6111\\u20136135. [CrossRef]\\n29. Cottam, A.; Gorelick, N.; Belward, A.S.; Pekel, J.F. High-resolution mapping of global surface water and its\\nlong-term changes. Nature 2016,540, 1\\u201319.\\n30. Soluri, E.A.; Woodson, V.A. World Vector Shoreline. Int. Hydrogr. Rev. 1990,1, 27\\u201335.\\n31. Wessel, P.; Smith, W.H.F. A global, self-consistent, hierarchical, high-resolution shoreline database.\\nJ. Geophys. Res. 1996,101, 8741\\u20138743. [CrossRef]\\n32. Weatherall, P.; Marks, K.M.; Jakobsson, M.; Schmitt, T.; Tani, S.; Arndt, J.E.; Rovere, M.; Chayes, D.; Ferrini, V.;\\nWigley, R. A new digital bathymetric model of the world\\u2019s oceans. Earth Space Sci. 2015,2, 331\\u2013345.\\n[CrossRef]\\n33. Shimada, M.; Itoh, T.; Motohka, T.; Watanabe, M.; Shiraishi, T.; Thapa, R.; Lucas, R. New global\\nforest/non-forest maps from ALOS PALSAR data (2007\\u20132010). Remote Sens. Environ. 2014,155, 13\\u201331.\\n[CrossRef]\\n34. Bunting, P.; Clewley, D. Atmospheric and Radiometric Correction of Satellite Imagery (ARCSI). 2018.\\nAvailable online: https://arcsi.remotesensing.info (accessed on 21 October 2018).\\n35. Chavez, P.S., Jr. An improved dark-object subtraction technique for atmospheric scattering correction of\\nmultispectral data. Remote Sens. Environ. 1988,24, 459\\u2013479. [CrossRef]\\n36. Vermote, E.; Tanre, D.; Deuze, J.; Herman, M.; Morcrette, J. Second Simulation of the Satellite Signal in the\\nSolar Spectrum, 6S: An overview. IEEE Trans. Geosci. Remote Sens. 1997,35, 675\\u2013686. [CrossRef]\\n37. Shepherd, J.D.; Dymond, J.R. Correcting satellite imagery for the variance of reflectance and illumination\\nwith topography. Int. J. Remote Sens. 2003,24, 3503\\u20133514. [CrossRef]\\n38. Zhu, Z.; Woodcock, C.E. Object-based cloud and cloud shadow detection in Landsat imagery.\\nRemote Sens. Environ. 2012,118, 83\\u201394. [CrossRef]\\n39. Zhu, Z.; Wang, S.; Woodcock, C.E. Improvement and expansion of the Fmask algorithm: cloud, cloud\\nshadow, and snow detection for Landsats 4\\u20137, 8, and Sentinel 2 images. Remote Sens. Environ. 2015,\\n159, 269\\u2013277. [CrossRef]\\n40. Holben, B.N. Characteristics of maximum-value composite images from temporal AVHRR data. Int. J.\\nRemote Sens. 1986,7, 1417\\u20131434. [CrossRef]Remote Sens. 2018,10, 1669 19 of 19\\n41. Ramoino, F.; Tutunaru, F.; Pera, F.; Arino, O. Ten-Meter Sentinel-2A Cloud-Free Composite\\u2014Southern Africa\\n2016. Remote Sens. 2017,9, 652. [CrossRef]\\n42. Bunting, P.; Lucas, R.; Jones, K.; Bean, A. Characterisation and mapping of forest communities by clustering\\nindividual tree crowns. Remote Sens. Environ. 2010,114, 2536\\u20132547. [CrossRef]\\n43. Wilson, E.B. Probable inference, the law of succession, and statistical inference. J. Am. Stat. Assoc. 1927,\\n22, 209\\u2013212. [CrossRef]\\nc\\r2018 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access\\narticle distributed under the terms and conditions of the Creative Commons Attribution\\n(CC BY) license (http://creativecommons.org/licenses/by/4.0/).\",\n          \"remote sensing  \\nArticle\\nA New Vegetation Index to Detect Periodically\\nSubmerged Mangrove Forest Using Single-Tide\\nSentinel-2 Imagery\\nMingming Jia1,2\\n, Zongming Wang1,*, Chao Wang2\\n, Dehua Mao1\\nand Yuanzhi Zhang3,4\\n1Key Laboratory of Wetland Ecology and Environment, Northeast Institute of Geography and Agroecology,\\nChinese Academy of Sciences, No. 4888, Shengbei Street, Changchun 130102, China\\n2State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan\\nUniversity, No.129 Luoyu Road, Wuhan 430079, China\\n3Center for Housing Innovations, Chinese University of Hong Kong, Shatin, New Territories, Hong Kong\\n4Key Lab of Lunar Science and Deep-exploration, National Astronomical Observatories, Chinese Academy of\\nSciences, Beijing 100101, China\\n*Correspondence: zongmingwang@iga.ac.cn\\nReceived: 4 July 2019; Accepted: 27 August 2019; Published: 29 August 2019\\n/gid00030/gid00035/gid00032/gid00030/gid00038/gid00001/gid00033/gid00042/gid00045 /gid00001\\n/gid00048/gid00043/gid00031/gid00028/gid00047/gid00032/gid00046\\nAbstract: Mangrove forests are tropical trees and shrubs that grow in sheltered intertidal zones.\\nAccurate mapping of mangrove forests is a great challenge for remote sensing because mangroves are\\nperiodically submerged by tidal \\ufb02oods. Traditionally, multi-tides images were needed to remove the\\nin\\ufb02uence of water; however, such images are often unavailable due to rainy climates and uncertain\\nlocal tidal conditions. Therefore, extracting mangrove forests from a single-tide imagery is of great\\nimportance. In this study, re\\ufb02ectance of red-edge bands in Sentinel-2 imagery were utilized to\\nestablish a new vegetation index that is sensitive to submerged mangrove forests. Speci\\ufb01cally, red\\nand short-wave near infrared bands were used to build a linear baseline; the average re\\ufb02ectance\\nvalue of four red-edge bands above the baseline is de\\ufb01ned as the Mangrove Forest Index (MFI).\\nTo evaluate MFI, capabilities of detecting mangrove forests were quantitatively assessed between\\nMFI and four widely used vegetation indices (VIs). Additionally, the practical roles of MFI were\\nvalidated by applying it to three mangrove forest sites globally. Results showed that: (1) theoretically,\\nJensen\\u2013Shannon divergence demonstrated that a submerged mangrove forest and water pixels have\\nthe largest distance in MFI compared to other VIs. In addition, the boxplot showed that all submerged\\nmangrove forests could be separated from the water background in the MFI image. Furthermore, in\\nthe MFI image, to separate mangrove forests and water, the threshold is a constant that is equal to\\nzero. (2) Practically, after applying the MFI to three global sites, 99\\u2013102% of submerged mangrove\\nforests were successfully extracted by MFI. Although there are still some uncertainties and limitations,\\nthe MFI o \\u000bers great bene\\ufb01ts in accurately mapping mangrove forests as well as other coastal and\\naquatic vegetation worldwide.\\nKeywords: Sentinel-2 MultiSpectral Instrument (MSI); red-edge band; aquatic vegetation; tidal\\ncondition; vegetation index; coastal vegetation\\n1. Introduction\\nMangrove forest are highly productive ecosystems with signi\\ufb01cant ecological and socio- economic\\nimportance in the world [ 1,2]. However, over the past century, these forests have declined at an\\nalarming rate that is more rapid than that of inland tropical forests [ 3]. Therefore, there is an emerging\\ndemand for conservation and restoration e \\u000borts in mangrove forests. Obtaining accurate information\\nRemote Sens. 2019 ,11, 2043; doi:10.3390 /rs11172043 www.mdpi.com /journal /remotesensingRemote Sens. 2019 ,11, 2043 2 of 17\\nregarding the current and past acreage and condition of mangrove forests is essential for e \\u000ecient\\nmanagement of these ecosystems and for policy- and decision-making processes [4,5].\\nLocated in intertidal zones, mangrove forests are often inaccessible for traditional \\ufb01eld surveys.\\nFor decades, remote sensing has been widely used to monitor the distribution of mangrove forests, yet\\naccurate and timely interpretation of the relatively small patches has been rare, due to the lack of full\\nconsideration of tidal conditions [ 6\\u20139]. Mangrove forests located near the shoreline are periodically\\nsubmerged by tides, especially in regions with high tide \\ufb02uctuations and lower mangrove shrubs [ 9,10].\\nIdeally, it is better to use images acquired during low tides; however, such data are di \\u000ecult to obtain,\\ndue to uncertainties of local instantaneous tidal conditions during predetermined times that satellites\\npass over [ 11,12]. For a long time, numerous studies have pointed out that tides may seriously\\nin\\ufb02uence remote sensing results of mangrove forests, yet, solutions were not reported until the past\\ntwo years [ 10,13,14]. However, all these studies used multi-tides (multi-date) images; therefore, we\\nhave one concern: if multi-tides images are not available due to rainy climates and uncertain local tide\\nconditions, how could we accurately map mangrove forests by a single-date image?\\nOver the last two decades, remote sensing of submerged and emerged aquatic vegetation has\\nbeen widely studied [ 15,16]. Hyperspectral image with numerous narrow and contiguous bands is\\nreliable for studying aquatic vegetation and is able to detect the biophysical properties of vegetation\\ne\\u000eciently [ 16\\u201319]. However, there is no freely available satellite hyperspectral data in recent years, and\\nairborne applications are exorbitantly expensive and only cover a very small spatial extent. Landsat\\nimages with moderate spatial resolution of 30\\u201360 m have been widely used for mapping aquatic\\nvegetation [ 20\\u201324]. Yet, Landsat only has one band in the spectral region of near infrared (760\\u2013900 nm),\\nwhich may become less sensitive as water depth increases [ 25]. The MODIS (Moderate Resolution\\nImaging Spectroradiometer) and AVHRR (Advanced Very High Resolution Radiometer) are publicly\\navailable with high spectral resolution but coarse spatial resolution (250\\u20131100 m, respectively), making\\nthem unsuitable for mangrove detection [ 9]. In contrast, the Sentinel-2 MultiSpectral Instrument\\n(MSI) sensor has a 10\\u201320 m spatial resolution and \\ufb01ve bands in near infrared region, which provides\\nopportunities to conduct quick, robust, and e \\u000ecient monitoring of submerged mangrove forests.\\nFor years, numerous methods were utilized to map mangrove forests as well as other aquatic\\nvegetation from remote sensing imagery, ranging from pixel to object-oriented approach, and manual\\nto unsupervised methods [ 9,14,26\\u201328]. Recently, machine-learning algorithms such as random\\nforest, neural network, and support vector machine provide promising accuracy in mangrove forests\\nextraction [ 10,13,29]. As it is hard to locate representative training samples due to uncertain tidal\\nconditions, it is relatively hard to apply these methods to extract submerged mangrove forests from\\na single-date image. Vegetation indices (VIs), which are mathematically determined based on the\\nspectral characteristics of vegetation, have been proven e \\u000ecient in monitoring vegetation from\\nspace [ 30]. The Normalized Di \\u000berence Vegetation Index (NDVI) is the most commonly used index\\nin global vegetation studies (e.g., [ 30,31]). The Land Surface Water Index (LSWI) and the Modi\\ufb01ed\\nNormalized Di \\u000berence Water Index (MNDWI) were proposed and widely used for mapping surface\\nwater [ 32\\u201334]. Given that these indices are established based on di \\u000berences between two bands,\\nthey are insensitive to small variations of the re\\ufb02ectance of submerged mangrove forests and water\\nbackground [ 14]. Furthermore, it is hard to decide thresholds that distinguish submerged mangroves\\nand water. With more bands, several VIs were built based on a baseline theory, such as Maximum\\nChlorophyll Index (MCI; [ 35]), the Floating Algae Index (FAI; [ 36]), and the Floating Vegetation Index\\n(FVI; [ 17]). However, these indices were de\\ufb01ned to extract \\ufb02oating vegetation (above water surface)\\nfrom water, not submerged vegetation. Meanwhile, bands used to build MCI and FVI did not exist in\\nSentinel MSI image.\\nThus, the objective of this study is to develop a new vegetation index, called the Mangrove Forest\\nIndex (MFI), which is capable to map the distribution of mangroves based on a single date MSI image.\\nThen, we will compare MFI with other widely used VIs to validate MFI\\u2019s capabilities in detecting\\nsubmerged mangrove forests from water background. Additionally, MFI will be applied to three sitesRemote Sens. 2019 ,11, 2043 3 of 17\\nof typical mangrove forests worldwide; the practical roles of mapping mangrove forests during local\\nhigh-tide conditions will also be discussed.\\n2. Materials and Methods\\n2.1. Sentinel-2 Imagery\\nSentinel-2, a European Space Agency (ESA) land-monitoring mission, has two matching satellites\\nthat provide high-resolution optical imagery. Sentinel-2A and Sentinel-2B carry the MultiSpectral\\nInstrument (MSI) and were successfully launched in June 2015 and March 2017 respectively and\\nprovide important means to augment earth observation capabilities [ 37]. These satellites revisit the\\nsame location every 2 to 5 days. The MSI sensor o \\u000bers 13 spectral bands, with four bands at 10 m, six\\nbands at 20 m, and three bands at a 60 m spatial resolution (Table 1) and o \\u000bers a wide range of earth\\nobservation applications [38].\\nIn this study, Sentinel-2 MSI images were downloaded from European Space Agency Sentinels\\nScienti\\ufb01c Data Hub; the images were preprocessed with geometric and radiometric corrections at\\nsub-pixel accuracy. Then, atmospheric correction (converting top-of-atmosphere re\\ufb02ectance into\\ntop-of-canopy re\\ufb02ectance) was performed by the tool of SEN2COR (version 2.05.05), which was\\navailable in the Sentinel Application Platform (SNAP) toolbox [ 39,40]. In order to standardize di \\u000berent\\nspatial resolutions of bands in MSI images, we excluded bands with a spatial resolution of 60 m (Band\\n1, Band 9, and Band 10). After atmospheric correction, all remaining bands were resampled to a pixel\\nsize of 20 m\\u000220 m.\\nTable 1. General characteristics of the Sentinal-2 MultiSpectral Instrument (MSI) sensor.\\nMSI Band Band NameWavelength\\n(Central, nm)Spectral Width\\n(nm)Spatial Resolution\\n(m)\\nB1 Aerosols 443 20 60\\nB2 Blue 490 65 10\\nB3 Green 560 35 10\\nB4 Red 665 30 10\\nB5 Vegetation red-edge 705 15 20\\nB6 Vegetation red-edge 740 15 20\\nB7 Vegetation red-edge 783 20 20\\nB8 Near infrared 842 115 10\\nB8A Vegetation red-edge 865 20 20\\nB9 Water-vapor 945 20 60\\nB10 Cirrus 1380 30 60\\nB11Shortwave-infrared\\nre\\ufb02ectance (SWIR)11610 90 20\\nB12 SWIR2 2190 180 20\\n2.2. Study Area\\nThe study area, Zhenzhu Harbor (21\\u000e280\\u201321\\u000e420N and 108\\u000e000\\u2013108\\u000e200N), is located in Guangxi\\nProvince, China, in the southwest portion of mainland China and the north region of Tonkin Gulf\\n(Figure 1). In Zhenzhu Harbor, mangrove forests are mainly composed of four communities: Comm. A.\\nmarina, Comm. A. corniculatum, Comm. A. marina\\u2013A. corniculatum, and Comm. K. candel\\u2013A. corniculatum .\\nThe tides in the coast of Zhenzhu Harbor are diurnal, with an average tidal range of 2.24 m, and\\nmangrove forests here are primarily younger shrubs with an average height of less than 3 m [ 7].\\nTherefore, the Zhenzhu Harbor is a typical area for the study of submerged mangrove forests, due to a\\nlarge area of pioneer mangrove trees and shrubs that would be entirely submerged during high tides\\n(Figure 1A,B). Information of MSI images we selected are shown in Table 2.Remote Sens. 2019 ,11, 2043 4 of 17\\nAdditionally, a \\ufb01eld survey of Zhenzhu Harbor was conducted during April 2017, in which 408\\nground truth samples were collected including samples of mangrove forest, open water, and other\\nland cover.\\nFigure 1. Snapshots of low- and high-tide Sentinel MSI images of study area (( A) during local low\\ntide all mangrove forests were emerged; ( B) during local high tide some of the mangrove forests were\\nsubmerged).\\nTable 2. Description of satellite data, including the path, row, date, time of acquisition, and tide level of\\nthe nearest tide station (Fangcheng Harbor Station, 108\\u000e140E, 21\\u000e280N).\\nSensor Path Row Date Time (hh:mm) Tide Height (m)\\nMSI 205 118 2017-12-17 11:23 \\u00000.9\\nMSI 205 118 2017-09-28 16:37 1.8\\n2.3. Build a Reference Map\\nGround surveys were conducted along the coasts of Zhenzhu Harbor in November 2017. The\\nlocation of each sampling point was measured using a global positioning system (GPS), with an error\\nless than 1 m. The observations collected in the surveys contained 85 mangrove points and 81 water\\npoints. A vector \\ufb01le of ground survey points with the attributes of location (longitude and latitude),\\nland cover types, and photos was created with ArcGIS.\\nThe spectral curves of water, submerged mangrove forests, and emerged mangrove forests were\\nextracted from images. The work\\ufb02ow of discriminating these classes is shown in Figure 2. A reference\\nmap was built based on object-oriented methods and visual interpretation.\\nThe description of the object-oriented method can be found in Harayama and Jaquet [ 41]. The\\neCognition Developer 9.0, an image analysis program, was used to conduct object-oriented classi\\ufb01cation.\\nVisual interpretation was performed to classify objects as either mangrove forests or water. To facilitateRemote Sens. 2019 ,11, 2043 5 of 17\\nvisual interpretation, a false color composite of MSI Bands 11 (centered 1610 nm), Band 8 (centered\\n842 nm), and Band 4 (centered 665 nm) was generated. This band combination that was deemed the\\nbest for detecting mangroves which appears dark green color [ 42]. Furthermore, in order to conduct the\\nadjustment in a robust manner, visual interpretation was performed by an experienced remote sensing\\nexpert who was familiar with this area. First, we identi\\ufb01ed mangrove forest and surrounding water\\nfrom the low-tide MSI image. Subsequently, a confusion matrix was generated using the independent\\nground-truth samples described in Section 2.2. With this matrix, we achieved an overall classi\\ufb01cation\\naccuracy of 97% with a Kappa coe \\u000ecient of 0.92, which indicated excellent agreements between our\\nmapping results and ground-truth data. Therefore, mangrove forests identi\\ufb01ed with this method\\nwere assumed to cover entire area of local mangrove forests. Second, using the same techniques as\\nabove, mangrove forests were identi\\ufb01ed from the high-tide MSI image. Finally, the extent of the\\nsubmerged mangrove was determined by subtracting the high-tide from the low-tide mangrove forest\\nmap. Figure 3 shows the distributions of emerged mangrove forests and submerged mangrove forests\\nin the high-tidal MSI image.\\nFigure 2. Work \\ufb02ow for identifying submerge mangrove forests.Remote Sens. 2019 ,11, 2043 6 of 17\\nFigure 3. Distribution of emerged and submerged mangrove forests in high-tide MSI image.\\n2.4. Theories\\nFigure 4 shows the \\ufb01eld measurements of spectral curves of the water, emerged vegetation,\\nand submerged vegetation, generated by Chen et al. (2018; Figure 4A) and Visser et al. (2015;\\nFigure 4B) [ 15,25]. As normal green plants, vegetation above the water surface showed high re\\ufb02ectance\\nin the spectral region of 770\\u2013890 nm. Waterbody is characterized by low re\\ufb02ectance in near infrared at\\n700 nm while emerged mangrove has a relatively high re\\ufb02ectance, which make them separable from\\neach other. However, when mangroves are submerged under water, the re\\ufb02ectance is largely reduced,\\ntherefore, it is di \\u000ecult to distinguish submerged vegetation from waterbody [ 15,25,43]. As measured,\\nwhen submerged vegetation are 43\\u201351 cm below clear water, the NDVI value was close to zero, which\\nmeans no di \\u000berences were observed between the red band and NIR band [44].\\nHowever, by careful inspection of the spectral curves shown in Figure 4A,B, two re\\ufb02ectance\\npeaks ranging from approximately 690\\u2013740 nm and 810\\u2013830 nm were found, even for the curves of\\nvegetation located 40 cm below the water surface. These peaks result from the competing e \\u000bects\\nof the chlorophyll re\\ufb02ectance plateau and the absorption e \\u000bects of water located within submerged\\nvegetation and the surrounding water background. However, traditional multispectral satellite sensors\\ncould not capture these re\\ufb02ectance peaks. Fortunately, the MSI sensor has \\ufb01ve channels that cover\\nthese regions. Figure 5 shows the typical spectral curves of water (WB), emerged mangrove forest\\n(EMF), and submerged mangrove forest (SMF) that are observed on the MSI image. As shown in\\nFigure 5, the emerged and shallow submerged mangrove forest pixels demonstrated a strong re\\ufb02ection\\nin the region of 660\\u2013900 nm, the absorption valleys appeared in bands 4 (centered wavelength 665 nm)\\nand 12 (centered 2160 nm). For the submerged mangrove forest (b) curves, a small re\\ufb02ectance peak\\nappeared in the 660\\u2013900 nm region; the absorption valley also appeared in bands 4 (centered 665 nm)\\nand 12 (centered 2160 nm). The re\\ufb02ectance of the water pixels shows a continuous decreasing tendency\\nbeginning with band 4 (central wavelength 665 nm). Therefore, comparing submerged curves to water\\ncurves, the higher re\\ufb02ectance in bands 5 (centered 705 nm), 6 (centered 740 nm), 7 (centered 783 nm),\\n8 (centered 842 nm), and 8A (centered 865 nm) could be used to distinguish submerged mangrove\\nforests from the water background.Remote Sens. 2019 ,11, 2043 7 of 17\\nFigure 4. The spectral curves of water, emerged, and submerged vegetation, as well as the absorption\\ncoe\\u000ecients of water (cm\\u00001). ((A) \\ufb01eld-measurement [ 15]; (B) \\ufb01eld-measured of submerged vegetation\\u2019s\\nre\\ufb02ectance at 1.5, 16, and 40 cm below water surface [25]).\\nFigure 5. (A) Typical spectral curves of emerged (EMF), submerged mangrove forests (SMF) and water\\n(WB) in Sentinel-2A MSI image. ( B) EMF and SMF forests in Sentinel MSI image and \\ufb01eld photo. ( a)\\nRepresents shallow submerged mangrove forests (0\\u201330 cm), ( b) Represents deep submerged mangrove\\nforests (30\\u201360 cm).\\n2.5. Existing Vegetation Indices\\nPreviously, NDVI (Equation 1), LSWI (Equation 2), and MNDWI (Equation 3) and FAI (Equation\\n4) were used in detecting vegetation from water bodies [33,34,45].\\nNDVI =\\u001aNIR\\u0000\\u001aRed\\n\\u001aNIR+\\u001aRed(1)\\nLSWI =\\u001aNIR\\u0000\\u001aSWIR\\n\\u001aNIR+\\u001aSWIR(2)\\nMNDWI =\\u001aGreen\\u0000\\u001aSWIR\\n\\u001aGreen +\\u001aSWIR(3)\\nFAI=\\b\\u001a860\\u0000[\\u001a1240+(\\u001a660\\u0000\\u001a1240)\\u0002(1240\\u0000860)/(1240\\u0000660)]\\t(4)\\nwhere\\u001aGreen ,\\u001aRed,\\u001aNIR, and\\u001aSWIR are the re\\ufb02ectance of the green, red, NIR, and SWIR, respectively.\\nHowever, these indices are not suitable for discerning submerged vegetation from water bodies,\\nbecause there are no obvious re\\ufb02ectance di \\u000berences in bands green, red, and SWIR between submerged\\nvegetation and water bodies (Figures 4 and 5).Remote Sens. 2019 ,11, 2043 8 of 17\\n2.6. Formulation of MFI\\nFor this study, according to the analysis in Section 2.4, the absorption valleys in band 4 (centered\\n665 nm) and band 12 (centered 2190 nm) could be used to form a baseline (Figure 6). In order to\\nenhance the stability of di \\u000berences between submerged mangrove forests and the water background,\\nthe average value of re\\ufb02ectance of band 5 (centered 705 nm), band 6 (centered 740 nm), band 7 (centered\\n783 nm), and band 8A (centered 865 nm) above the baseline, is de\\ufb01ned as MFI. Band 8 was excluded\\nbecause Bands 7 (centered 783 nm) and 8A (centered 865 nm) covered most of its spectra, and its\\nspectral range overlaps with the water absorption region. The mathematical formulation is\\nMFI =h\\n(\\u001a\\u00151\\u0000\\u001aB\\u00151)+(\\u001a\\u00152\\u0000\\u001aB\\u00152)+(\\u001a\\u00153\\u0000\\u001aB\\u00153)+(\\u001a\\u00154\\u0000\\u001aB\\u00154\\u0011\\n]/4 (5)\\n\\u001aB\\u0015i=\\u001a2190+(\\u001a665\\u0000\\u001a2190)\\u0002(2190\\u0000\\u0015i)/(2190\\u0000665) (6)\\nwhere the \\u001a\\u0015is the re\\ufb02ectance of the band center of \\u0015, and iranged from 1 to 4; \\u00151,\\u00152,\\u00153,\\u00154represent\\nthe center wavelengths at 705, 740, 783 and 865 nm, respectively. \\u001aB\\u0015iis the baseline re\\ufb02ectance in\\n\\u0015i.\\u001a665and\\u001a2190are the re\\ufb02ectance of band 4 (centered at 665 nm) and 12 (centered at 2190 nm),\\nrespectively. Pixels with an MFI value above 0 are recognized as mangrove forests.\\nFigure 6. Baseline theory of establishing Mangrove Forest Index (MFI), including re\\ufb02ectance of\\nsubmerged mangrove forest and water.\\n2.7. Quantitative Comparison between MFI and Other VIs\\nIn this study, Jensen\\u2013Shannon divergence (JSD)\\u2014a measure of distance between a \\ufb01nite number\\nof distributions\\u2014was adopted to compare sensitivities of MFI and other VIs. The JSD ( D) quanti\\ufb01es\\nthe di \\u000berence between two or more probability distributions. In this study, it was used to compare\\nthe di \\u000berences between submerged mangrove forests and water pixels in di \\u000berent VI images. The\\nDvalue, which was calculated in MATLAB, is de\\ufb01ned as follows: let p(1)\\u0011(p(1)\\n1,p(1)\\n2,:::,p(1)\\nk)\\nand p(2)\\u0011\\u0012\\np(2)\\n1,p(2)\\n2,:::,p(2)\\nk\\u0013\\ndenote two probability distributions satisfying the usual constraints\\nPk\\ni=1p(j)\\ni=1and 0\\u0014p(j)\\ni\\u00141for all i=1,2,:::,k and j=1,2; and let \\u0019(1)and\\u0019(2)denote the weights\\nof the distributions p(1)and p(2), satisfying the constraints \\u0019(1)+\\u0019(2)=1and 0\\u0014\\u0019(j)\\u00141. Then theRemote Sens. 2019 ,11, 2043 9 of 17\\nJensen\\u2013Shannon divergence Dbetween the probability distributions p(1)and p(2)with weights \\u0019(1)\\nand\\u0019(2)is de\\ufb01ned by [46]:\\nDh\\np(1),p(2)i\\n\\u0011Hh\\n\\u0019(1)p(1)+\\u0019(2)p(2)i\\n\\u0000\\u0010\\n\\u0019(1)Hh\\np(1)i\\n+\\u0019(2)Hh\\np(2)i\\u0011\\n(7)\\nwhere\\nH[p]=\\u0000Xk\\ni=1pilog2pi (8)\\ndenotes the Shannon entropy of the probability distribution p\\u0011(p1,p2,:::pk).Dranging from 0\\u20131, 0\\nmeans no di \\u000berence between distributions, 1 means the distributions are completely di \\u000berent.\\n3. Results\\n3.1. Quantitative Comparison of MFI, FAI, NDVI, LSWI, and MNDWI\\nTo compare the ability to distinguish submerged mangrove forests from the water background,\\nthe VIs values of all submerged mangrove forests (in total 12,001 pixels extracted in Section 2.3), and\\n22,668 pixels of water in the high-tidal MSI image (acquired on 28 September 2017) were calculated.\\nAdditionally, to make the di \\u000berent VIs comparable, the MFI and FAI were calculated to 10 times of their\\noriginal values. The boxplots of submerged mangrove forests and water pixels are shown in Figure 7.\\nFigure 7. Boxplot of di \\u000berent index values over submerged mangrove forest pixels and water pixels\\n(MFI and Floating Algae Index (FAI) are 10 times their original value. SMF means submerged mangrove\\nforest, WB means Water Body. The horizontal axis represents di \\u000berent indices).\\nAs shown in Figure 7, all submerged mangrove forest pixels have higher MFI values than those of\\nthe water background, the minimum value of submerged mangrove forests is equal to the maximal\\nvalue of water. Most of the water pixels are confused with submerged mangrove forests in FAI, NDVI,\\nand NDWI image. According to our calculations, the Dvalues of MFI, FAI, NDVI, LSWI, and MNDWI\\nare 0.209, 0.077, 0.012, 0.003, and 0.121, respectively, which means pixels of submerged mangrove\\nforests and water are better separated in an MFI image than other VIs.Remote Sens. 2019 ,11, 2043 10 of 17\\n3.2. Evaluation of MFI at Di \\u000berent Mangrove Forests around the World\\nGlobally, three selected mangrove forest sites were chosen to demonstrate the practical utility\\nof our newly formed index (MFI) in distinguishing mangrove forests from water background. They\\nare (a) Zhenzhu Harbor, Guangxi, China, (b) Dalhousie Island, Sundarbans, India, (c) Baia do Arraial,\\nAmazon Coast, Brazil. Locations are shown in Figure 8.\\nFigure 8. Global study sites of mangrove forests. (Displayed imagery: R:G:B =Sentinel MSI Band 8A:\\n4:3. ( a) Zhenzhu Harbor, Guangxi, China; ( b) Dalhousie Island, Sundarbans, India; ( c) Baia do Arraial,\\nAmazon Coast, Brazil).\\nClassi\\ufb01cation accuracy assessment is essential for validating the performance of the MFI index.\\nIn this study, a table containing the overall accuracy, user\\u2019s accuracy, producer\\u2019s accuracy, and the\\nKappa coe \\u000ecient of each site were presented in Table 3. In Zhenzhu Harbor, the validation samples\\nwere collected from \\ufb01eld survey. In Dalhousie Island and Baja do Arraial, validation samples were\\nrandomly selected from Google Earth high-resolution images.Remote Sens. 2019 ,11, 2043 11 of 17\\nTable 3. Confusion matrix for worldwide study sites of mangrove forests, including overall accuracy,\\nproducer\\u2019s accuracy, user\\u2019s accuracy, and Kappa coe \\u000ecient.\\nZhenzhu Harbor\\nLand CoverClassi\\ufb01cation Results\\nMangrove Water Producer\\u2019s Accuracy\\nMangrove 82 3 96.4%\\nWater 2 79 97.5%\\nUser\\u2019s accuracy 97.6% 96.3% \\u2013\\nOverall accuracy 97.0% Kappa coe \\u000ecient 0.94\\nDalhousie Island Mangrove Water Producer\\u2019s accuracy\\nMangrove 52 1 98.1%\\nWater 2 39 95.1%\\nUser\\u2019s accuracy 96.2% 97.5% \\u2013\\nOverall accuracy 96.8% Kappa coe \\u000ecient 0.93\\nBaja do Arraial Mangrove Water Producer\\u2019s accuracy\\nMangrove 30 3 90.9%\\nWater 3 36 92.3%\\nUser\\u2019s accuracy 90.9% 92.3% \\u2013\\nOverall accuracy 91.7% Kappa coe \\u000ecient 0.83\\n3.2.1. Zhenzhu Harbor, Guangxi, China\\nMFI was applied to the high-tidal Sentinel MSI image (acquired 2017-09-28). Figure 9 shows\\nthe MFI image (Figure 9A), mangrove forest distribution classi\\ufb01ed from MFI image (Figure 9B), and\\nreference map (Figure 9C) derived from low-tide Sentinel MSI images (described in Section 2.3).\\nAccording to the results shown in the reference map (Figure 9C), the total area of mangrove forests was\\n856.30 ha, with 107.05 ha of submerged and 749.25 ha of emerged mangrove forests. In Figure 9B, the\\ntotal area of mangrove forest we classi\\ufb01ed from the MFI image was 849.4 ha, which means 99% of the\\nmangrove forest pixels were successfully extracted from water background by the MFI. According to\\nTable 3, the overall accuracy of this mangrove map is 97% with a Kappa coe \\u000ecient of 0.94. In Zhenzhu\\nHarbor, the MFI value of emerged mangrove forests, submerged mangrove forests, and water pixels\\nrange from 0.19 to 0.30, \\u00000.01 to 0.18, and\\u00000.2 to\\u00000.01.\\nFigure 9. Apply the MFI to extract mangrove forests in Zhenzhu Harbor, Guangxi, China. ( A) MFI\\nimage, ( B) mangrove forests extracted from MFI image, and ( C) reference map.\\n3.2.2. Dalhousie Island, Sundarbans, India\\nSundarbans has the biggest patch of mangrove forest \\ufb02ourishing on the world\\u2019s largest delta\\n(Ganga\\u2013Bramhaputra\\u2013Meghna Delta; [ 47]). The tidal amplitude within the estuary ranges from 3.5\\nto 4 m, with seasonal variation between 1 and 6 m; mangrove forests are periodically submerged\\nduring high tide [ 48,49]. In this study, Dalhousie Island (located in the southern part of Sundarbans,\\nIndia) was chosen as a typical area to validate the performance of the MFI. Figure 10 shows a local\\nhigh-tidal MSI image (Figure 10A, captured on 2016-10-17), the MFI-derived image (Figure 10B), andRemote Sens. 2019 ,11, 2043 12 of 17\\nground-truth images obtained by Google Earth snapshot (Figure 10a\\u2013c). As shown in Figure 10A, in\\nmangrove swamps, a number of patches seem similar to seawater. In Figure 10a\\u2013c, although these\\npatches show white tones, they are lower and sparser mangrove forests that are intermittently \\ufb02ooded\\nby tides. Fortunately, these patches have positive values in the MFI image (Figure 10B). According to\\nMondal and Saha (2018), Dalhousie Island had 5950 ha of mangrove forests on 2015-08-03 [ 50]. In the\\nMFI image, the extent of mangrove extracted by the MFI is 6105 ha (pixels with positive MFI values),\\naccounting for 102% of Mondal and Saha\\u2019s result. Although the MSI image was captured during high\\ntide, almost all the local mangrove forests were detected by the MFI. According to Table 3, the overall\\naccuracy of this mangrove map is 96.8%, with a Kappa coe \\u000ecient of 0.93. In Dalhousie Island, the MFI\\nvalue of emerged mangrove forests, submerged mangrove forests, and water pixels range from 0.11 to\\n0.25, 0 to 0.10, and \\u20130.03 to 0.\\nFigure 10. Apply the MFI to extract mangrove forests in Dalhousie Island, Sundarbans, India. ( A)\\nSentinel MSI image (Band combination: R:G:B =8A: 4: 3); ( B) Sentinel MSI-based MFI image; ( a\\u2013c):\\nGoogle Earth snapshot.\\n3.2.3. Baia do Arraial, Amazon Coast, Brazil\\nBaia do Arraial is located along the south coasts of S \\u00e3o Lu \\u00eds city, Brazil (Figure 11). The coastal\\nzone of S \\u00e3o Lu \\u00eds is dominated by a semidiurnal tide; the high energy causes a maximum tidal height\\nof 8 m during the equinoctial spring tide. Therefore, numerous mangrove trees and shrubs would\\nbe submerged during high tides. As shown in Figure 11A, on 2018-06-14, patches in the northwest\\nand the middle of mangrove swamps were submerged; fortunately, these mangrove forests showed\\npositive values in Figure 11B, and the snapshot of Google Earth images con\\ufb01rmed that these places\\nwere occupied by low mangrove forests. Therefore, we concluded that submerged mangrove forests\\nin Baia do Arraial could be detected by the MFI. According to Table 3, the overall accuracy of this\\nmangrove map is 91.7%, with a Kappa coe \\u000ecient of 0.83. In Baia do Arraial, the MFI values of emerged\\nmangrove forests, submerged mangrove forests, and water pixels range from 0.09 to 0.25, 0 to 0.09, and\\n\\u00000.06 to 0.Remote Sens. 2019 ,11, 2043 13 of 17\\nFigure 11. Apply the MFI to extract mangrove forests in Baia do Arraial, Amazon Coast, Brazil. ( A)\\nSentinel MSI image (band combination: R:G:B =8A: 4: 3), ( B) Sentinel MSI based MFI image, ( a,b):\\nGoogle Earth snapshot.\\n4. Discussion\\n4.1. Advantages and Potential Applications of MFI\\nLocated along intertidal zones, mangrove forests are always relatively small patches; therefore,\\nmisclassi\\ufb01cation of a small area would greatly a \\u000bect mapping results. The lack of full consideration\\nof tidal conditions would cause misclassi\\ufb01cation between mangrove forests and water background.\\nTo accurately map and manage mangrove forests, in this study, we attempt to extract all mangrove\\nforests during local high tides. Undeniably, using VIs to extract mangrove forests is not new. All the\\ncommonly used indices are applicable to detecting emerged mangrove forests. However, during high\\ntides, according to our statistics in Figure 7, in LSWI, MNDWI, NDVI, and FAI images 27%, 8%, 19%,\\nand 5% of submerged pixels were mixed with water background. Furthermore, based on the result of\\nJensen\\u2013Shannon divergence, MFI greatly increased the distance of submerged mangrove forests and\\nwater. However, in the MFI image, nearly all the submerged pixels were completely separated from\\nthe water background. Furthermore, all traditional vegetation indices have a vital uncertainty, that\\nallow for the determination of the threshold of VIs. Fortunately, based on the theory of being above\\nthe baseline, one advantage of using the MFI in detecting mangrove forests is that the threshold is at\\nthe \\ufb01xed value of zero.\\nThis study provides an index built by Sentinel-2 MSI bands for discriminating submerged\\nmangrove forests from water background. It supports the \\ufb01ndings of previous studies that the NIR\\nand red-edge provide great opportunities in discriminating between vegetation and water. Sentinel-2\\nMSI image contains \\ufb01ve bands in NIR region, four of which were used to build the MFI. The FAI was\\nalso established based on baseline theory, but with one NIR band. However, according to Figure 7\\nand our statistics, unlike MFI (completely separated submerged mangrove forest and water), in the\\nFAI image, 5% of submerged mangrove forests pixels were mixed with water pixels. This is primarily\\nbecause unexpected \\ufb02uctuation in one NIR band could greatly a \\u000bect the value of the FAI. The four MSI\\nred-edge bands demonstrated relatively stable discrimination between submerged mangrove forest\\nand water.\\nTheoretically, the MFI concept can be applied to other sensors that contain spectral channels of red,\\nNIR, and SWIR, for example, the Landsat OLI sensor which has a red band ranging from 630 to 690 nm,\\nan NIR band ranging from 840 to 890 nm, and a SWIR band ranging from 2100 to 2300 nm. However,\\ndi\\u000berent sensors may acquire di \\u000berent MFI values due to the di \\u000berent ranges of red, NIR, and SWIR\\nbands. Furthermore, the performance of the Sentinel-2 MSI red-edge bands will also be present on\\nthe Sentinel-3 Ocean and Land Color Instrument (OLCI) sensor [ 51]. Therefore, the adaptability of\\nthe MFI to other remote sensing sensors still requires further examination. Moreover, the MFI was\\ndesigned based on the re\\ufb02ectance peak in the NIR spectral regions of green vegetation. Therefore,Remote Sens. 2019 ,11, 2043 14 of 17\\nthe MFI has great potential in detecting any submerged or emerged vegetation in aquatic environments,\\nsuch as \\ufb02oating algae and aquatic macrophytes. However, considering the various environments\\nwhere aquatic vegetation grows, the applicability of the MFI in detecting other aquatic vegetation still\\nwarrants further exploration.\\n4.2. Uncertainties Leading to Overestimation of Mangrove Forests Using the MFI\\nThis study demonstrates that there are abundant di \\u000berences in the spectral re\\ufb02ectance between\\nsubmerged mangrove forests and water bodies. In addition, the spectral curves of submerged and\\nemerged mangrove forests showed similar concave\\u2013convex characteristics (Figure 5). Therefore, the\\nMFI function can e \\u000eciently identify and detect mangrove forests from water background. However,\\nthe MFI was designed based on the re\\ufb02ectance peak between red and SWIR; any other vegetation that\\ncontains absorption signatures of chlorophyll in aquatic environment can also be detected [ 17,36,52].\\nHence, pixels containing \\ufb02oating vegetation (for example, algae) and other aquatic macrophytes (for\\nexample, Spartina alterni\\ufb02ora ) may be classi\\ufb01ed as mangrove forest. Additionally, due to limits in image\\nresolution, a small area of the water could still be classi\\ufb01ed as mangrove forests, due to having similar\\nspectral characteristics as nearby mangrove forests. These uncertainties can lead to overestimation of\\nmangrove forests by the MFI. In our application in Dalhousie Island, Sundarbans, India, the bias of\\narea of mangrove forests obtained by MFI is 2% larger.\\n4.3. Limitations Leading to Underestimation of Mangrove Forests Using the MFI\\nIn this study, MFI was created based on the typical re\\ufb02ectance curves of submerged mangrove\\nforests. However, the spectral curve of submerged mangrove forest can be a \\u000bected by several factors,\\nincluding water transparency (turbidity), distance that mangrove canopy under the water surface, and\\nthe coverage of mangrove forest [ 15]. Liew and Chang proved that the spectral curves of submerged\\nvegetation changes when water turbidity and depth change [ 53]. They demonstrated that with high\\nturbidity (50 nephelometric turbidity units), green vegetation could not be distinguished at a water\\ndepth of 0.5 m. In addition, with low turbidity (0.5 nephelometric turbidity units), typical vegetation\\nre\\ufb02ectance was undetectable at a water depth of 1 m. Chen et al. discovered that when submerged\\nvegetation coverage was less than 40%, it is di \\u000ecult to detect vegetation based on the NIR peak in\\nthe spectral re\\ufb02ectance curve [ 15]. Unfortunately, water \\ufb02ow in mangrove swamps always has high\\nturbidity, and newly grown trees at the edge of mangrove forests always have low coverage. According\\nto our \\ufb01eld measurement, in Zhenzhu Harbor, submerged mangrove forests with a depth of 60 cm\\nunder the water surface would not be detected by MFI. Moreover, due to limits of image resolution,\\nsmall parts of the mangrove forests may be classi\\ufb01ed as water due to low tree coverage. As shown in\\nFigure 12, in Zhenzhu Harbor, low mangrove forests along tidal creeks were not identi\\ufb01ed by MFI.\\nThese limitations lead to underestimation of the areal extent of mangrove forests by the MFI.\\nFigure 12. Intermittently \\ufb02ooded mangrove forests in local low tide period.\\n5. Conclusions\\nBased on the spectral response curves of submerged mangrove forests, a new vegetation index\\n(MFI) was developed to distinguish mangrove forests from the water background. To take fullRemote Sens. 2019 ,11, 2043 15 of 17\\nadvantage of the di \\u000berences in re\\ufb02ectance between submerged mangrove forests and the water\\nbackground, Sentinel-2 MSI bands, red and SWIR2 were selected to build a linear baseline, and the\\naverage re\\ufb02ectance value of four red-edge bands above the baseline was de\\ufb01ned as mangrove forest\\nindex (MFI). This new vegetation index is more advantageous in detecting submerged mangrove\\nforests than the traditional NDVI, LSWI, MNDWI, and FAI indices. According to the results of\\nJensen\\u2013Shannon divergence, MFI signi\\ufb01cantly widens the distance of submerged mangrove forest and\\nwater pixels compared to other VIs (the Jensen-Shannon divergence values of MFI, FAI, NDVI, LSWI,\\nand MNDWI are 0.209, 0.077, 0.012, 0.003, and 0.121, respectively). Theoretically, 100% of submerged\\nmangrove forests could be extracted from MFI images. Practically, application of the MFI in three\\nglobal mangrove sites showed 99% to 102% of submerged mangrove forests were successfully extracted\\nfrom the MFI image. The overall accuracy of classi\\ufb01cation results obtained from the MFI image ranged\\nfrom 91.7% to 97.6%. According to our \\ufb01eld measurements in Zhenzhu Harbor, MFI is insensitive to\\nmangrove forests with canopies under 60 cm of the water surface. There are some uncertainties and\\nlimitations, but the MFI was proven to be e \\u000bective in detecting the extent and condition of mangrove\\nforests from high-tide Sentinel MSI images. Although the repeatability and portability of the MFI is\\nstill a work in progress, this index brings great bene\\ufb01ts to remote sensing communities of coastal and\\naquatic vegetation studies.\\nAuthor Contributions: M.J. and Z.W. designed the research, process the data, and wrote the manuscript draft.\\nY.Z. helped with designed research and reviewed the manuscript. C.W. helped with image analysis, \\ufb01eldwork,\\nand reviewed the manuscript. D.M. helped with image analysis and reviewed the manuscript.\\nFunding: The work is supported by Science and Technology Basic Resources Investigation Program of China (No.\\n2017FY100706), the National Natural Science Foundation of China (No. 41601470, No. 41601406), the Strategic\\nPlanning Project of the Institute of Northeast Geography and Agroecology (IGA), Chinese Academy of Sciences\\n(No. Y6H2091000), and the Youth Innovation Promotion Association of Chinese Academy of Sciences (2017277,\\n2012178). This work is supported by Open Fund of State Laboratory of Information Engineering in Surveying,\\nMapping and Remote Sensing, Wuhan University (Grant No. 19I02).\\nAcknowledgments: The authors are grateful to the colleagues who participated in the \\ufb01eld surveys and\\ndata collection.\\nCon\\ufb02icts of Interest: The authors declare no con\\ufb02ict of interest.\\nReferences\\n1. Collins, D.S.; Avdis, A.; Allison, P .A.; Johnson, H.D.; Hill, J.; Piggott, M.D.; Hassan, M.H.A.; Damit, A.R.\\nTidal dynamics and mangrove carbon sequestration during the Oligo-Miocene in the South China Sea.\\nNat. Commun. 2017 ,8, 15698. [CrossRef] [PubMed]\\n2. Richards, D.R.; Friess, D.A. Rates and drivers of mangrove deforestation in Southeast Asia, 2000\\u20132012.\\nProc. Natl. Acad. Sci. USA 2016 ,113, 344\\u2013349. [CrossRef] [PubMed]\\n3. Friess, D.A.; Webb, E.L. Variability in mangrove change estimates and implications for the assessment of\\necosystem service provision. Glob. Ecol. Biogeogr. 2014 ,23, 715\\u2013725. [CrossRef]\\n4. Kuenzer, C.; Bluemel, A.; Gebhardt, S.; Quoc, T.V .; Dech, S. Remote sensing of mangrove ecosystems:\\nA review. Remote Sens. 2011 ,3, 878\\u2013928. [CrossRef]\\n5. Hamilton, S.E.; Casey, D. Creation of a high spatio-temporal resolution global database of continuous\\nmangrove forest cover for the 21st century (CGMFC-21). Glob. Ecol. Biogeogr. 2016 ,25, 729\\u2013738. [CrossRef]\\n6. Giri, C.; Pengra, B.; Zhu, Z.; Singh, A.; Tieszen, L.L. Monitoring mangrove forest dynamics of the Sundarbans\\nin Bangladesh and India using multi-temporal satellite data from 1973 to 2000. Estuar. Coast. Shelf Sci. 2007 ,\\n73, 91\\u2013100. [CrossRef]\\n7. Li, M.; Lee, S. Mangroves of China: A brief review. For. Ecol. Manag. 1997 ,96, 241\\u2013259. [CrossRef]\\n8. Spalding, M.D.; Blasco, F.; Field, C.D. World Mangrove Atlas ; Routledge: London, UK, 1997.\\n9. Cardenas, N.Y.; Joyce, K.E.; Maier, S.W. Monitoring mangrove forests: Are we taking full advantage of\\ntechnology? Int. J. Appl. Earth Obs. Geoinf. 2017 ,63, 1\\u201314. [CrossRef]\\n10. Rogers, K.; Lymburner, L.; Salum, R.; Brooke, B.P .; Woodro \\u000be, C.D. Mapping of mangrove extent and\\nzonation using high and low tide composites of Landsat data. Hydrobiologia 2017 ,803, 49\\u201368. [CrossRef]Remote Sens. 2019 ,11, 2043 16 of 17\\n11. Jia, M.; Wang, Z.; Zhang, Y.; Mao, D.; Wang, C. Monitoring loss and recovery of mangrove forests during\\n42 years: The achievements of mangrove conservation in China. Int. J. Appl. Earth Obs. Geoinf. 2018 ,73,\\n535\\u2013545. [CrossRef]\\n12. Jia, M.; Wang, Z.; Zhang, Y.; Ren, C.; Song, K. Landsat-based estimation of mangrove forest loss and\\nrestoration in Guangxi province, China, in\\ufb02uenced by human and natural factors. IEEE J. Sel. Top. Appl.\\nEarth Obs. Remote Sens. 2015 ,8, 311\\u2013323. [CrossRef]\\n13. Xia, Q.; Qin, C.-Z.; Li, H.; Huang, C.; Su, F.-Z. Mapping mangrove forests based on multi-tidal high-resolution\\nsatellite imagery. Remote Sens. 2018 ,10, 1343. [CrossRef]\\n14. Zhang, X.; Treitz, P .M.; Chen, D.; Quan, C.; Shi, L.; Li, X. Mapping mangrove forests using multi-tidal\\nremotely-sensed data and a decision-tree-based procedure. Int. J. Appl. Earth Obs. Geoinf. 2017 ,62, 201\\u2013214.\\n[CrossRef]\\n15. Chen, Q.; Yu, R.; Hao, Y.; Wu, L.; Zhang, W.; Zhang, Q.; Bu, X. A New Method for Mapping Aquatic\\nVegetation Especially Underwater Vegetation in Lake Ulansuhai Using GF-1 Satellite Data. Remote Sens.\\n2018 ,10, 1279. [CrossRef]\\n16. Silva, T.S.; Costa, M.P .; Melack, J.M.; Novo, E.M. Remote sensing of aquatic vegetation: Theory and\\napplications. Environ. Monit. Assess. 2008 ,140, 131\\u2013145. [CrossRef] [PubMed]\\n17. Gao, B.-C.; Li, R.-R. FVI\\u2014A Floating Vegetation Index Formed with Three Near-IR Channels in the 1.0\\u20131.24\\n\\u0016m Spectral Range for the Detection of Vegetation Floating over Water Surfaces. Remote Sens. 2018 ,10, 1421.\\n[CrossRef]\\n18. Sibanda, M.; Mutanga, O.; Dube, T.; S Vundla, T.; L Mafongoya, P . Estimating LAI and mapping canopy\\nstorage capacity for hydrological applications in wattle infested ecosystems using Sentinel-2 MSI derived\\nred edge bands. GISci. Remote Sens. 2019 ,56, 68\\u201386. [CrossRef]\\n19. Williams, D.J.; Rybicki, N.B.; Lombana, A.V .; O\\u2019Brien, T.M.; Gomez, R.B. Preliminary investigation of\\nsubmerged aquatic vegetation mapping using hyperspectral remote sensing. In Coastal Monitoring through\\nPartnerships ; Springer: Berlin, Germany, 2003; pp. 383\\u2013392.\\n20. Luo, J.; Li, X.; Ma, R.; Li, F.; Duan, H.; Hu, W.; Qin, B.; Huang, W. Applying remote sensing techniques to\\nmonitoring seasonal and interannual changes of aquatic vegetation in Taihu Lake, China. Ecol. Indic. 2016 ,\\n60, 503\\u2013513. [CrossRef]\\n21. Ma, R.; Duan, H.; Liu, Q.; Loiselle, S.A. Approximate bottom contribution to remote sensing re\\ufb02ectance in\\nTaihu Lake, China. J. Great Lakes Res. 2011 ,37, 18\\u201325. [CrossRef]\\n22. Pu, R.; Bell, S.; Meyer, C.; Baggett, L.; Zhao, Y. Mapping and assessing seagrass along the western coast of\\nFlorida using Landsat TM and EO-1 ALI /Hyperion imagery. Estuar. Coast. Shelf Sci. 2012 ,115, 234\\u2013245.\\n[CrossRef]\\n23. Purnamasayangsukasih, P .R.; Norizah, K.; Ismail, A.A.; Shamsudin, I. A review of uses of satellite imagery\\nin monitoring mangrove forests. In Proceedings of the IOP Conference Series: Earth and Environmental\\nScience, Prague, Czech Republic, 12\\u201319 July 2016; p. 012034.\\n24. Zhao, D.; Jiang, H.; Yang, T.; Cai, Y.; Xu, D.; An, S. Remote sensing of aquatic vegetation distribution in Taihu\\nLake using an improved classi\\ufb01cation tree with modi\\ufb01ed thresholds. J. Environ. Manag. 2012 ,95, 98\\u2013107.\\n[CrossRef] [PubMed]\\n25. Visser, F.; Buis, K.; Verschoren, V .; Meire, P . Depth estimation of submerged aquatic vegetation in clear water\\nstreams using low-altitude optical remote sensing. Sensors 2015 ,15, 25287\\u201325312. [CrossRef] [PubMed]\\n26. Heumann, B.W. An object-based classi\\ufb01cation of mangroves using a hybrid decision tree\\u2014Support vector\\nmachine approach. Remote Sens. 2011 ,3, 2440\\u20132460. [CrossRef]\\n27. Heumann, B.W. Satellite remote sensing of mangrove forests: Recent advances and future opportunities.\\nProg. Phys. Geogr. 2011 ,35, 87\\u2013108. [CrossRef]\\n28. Wang, T.; Zhang, H.; Lin, H.; Fang, C. Textural\\u2013spectral feature-based species classi\\ufb01cation of mangroves in\\nMai Po Nature Reserve from Worldview-3 imagery. Remote Sens. 2016 ,8, 24. [CrossRef]\\n29. Wan, L.; Zhang, H.; Wang, T.; Li, G.; Lin, H. Mangrove species discrimination from very high resolution\\nimagery using gaussian markov random \\ufb01eld model. Wetlands 2018 ,38, 861\\u2013874. [CrossRef]\\n30. Huete, A.; Justice, C.; Van Leeuwen, W. MODIS vegetation index (MOD 13) algorithm theoretical basis\\ndocument (ATBD) Version 3.0. EOS Proj. O \\u000b.1999 , 2\\u20133.Remote Sens. 2019 ,11, 2043 17 of 17\\n31. Matsushita, B.; Yang, W.; Chen, J.; Onda, Y.; Qiu, G. Sensitivity of the enhanced vegetation index (EVI) and\\nnormalized di \\u000berence vegetation index (NDVI) to topographic e \\u000bects: A case study in high-density cypress\\nforest. Sensors 2007 ,7, 2636\\u20132651. [CrossRef] [PubMed]\\n32. Gao, B.-C. NDWI\\u2014A normalized di \\u000berence water index for remote sensing of vegetation liquid water from\\nspace. Remote Sens. Environ. 1996 ,58, 257\\u2013266. [CrossRef]\\n33. Xiao, X.; Boles, S.; Liu, J.; Zhuang, D.; Frolking, S.; Li, C.; Salas, W.; Moore, B., III. Mapping paddy rice\\nagriculture in southern China using multi-temporal MODIS images. Remote Sens. Environ. 2005 ,95, 480\\u2013492.\\n[CrossRef]\\n34. Xu, H. Modi\\ufb01cation of normalised di \\u000berence water index (NDWI) to enhance open water features in remotely\\nsensed imagery. Int. J. Remote Sens. 2006 ,27, 3025\\u20133033. [CrossRef]\\n35. Gower, J.; Hu, C.; Borstad, G.; King, S. Ocean color satellites show extensive lines of \\ufb02oating Sargassum in\\nthe Gulf of Mexico. IEEE Trans. Geosci. Remote Sens. 2006 ,44, 3619\\u20133625. [CrossRef]\\n36. Hu, C. A novel ocean color index to detect \\ufb02oating algae in the global oceans. Remote Sens. Environ. 2009 ,\\n113, 2118\\u20132129. [CrossRef]\\n37. Li, S.; Ganguly, S.; Dungan, J.L.; Wang, W.; Nemani, R.R. Sentinel-2 MSI radiometric characterization and\\ncross-calibration with Landsat-8 OLI. Adv. Remote Sens 2017 ,6, 147. [CrossRef]\\n38. Wang, Q.; Blackburn, G.A.; Onojeghuo, A.O.; Dash, J.; Zhou, L.; Zhang, Y.; Atkinson, P .M. Fusion of Landsat\\n8 OLI and Sentinel-2 MSI data. IEEE Trans. Geosci. Remote Sens. 2017 ,55, 3885\\u20133899. [CrossRef]\\n39. Clevers, J.G.; Kooistra, L.; van den Brande, M.M. Using Sentinel-2 data for retrieving LAI and leaf and\\ncanopy chlorophyll content of a potato crop. Remote Sens. 2017 ,9, 405. [CrossRef]\\n40. Quintano, C.; Fern \\u00e1ndez-Manso, A.; Fern \\u00e1ndez-Manso, O. Combination of Landsat and Sentinel-2 MSI data\\nfor initial assessing of burn severity. Int. J. Appl. Earth Obs. Geoinf. 2018 ,64, 221\\u2013225. [CrossRef]\\n41. Harayama, A.; Jaquet, J.-M. Multi-Source Object-Oriented Classi\\ufb01cation of Landcover Using Very High Resolution\\nImagery and Digital Elevation Model ; UNEP: Geneva, Switzerland, 2004.\\n42. Spalding, M. World Atlas of Mangroves ; Routledge: London, UK, 2010.\\n43. Han, L.; Rundquist, D. The spectral responses of Ceratophyllum demersum at varying depths in an\\nexperimental tank. Int. J. Remote Sens. 2003 ,24, 859\\u2013864. [CrossRef]\\n44. Cho, H.J.; Kirui, P .; Natarajan, H. Test of multi-spectral vegetation index for \\ufb02oating and canopy-forming\\nsubmerged vegetation. Int. J. Environ. Res. Public Health 2008 ,5, 477\\u2013483. [CrossRef]\\n45. Tucker, C.J. Red and photographic infrared linear combinations for monitoring vegetation. Remote Sens.\\nEnviron. 1979 ,8, 127\\u2013150. [CrossRef]\\n46. Lin, J. Divergence measures based on the Shannon entropy. IEEE Trans. Inf. Theory 1991 ,37, 145\\u2013151. [CrossRef]\\n47. Manna, S.; Raychaudhuri, B. Mapping distribution of Sundarban mangroves using Sentinel-2 data and new\\nspectral metric for detecting their health condition. Geocarto Int. 2018 , 1\\u201330. [CrossRef]\\n48. Ghosh, A.; Schmidt, S.; Fickert, T.; N\\u00fcsser, M. The Indian Sundarban mangrove forests: History, utilization,\\nconservation strategies and local perception. Diversity 2015 ,7, 149\\u2013169. [CrossRef]\\n49. Islam, M.T. Vegetation changes of Sundarbans based on Landsat Imagery analysis between 1975 and 2006.\\nActa Geogr. Debrecina Landsc. Environ. Ser. 2014 ,8, 1\\u20139.\\n50. Mondal, B.; Saha, A.K. Spatio-Temporal Analysis of Mangrove Loss in Vulnerable Islands of Sundarban World\\nHeritage Site, India. In Proceedings of the Annual International Conference on Geographic Information\\nScience, Lund, Sweden, 12\\u201315 June 2018; Springer: Cham, Switzerland, 2018; pp. 93\\u2013109.\\n51. Clevers, J.G.; Gitelson, A.A. Remote estimation of crop and grass chlorophyll and nitrogen content using\\nred-edge bands on Sentinel-2 and-3. Int. J. Appl. Earth Obs. Geoinf. 2013 ,23, 344\\u2013351. [CrossRef]\\n52. Cho, H.J.; Lu, D. A water-depth correction algorithm for submerged vegetation spectra. Remote Sens. Lett.\\n2010 ,1, 29\\u201335. [CrossRef]\\n53. Liew, S.C.; Chang, C.W. Detecting submerged aquatic vegetation with 8-band WorldView-2 satellite images.\\nIn Proceedings of the 2012 IEEE International Geoscience and Remote Sensing Symposium (IGARSS), Munich,\\nGermany, 22\\u201327 July 2012; pp. 2560\\u20132562.\\n\\u00a92019 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access\\narticle distributed under the terms and conditions of the Creative Commons Attribution\\n(CC BY) license (http: //creativecommons.org /licenses /by/4.0/).\",\n          \"Extinguished philosophies lie about the cradle of every sci ence as the\\nstrangled snakes beside that of Hercules. - adapted from T. H . Huxley\\n1WHAT IS ARTIFICIAL INTELLIGENCE?\\nJohn McCarthy\\nComputer Science Department\\nStanford University\\nStanford, CA 94305\\njmc@cs.stanford.edu\\nhttp://www-formal.stanford.edu/jmc/\\n2007 Nov 12, 2:05 a.m.\\nRevised November 12, 2007:\\nAbstract\\nThis article for the layman answers basic questions about ar ti\\ufb01cial\\nintelligence. The opinions expressed here are not all conse nsus opinion\\namong researchers in AI.\\n1 Basic Questions\\nQ. What is arti\\ufb01cial intelligence?\\nA. It is the science and engineering of making intelligent ma chines, es-\\npecially intelligent computer programs. It is related to th e similar task of\\nusing computers to understand human intelligence, but AI do es not have to\\ncon\\ufb01ne itself to methods that are biologically observable.\\nQ. Yes, but what is intelligence?\\nA. Intelligence is the computational part of the ability to a chieve goals in\\nthe world. Varying kinds and degrees of intelligence occur i n people, many\\nanimals and some machines.\\nQ. Isn\\u2019t there a solid de\\ufb01nition of intelligence that doesn\\u2019 t depend on\\nrelating it to human intelligence?\\n2A. Not yet. The problem is that we cannot yet characterize in g eneral\\nwhat kinds of computational procedures we want to call intel ligent. We\\nunderstand some of the mechanisms of intelligence and not ot hers.\\nQ. Is intelligence a single thing so that one can ask a yes or no question\\n\\u201cIs this machine intelligent or not?\\u201d?\\nA. No. Intelligence involves mechanisms, and AI research ha s discovered\\nhow to make computers carry out some of them and not others. If doing a\\ntask requires only mechanisms that are well understood toda y, computer pro-\\ngrams can give very impressive performances on these tasks. Such programs\\nshould be considered \\u201csomewhat intelligent\\u201d.\\nQ. Isn\\u2019t AI about simulating human intelligence?\\nA. Sometimes but not always or even usually. On the one hand, w e can\\nlearn something about how to make machines solve problems by observing\\nother people or just by observing our own methods. On the othe r hand, most\\nwork in AI involves studying the problems the world presents to intelligence\\nrather than studying people or animals. AI researchers are f ree to use meth-\\nods that are not observed in people or that involve much more c omputing\\nthan people can do.\\nQ. What about IQ? Do computer programs have IQs?\\nA. No. IQ is based on the rates at which intelligence develops in children.\\nIt is the ratio of the age at which a child normally makes a cert ain score\\nto the child\\u2019s age. The scale is extended to adults in a suitab le way. IQ\\ncorrelates well with various measures of success or failure in life, but making\\ncomputers that can score high on IQ tests would be weakly corr elated with\\ntheir usefulness. For example, the ability of a child to repe at back a long\\nsequence of digits correlates well with other intellectual abilities, perhaps\\nbecause it measures how much information the child can compu te with at\\nonce. However, \\u201cdigit span\\u201d is trivial for even extremely li mited computers.\\nHowever, some of the problems on IQ tests are useful challeng es for AI.\\nQ. What about other comparisons between human and computer i ntelli-\\ngence?\\nArthur R. Jensen [Jen98], a leading researcher in human inte lligence,\\nsuggests \\u201cas a heuristic hypothesis\\u201d that all normal humans have the same\\nintellectual mechanisms and that di\\ufb00erences in intelligen ce are related to\\n\\u201cquantitative biochemical and physiological conditions\\u201d . I see them as speed,\\nshort term memory, and the ability to form accurate and retri evable long term\\nmemories.\\nWhether or not Jensen is right about human intelligence, the situation in\\n3AI today is the reverse.\\nComputer programs have plenty of speed and memory but their a bilities\\ncorrespond to the intellectual mechanisms that program des igners understand\\nwell enough to put in programs. Some abilities that children normally don\\u2019t\\ndevelop till they are teenagers may be in, and some abilities possessed by\\ntwo year olds are still out. The matter is further complicate d by the fact\\nthat the cognitive sciences still have not succeeded in dete rmining exactly\\nwhat the human abilities are. Very likely the organization o f the intellectual\\nmechanisms for AI can usefully be di\\ufb00erent from that in peopl e.\\nWhenever people do better than computers on some task or comp uters\\nuse a lot of computation to do as well as people, this demonstr ates that the\\nprogram designers lack understanding of the intellectual m echanisms required\\nto do the task e\\ufb03ciently.\\nQ. When did AI research start?\\nA. After WWII, a number of people independently started to wo rk on\\nintelligent machines. The English mathematician Alan Turi ng may have\\nbeen the \\ufb01rst. He gave a lecture on it in 1947. He also may have b een the\\n\\ufb01rst to decide that AI was best researched by programming com puters rather\\nthan by building machines. By the late 1950s, there were many researchers\\non AI, and most of them were basing their work on programming c omputers.\\nQ. Does AI aim to put the human mind into the computer?\\nA. Some researchers say they have that objective, but maybe t hey are\\nusing the phrase metaphorically. The human mind has a lot of p eculiarities,\\nand I\\u2019m not sure anyone is serious about imitating all of them .\\nQ. What is the Turing test?\\nA. Alan Turing\\u2019s 1950 article Computing Machinery and Intelligence [Tur50]\\ndiscussed conditions for considering a machine to be intell igent. He argued\\nthat if the machine could successfully pretend to be human to a knowledge-\\nable observer then you certainly should consider it intelli gent. This test\\nwould satisfy most people but not all philosophers. The obse rver could in-\\nteract with the machine and a human by teletype (to avoid requ iring that\\nthe machine imitate the appearance or voice of the person), a nd the human\\nwould try to persuade the observer that it was human and the ma chine would\\ntry to fool the observer.\\nThe Turing test is a one-sided test. A machine that passes the test should\\ncertainly be considered intelligent, but a machine could st ill be considered\\nintelligent without knowing enough about humans to imitate a human.\\nDaniel Dennett\\u2019s book Brainchildren [Den98] has an excellent discussion\\n4of the Turing test and the various partial Turing tests that h ave been im-\\nplemented, i.e. with restrictions on the observer\\u2019s knowle dge of AI and the\\nsubject matter of questioning. It turns out that some people are easily led\\ninto believing that a rather dumb program is intelligent.\\nQ. Does AI aim at human-level intelligence?\\nA. Yes. The ultimate e\\ufb00ort is to make computer programs that c an solve\\nproblems and achieve goals in the world as well as humans. How ever, many\\npeople involved in particular research areas are much less a mbitious.\\nQ. How far is AI from reaching human-level intelligence? Whe n will it\\nhappen?\\nA. A few people think that human-level intelligence can be ac hieved by\\nwriting large numbers of programs of the kind people are now w riting and\\nassembling vast knowledge bases of facts in the languages no w used for ex-\\npressing knowledge.\\nHowever, most AI researchers believe that new fundamental i deas are\\nrequired, and therefore it cannot be predicted when human-l evel intelligence\\nwill be achieved.\\nQ. Are computers the right kind of machine to be made intellig ent?\\nA. Computers can be programmed to simulate any kind of machin e.\\nMany researchers invented non-computer machines, hoping t hat they\\nwould be intelligent in di\\ufb00erent ways than the computer prog rams could\\nbe. However, they usually simulate their invented machines on a computer\\nand come to doubt that the new machine is worth building. Beca use many\\nbillions of dollars that have been spent in making computers faster and faster,\\nanother kind of machine would have to be very fast to perform b etter than\\na program on a computer simulating the machine.\\nQ. Are computers fast enough to be intelligent?\\nA. Some people think much faster computers are required as we ll as new\\nideas. My own opinion is that the computers of 30 years ago wer e fast\\nenough if only we knew how to program them. Of course, quite ap art from\\nthe ambitions of AI researchers, computers will keep gettin g faster.\\nQ. What about parallel machines?\\nA. Machines with many processors are much faster than single proces-\\nsors can be. Parallelism itself presents no advantages, and parallel machines\\nare somewhat awkward to program. When extreme speed is requi red, it is\\nnecessary to face this awkwardness.\\nQ. What about making a \\u201cchild machine\\u201d that could improve by r eading\\nand by learning from experience?\\n5A. This idea has been proposed many times, starting in the 194 0s. Even-\\ntually, it will be made to work. However, AI programs haven\\u2019t yet reached\\nthe level of being able to learn much of what a child learns fro m physical\\nexperience. Nor do present programs understand language we ll enough to\\nlearn much by reading.\\nQ. Might an AI system be able to bootstrap itself to higher and higher\\nlevel intelligence by thinking about AI?\\nA. I think yes, but we aren\\u2019t yet at a level of AI at which this pr ocess can\\nbegin.\\nQ. What about chess?\\nA. Alexander Kronrod, a Russian AI researcher, said \\u201cChess i s theDrosophila\\nof AI.\\u201d He was making an analogy with geneticists\\u2019 use of that fruit \\ufb02y to\\nstudy inheritance. Playing chess requires certain intelle ctual mechanisms and\\nnot others. Chess programs now play at grandmaster level, bu t they do it\\nwith limited intellectual mechanisms compared to those use d by a human\\nchess player, substituting large amounts of computation fo r understanding.\\nOnce we understand these mechanisms better, we can build hum an-level\\nchess programs that do far less computation than do present p rograms.\\nUnfortunately, the competitive and commercial aspects of m aking com-\\nputers play chess have taken precedence over using chess as a scienti\\ufb01c do-\\nmain. It is as if the geneticists after 1910 had organized fru it \\ufb02y races and\\nconcentrated their e\\ufb00orts on breeding fruit \\ufb02ies that could win these races.\\nQ. What about Go?\\nA. The Chinese and Japanese game of Gois also a board game in which\\nthe players take turns moving. Goexposes the weakness of our present under-\\nstanding of the intellectual mechanisms involved in human g ame playing. Go\\nprograms are very bad players, in spite of considerable e\\ufb00or t (not as much as\\nfor chess). The problem seems to be that a position in Gohas to be divided\\nmentally into a collection of subpositions which are \\ufb01rst an alyzed separately\\nfollowed by an analysis of their interaction. Humans use thi s in chess also,\\nbut chess programs consider the position as a whole. Chess pr ograms com-\\npensate for the lack of this intellectual mechanism by doing thousands or, in\\nthe case of Deep Blue, many millions of times as much computat ion.\\nSooner or later, AI research will overcome this scandalous w eakness.\\nQ. Don\\u2019t some people say that AI is a bad idea?\\nA. The philosopher John Searle says that the idea of a non-bio logical ma-\\nchine being intelligent is incoherent. He proposes the Chin ese room argument\\nwww-formal.stanford.edu/jmc/chinese.html The philosop her Hubert Dreyfus\\n6says that AI is impossible. The computer scientist Joseph We izenbaum says\\nthe idea is obscene, anti-human and immoral. Various people have said that\\nsince arti\\ufb01cial intelligence hasn\\u2019t reached human level by now, it must be\\nimpossible. Still other people are disappointed that compa nies they invested\\nin went bankrupt.\\nQ. Aren\\u2019t computability theory and computational complexi ty the keys\\nto AI? [Note to the layman and beginners in computer science: These are\\nquite technical branches of mathematical logic and compute r science, and\\nthe answer to the question has to be somewhat technical.]\\nA. No. These theories are relevant but don\\u2019t address the fund amental\\nproblems of AI.\\nIn the 1930s mathematical logicians, especially Kurt G\\u00a8 ode l and Alan Tur-\\ning, established that there did not exist algorithms that we re guaranteed to\\nsolve all problems in certain important mathematical domai ns. Whether a\\nsentence of \\ufb01rst order logic is a theorem is one example, and w hether a poly-\\nnomial equations in several variables has integer solution s is another. Hu-\\nmans solve problems in these domains all the time, and this ha s been o\\ufb00ered\\nas an argument (usually with some decorations) that compute rs are intrinsi-\\ncally incapable of doing what people do. Roger Penrose claim s this. However,\\npeople can\\u2019t guarantee to solve arbitrary problems in these domains either.\\nSee my Review of The Emperor\\u2019s New Mind by Roger Penrose. More essays\\nand reviews defending AI research are in [McC96a].\\nIn the 1960s computer scientists, especially Steve Cook and Richard Karp\\ndeveloped the theory of NP-complete problem domains. Probl ems in these\\ndomains are solvable, but seem to take time exponential in th e size of the\\nproblem. Which sentences of propositional calculus are sat is\\ufb01able is a basic\\nexample of an NP-complete problem domain. Humans often solv e problems\\nin NP-complete domains in times much shorter than is guarant eed by the\\ngeneral algorithms, but can\\u2019t solve them quickly in general .\\nWhat is important for AI is to have algorithms as capable as pe ople at\\nsolving problems. The identi\\ufb01cation of subdomains for whic h good algo-\\nrithms exist is important, but a lot of AI problem solvers are not associated\\nwith readily identi\\ufb01ed subdomains.\\nThe theory of the di\\ufb03culty of general classes of problems is c alledcom-\\nputational complexity. So far this theory hasn\\u2019t interacted with AI as much\\nas might have been hoped. Success in problem solving by human s and by\\nAI programs seems to rely on properties of problems and probl em solving\\nmethods that the neither the complexity researchers nor the AI community\\n7have been able to identify precisely.\\nAlgorithmic complexity theory as developed by Solomono\\ufb00, K olmogorov\\nand Chaitin (independently of one another) is also relevant . It de\\ufb01nes the\\ncomplexity of a symbolic object as the length of the shortest program that\\nwill generate it. Proving that a candidate program is the sho rtest or close\\nto the shortest is an unsolvable problem, but representing o bjects by short\\nprograms that generate them should sometimes be illuminati ng even when\\nyou can\\u2019t prove that the program is the shortest.\\n2 Branches of AI\\nQ. What are the branches of AI?\\nA. Here\\u2019s a list, but some branches are surely missing, becau se no-one\\nhas identi\\ufb01ed them yet. Some of these may be regarded as conce pts or topics\\nrather than full branches.\\nlogical AI What a program knows about the world in general the facts\\nof the speci\\ufb01c situation in which it must act, and its goals ar e all\\nrepresented by sentences of some mathematical logical lang uage. The\\nprogram decides what to do by inferring that certain actions are ap-\\npropriate for achieving its goals. The \\ufb01rst article proposi ng this was\\n[McC59]. [McC89] is a more recent summary. [McC96b] lists so me of\\nthe concepts involved in logical aI. [Sha97] is an important text.\\nsearch AI programs often examine large numbers of possibilities, e .g. moves\\nin a chess game or inferences by a theorem proving program. Di scover-\\nies are continually made about how to do this more e\\ufb03ciently i n various\\ndomains.\\npattern recognition When a program makes observations of some kind,\\nit is often programmed to compare what it sees with a pattern. For\\nexample, a vision program may try to match a pattern of eyes an d a\\nnose in a scene in order to \\ufb01nd a face. More complex patterns, e .g. in\\na natural language text, in a chess position, or in the histor y of some\\nevent are also studied. These more complex patterns require quite\\ndi\\ufb00erent methods than do the simple patterns that have been s tudied\\nthe most.\\n8representation Facts about the world have to be represented in some way.\\nUsually languages of mathematical logic are used.\\ninference From some facts, others can be inferred. Mathematical logic al\\ndeduction is adequate for some purposes, but new methods of non-\\nmonotonic inference have been added to logic since the 1970s. The\\nsimplest kind of non-monotonic reasoning is default reason ing in which\\na conclusion is to be inferred by default, but the conclusion can be\\nwithdrawn if there is evidence to the contrary. For example, when\\nwe hear of a bird, we man infer that it can \\ufb02y, but this conclusi on\\ncan be reversed when we hear that it is a penguin. It is the poss ibil-\\nity that a conclusion may have to be withdrawn that constitut es the\\nnon-monotonic character of the reasoning. Ordinary logica l reasoning\\nis monotonic in that the set of conclusions that can the drawn from\\na set of premises is a monotonic increasing function of the pr emises.\\nCircumscription is another form of non-monotonic reasonin g.\\ncommon sense knowledge and reasoning This is the area in which AI\\nis farthest from human-level, in spite of the fact that it has been an\\nactive research area since the 1950s. While there has been co nsiderable\\nprogress, e.g. in developing systems of non-monotonic reasoning and\\ntheories of action, yet more new ideas are needed. The Cyc sys tem\\ncontains a large but spotty collection of common sense facts .\\nlearning from experience Programs do that. The approaches to AI based\\nonconnectionism andneural nets specialize in that. There is also learn-\\ning of laws expressed in logic. [Mit97] is a comprehensive un dergrad-\\nuate text on machine learning. Programs can only learn what f acts\\nor behaviors their formalisms can represent, and unfortuna tely learn-\\ning systems are almost all based on very limited abilities to represent\\ninformation.\\nplanning Planning programs start with general facts about the world ( es-\\npecially facts about the e\\ufb00ects of actions), facts about the particular\\nsituation and a statement of a goal. From these, they generat e a strat-\\negy for achieving the goal. In the most common cases, the stra tegy is\\njust a sequence of actions.\\nepistemology This is a study of the kinds of knowledge that are required\\nfor solving problems in the world.\\n9ontology Ontology is the study of the kinds of things that exist. In AI,\\nthe programs and sentences deal with various kinds of object s, and\\nwe study what these kinds are and what their basic properties are.\\nEmphasis on ontology begins in the 1990s.\\nheuristics A heuristic is a way of trying to discover something or an idea\\nimbedded in a program. The term is used variously in AI. Heuristic\\nfunctions are used in some approaches to search to measure how far\\na node in a search tree seems to be from a goal. Heuristic predicates\\nthat compare two nodes in a search tree to see if one is better t han the\\nother, i.e. constitutes an advance toward the goal, may be mo re useful.\\n[My opinion].\\ngenetic programming Genetic programming is a technique for getting pro-\\ngrams to solve a task by mating random Lisp programs and selec ting\\n\\ufb01ttest in millions of generations. It is being developed by J ohn Koza\\u2019s\\ngroup and here\\u2019s a tutorial1.\\n3 Applications of AI\\nQ. What are the applications of AI?\\nA. Here are some.\\ngame playing You can buy machines that can play master level chess for\\na few hundred dollars. There is some AI in them, but they play w ell\\nagainst people mainly through brute force computation\\u2014loo king at\\nhundreds of thousands of positions. To beat a world champion by\\nbrute force and known reliable heuristics requires being ab le to look at\\n200 million positions per second.\\nspeech recognition In the 1990s, computer speech recognition reached a\\npractical level for limited purposes. Thus United Airlines has replaced\\nits keyboard tree for \\ufb02ight information by a system using spe ech recog-\\nnition of \\ufb02ight numbers and city names. It is quite convenien t. On the\\nthe other hand, while it is possible to instruct some compute rs using\\nspeech, most users have gone back to the keyboard and the mous e as\\nstill more convenient.\\n1http://www.genetic-programming.com/gpanimatedtutori al.html\\n10understanding natural language Just getting a sequence of words into a\\ncomputer is not enough. Parsing sentences is not enough eith er. The\\ncomputer has to be provided with an understanding of the doma in\\nthe text is about, and this is presently possible only for ver y limited\\ndomains.\\ncomputer vision The world is composed of three-dimensional objects, but\\nthe inputs to the human eye and computers\\u2019 TV cameras are two d i-\\nmensional. Some useful programs can work solely in two dimen sions,\\nbut full computer vision requires partial three-dimension al informa-\\ntion that is not just a set of two-dimensional views. At prese nt there\\nare only limited ways of representing three-dimensional in formation di-\\nrectly, and they are not as good as what humans evidently use.\\nexpert systems A \\u201cknowledge engineer\\u201d interviews experts in a certain do-\\nmain and tries to embody their knowledge in a computer progra m for\\ncarrying out some task. How well this works depends on whethe r the\\nintellectual mechanisms required for the task are within th e present\\nstate of AI. When this turned out not to be so, there were many d is-\\nappointing results. One of the \\ufb01rst expert systems was MYCIN in\\n1974, which diagnosed bacterial infections of the blood and suggested\\ntreatments. It did better than medical students or practici ng doctors,\\nprovided its limitations were observed. Namely, its ontolo gy included\\nbacteria, symptoms, and treatments and did not include pati ents, doc-\\ntors, hospitals, death, recovery, and events occurring in t ime. Its in-\\nteractions depended on a single patient being considered. S ince the\\nexperts consulted by the knowledge engineers knew about pat ients,\\ndoctors, death, recovery, etc., it is clear that the knowled ge engineers\\nforced what the experts told them into a predetermined frame work. In\\nthe present state of AI, this has to be true. The usefulness of current\\nexpert systems depends on their users having common sense.\\nheuristic classi\\ufb01cation One of the most feasible kinds of expert system\\ngiven the present knowledge of AI is to put some information i n one\\nof a \\ufb01xed set of categories using several sources of informat ion. An\\nexample is advising whether to accept a proposed credit card purchase.\\nInformation is available about the owner of the credit card, his record\\nof payment and also about the item he is buying and about the es tab-\\nlishment from which he is buying it (e.g., about whether ther e have\\n11been previous credit card frauds at this establishment).\\n4 More questions\\nQ. How is AI research done?\\nA. AI research has both theoretical and experimental sides. The experi-\\nmental side has both basic and applied aspects.\\nThere are two main lines of research. One is biological, base d on the\\nidea that since humans are intelligent, AI should study huma ns and imitate\\ntheir psychology or physiology. The other is phenomenal, ba sed on studying\\nand formalizing common sense facts about the world and the pr oblems that\\nthe world presents to the achievement of goals. The two appro aches interact\\nto some extent, and both should eventually succeed. It is a ra ce, but both\\nracers seem to be walking.\\nQ. What are the relations between AI and philosophy?\\nA. AI has many relations with philosophy, especially modern analytic\\nphilosophy. Both study mind, and both study common sense. Th e best\\nreference is [Tho03].\\nQ. How are AI and logic programming related?\\nA. At the very least, logic programming provides useful prog ramming\\nlanguages (mainly Prolog).\\nBeyond that, sometimes a theory Tuseful in AI can be expressed as a col-\\nlection HofHorn clauses , and goal Gto be achieved can be expressed as that\\nof \\ufb01nding values of variables x1. . .x nsatisfying an expression g(x1. . .x n).\\nThe problem can sometimes be solved by running the Prolog pro gram con-\\nsisting of GandH.\\nThere are two possible obstacles to regarding AI as logic pro gramming.\\nFirst, Horn theories do not exhaust \\ufb01rst order logic. Second , the Prolog\\nprogram expressing the theory may be extremely ine\\ufb03cient. M ore elaborate\\ncontrol than just executing the program that expresses the t heory is often\\nneeded. Map coloring provides examples.\\nQ. What should I study before or while learning AI?\\nA. Study mathematics, especially mathematical logic. The m ore you\\nlearn about sciences, e.g. physics or biology, the better. F or the biological\\napproaches to AI, study psychology and the physiology of the nervous system.\\nLearn some programming languages\\u2014at least C, Lisp and Prolo g. It is also a\\ngood idea to learn one basic machine language. Jobs are likel y to depend on\\n12knowing the languages currently in fashion. In the late 1990 s, these include\\nC++ and Java.\\nQ. What is a good textbook on AI?\\nA.Arti\\ufb01cial Intelligence by Stuart Russell and Peter Norvig, Prentice Hall\\nis the most commonly used textbbook in 1997. The general view s expressed\\nthere do not exactly correspond to those of this essay. Arti\\ufb01cial Intelligence:\\nA New Synthesis by Nils Nilsson, Morgan Kaufman, may be easier to read.\\nSome people prefer Computational Intelligence by David Poole, Alan Mack-\\nworth and Randy Goebel, Oxford, 1998.\\nQ. What organizations and publications are concerned with A I?\\nA. The American Association for Arti\\ufb01cial Intelligence (AA AI)2, the Eu-\\nropean Coordinating Committee for Arti\\ufb01cial Intelligence (ECCAI)3and the\\nSociety for Arti\\ufb01cial Intelligence and Simulation of Behav ior (AISB)4are\\nscienti\\ufb01c societies concerned with AI research. The Associ ation for Comput-\\ning Machinery (ACM) has a special interest group on arti\\ufb01cia l intelligence\\nSIGART5.\\nThe International Joint Conference on AI (IJCAI)6is the main inter-\\nnational conference. The AAAI7runs a US National Conference on AI.\\nElectronic Transactions on Arti\\ufb01cial Intelligence8,Arti\\ufb01cial Intelligence9,\\nandJournal of Arti\\ufb01cial Intelligence Research10, and IEEE Transactions on\\nPattern Analysis and Machine Intelligence11are four of the main journals\\npublishing AI research papers. I have not yet found everythi ng that should\\nbe in this paragraph.\\nPage of Positive Reviews12lists papers that experts have found impor-\\ntant.\\nFunding a Revolution: Government Support for Computing Res earch by a\\ncommittee of the National Research covers support for AI res earch in Chapter\\n2http://www.aaai.org\\n3http://www.eccai.org/\\n4http://www.cogs.susx.ac.uk/aisb\\n5http://www.acm.org/sigart\\n6http://www.ijcai.org\\n7http://www.aaai.org\\n8http://www.ida.liu.se/ext/etai/\\n9http://www.elsevier.nl/locate/artint/\\n10http://www.jair.org/\\n11http://computer.org/tpami/\\n12http://www.cs.utexas.edu/users/vl/ppr/\\n139.13\\nReferences\\n[Den98] Daniel Dennett. Brainchildren: Essays on Designing Minds . MIT\\nPress, 1998.\\n[Jen98] Arthur R. Jensen. Does IQ matter? Commentary , pages 20\\u201321,\\nNovember 1998. The reference is just to Jensen\\u2019s comment\\u2014on e\\nof many.\\n[McC59] John McCarthy. Programs with Common Sense14. InMechani-\\nsation of Thought Processes, Proceedings of the Symposium o f the\\nNational Physics Laboratory , pages 77\\u201384, London, U.K., 1959.\\nHer Majesty\\u2019s Stationery O\\ufb03ce. Reprinted in [McC90].\\n[McC89] John McCarthy. Arti\\ufb01cial Intelligence, Logic and F ormalizing\\nCommon Sense15. In Richmond Thomason, editor, Philosophical\\nLogic and Arti\\ufb01cial Intelligence . Kl\\u00a8 uver Academic, 1989.\\n[McC90] John McCarthy. Formalizing Common Sense: Papers by John\\nMcCarthy . Ablex Publishing Corporation, 1990.\\n[McC96a] John McCarthy. Defending AI research : a collection of essays\\nand reviews . CSLI lecture notes: no. 49. Center for the Study\\nof Language and Information, 1996. distributed by Cambridg e\\nUniversity Press.\\n[McC96b] John McCarthy. Concepts of Logical AI16, 1996. Web only for\\nnow but may be referenced.\\n[Mit97] Tom Mitchell. Machine Learning . McGraw-Hill, 1997.\\n[Sha97] Murray Shanahan. Solving the Frame Problem, a mathematical\\ninvestigation of the common sense law of inertia . M.I.T. Press,\\n1997.\\n13http://www.nap.edu/readingroom/books/far/ch9.html\\n14http://www-formal.stanford.edu/jmc/mcc59.html\\n15http://www-formal.stanford.edu/jmc/ailogic.html\\n16http://www-formal.stanford.edu/jmc/concepts-ai.html\\n14[Tho03] Richmond Thomason. Logic and arti\\ufb01cial intelligen ce. In Ed-\\nward N. Zalta, editor, The Stanford Encyclopedia of Philosophy .\\n2003. http://plato.stanford.edu/entries/logic-ai/.\\n[Tur50] Alan Turing. Computing machinery and intelligence .Mind, 1950.\\n/@steam.stanford.edu:/u/ftp/jmc/whatisai.tex: begun S at Nov 23 10:30:17 1996, latexed November 12, 2007 at 2:05 a.m .\\n15\"\n        ],\n        \"num_unique_values\": 3,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "uxujba4OTXAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(pdf_text_data)"
      ],
      "metadata": {
        "id": "3cdOemmITyjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "t6jomyDhT7I2",
        "outputId": "7904d4fc-6bb9-4df4-bba6-e4d34400f183"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Filename  \\\n",
              "0  The-global-mangrove-watch-a-ne-4abecf89-c8a2-4...   \n",
              "1  A-New-Vegetation-Index-to-Dete-35086913-d72d-4...   \n",
              "2                                             Ai.pdf   \n",
              "\n",
              "                                                Text  \n",
              "0  remote sensing  \\nArticle\\nThe Global Mangrove...  \n",
              "1  remote sensing  \\nArticle\\nA New Vegetation In...  \n",
              "2  Extinguished philosophies lie about the cradle...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-94d75b39-f4d1-40da-abee-6944a54b570a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Filename</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The-global-mangrove-watch-a-ne-4abecf89-c8a2-4...</td>\n",
              "      <td>remote sensing  \\nArticle\\nThe Global Mangrove...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A-New-Vegetation-Index-to-Dete-35086913-d72d-4...</td>\n",
              "      <td>remote sensing  \\nArticle\\nA New Vegetation In...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ai.pdf</td>\n",
              "      <td>Extinguished philosophies lie about the cradle...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94d75b39-f4d1-40da-abee-6944a54b570a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-94d75b39-f4d1-40da-abee-6944a54b570a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-94d75b39-f4d1-40da-abee-6944a54b570a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fd231197-b1c1-4367-8518-095bbaeb2ff0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fd231197-b1c1-4367-8518-095bbaeb2ff0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fd231197-b1c1-4367-8518-095bbaeb2ff0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Filename\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"The-global-mangrove-watch-a-ne-4abecf89-c8a2-4e96-9c66-98c850be668f.pdf\",\n          \"A-New-Vegetation-Index-to-Dete-35086913-d72d-4d90-b224-4bd93a517488.pdf\",\n          \"Ai.pdf\"\n        ],\n        \"num_unique_values\": 3,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"remote sensing  \\nArticle\\nThe Global Mangrove Watch\\u2014A New 2010 Global\\nBaseline of Mangrove Extent\\nPete Bunting1,*\\n, Ake Rosenqvist2, Richard M. Lucas1,3, Lisa-Maria Rebelo4\\n,\\nLammert Hilarides5, Nathan Thomas6, Andy Hardy1\\n, Takuya Itoh7,\\nMasanobu Shimada8and C. Max Finlayson9\\n1Department of Geography and Earth Sciences, Aberystwyth University, Aberystwyth SY23 3DB, UK;\\nrichard.lucas@aber.ac.uk (R.M.L.); ajh13@aber.ac.uk (A.H.)\\n2Solo Earth Observation (soloEO), Tokyo 104-0054, Japan; ake.rosenqvist@soloEO.com\\n3School of Biological, Earth and Environmental Sciences (BEES), University of New South Wales (UNSW),\\nHigh Street, Kensington, NSW 2052, Australia\\n4International Water Management Institute, Regional Office for SE Asia and The Mekong,\\nP.O. Box 4199, Vientiane; l.rebelo@cgiar.org\\n5Wetlands International, 6700AL Wageningen, The Netherlands; Lammert.Hilarides@wetlands.org\\n6Earth System Science Interdicsiplinary Center, University of Maryland/NASA Goddard Space Flight Center,\\nCollege Park, MD 20742, USA; nathan.m.thomas@nasa.gov\\n7Remote Sensing Technology Center of Japan (RESTEC), Tsukuba Office, Ibaraki 305-8505, Japan;\\nitoh_takuya@restec.or.jp\\n8School of Science and Engineering, Tokyo Denki University, Saitama 350-0394, Japan;\\nshimada@g.dendai.ac.jp\\n9Institute for Land, Water and Society, Charles Sturt University, Albury, NSW 2640, Australia;\\nmfinlayson@csu.edu.au\\n*Correspondence: pete.bunting@aber.ac.uk; Tel.: +44-1970-622615\\nReceived: 31 July 2018 ; Accepted:18 October 2018; Published: 22 October 2018\\n/gid00030/gid00035/gid00032/gid00030/gid00038/gid00001/gid00033/gid00042/gid00045 /gid00001\\n/gid00048/gid00043/gid00031/gid00028/gid00047/gid00032/gid00046\\nAbstract: This study presents a new global baseline of mangrove extent for 2010 and has been\\nreleased as the first output of the Global Mangrove Watch (GMW) initiative. This is the first study\\nto apply a globally consistent and automated method for mapping mangroves, identifying a global\\nextent of 137,600 km2. The overall accuracy for mangrove extent was 94.0% with a 99% likelihood that\\nthe true value is between 93.6\\u201394.5%, using 53,878 accuracy points across 20 sites distributed globally.\\nUsing the geographic regions of the Ramsar Convention on Wetlands, Asia has the highest proportion\\nof mangroves with 38.7% of the global total, while Latin America and the Caribbean have 20.3%,\\nAfrica has 20.0%, Oceania has 11.9%, North America has 8.4% and the European Overseas Territories\\nhave 0.7%. The methodology developed is primarily based on the classification of ALOS PALSAR\\nand Landsat sensor data, where a habitat mask was first generated, within which the classification\\nof mangrove was undertaken using the Extremely Randomized Trees classifier. This new globally\\nconsistent baseline will also form the basis of a mangrove monitoring system using JAXA JERS-1\\nSAR, ALOS PALSAR and ALOS-2 PALSAR-2 radar data to assess mangrove change from 1996 to\\nthe present. However, when using the product, users should note that a minimum mapping unit\\nof 1 ha is recommended and that the error increases in regions of disturbance and where narrow\\nstrips or smaller fragmented areas of mangroves are present. Artefacts due to cloud cover and the\\nLandsat-7 SLC-off error are also present in some areas, particularly regions of West Africa due to the\\nlack of Landsat-5 data and persistence cloud cover. In the future, consideration will be given to the\\nproduction of a new global baseline based on 10 m Sentinel-2 composites.\\nKeywords: mangrove; extent; global; baseline; mapping; ALOS PALSAR; landsat; ramsar; global\\nmangrove watch; K&C\\nRemote Sens. 2018,10, 1669; doi:10.3390/rs10101669 www.mdpi.com/journal/remotesensingRemote Sens. 2018,10, 1669 2 of 19\\n1. Introduction\\nMangroves are forested wetlands that are uniquely adapted to the intertidal zone. Found in the\\ncoastal zones of more than 118 countries in the tropics, subtropics and temperate regions [1\\u20133],\\nmangroves have (for centuries) provided natural resources to local populations, including food\\n(particularly fish and invertebrates) and timber. However, through processes such as population\\nincreases, industrialisation, urban expansion and globalisation, their extent has been reduced [ 4] and\\nmany have been fragmented or degraded [ 5], particularly in Southeast Asia, where about one third\\n(32%) of the world\\u2019s mangroves are located [ 6]. Many of the mangrove areas that have remained\\nrelatively intact are those that are remote, inaccessible, protected within conservation reserves or\\nreceive national protection, for example in Australia. Globally, mangroves are being increasingly\\naffected by climatic fluctuations, including those induced by human activities [ 5]. At the same\\ntime, mangroves are receiving greater recognition for their role in food provision, coastal protection\\n(e.g., from large storms), reserves of biodiversity [ 7] and as a large carbon store [ 8]. Hence, there are\\nnumerous and increasing efforts to ensure protection and restoration across their range. A fundamental\\nrequirement for mangrove protection and restoration is information about current and historical\\nmangrove distributions and conditions. While critical for informing efforts that support conservation,\\nsustainable management, and restoration of these ecosystems, data on mangrove status and extent\\nare necessary to meet reporting requirements for signatories to the Ramsar Convention on Wetlands\\nand other countries with mangroves in their territories who are striving to meet the Sustainable\\nDevelopment Goals [5,9].\\nAt a global level, maps of mangrove extent have previously been generated by Spalding et al. for\\n1960\\u20131996 [ 3] and 1999\\u20132003 [ 2], by curating the best available national and regional maps, and by\\nthe United States Geological Survey (USGS; [ 1]) for 2000, based on the classification of Landsat sensor\\ndata primarily from 1997\\u20132000. The FAO [ 4,10,11] have also conducted surveys to estimate global\\nextent for 1980, 1990 and 2000 and, in the later studies, both the FAO and Spalding et al. [2]referred\\nto the 2000 Giri et al. [1] to fill in gaps in coverage. The map of Giri et al. [1]has been regarded as the\\nmost globally consistent because of the standardised use of Landsat sensor data and methodology\\nwithin a defined period but, in some cases, the contribution of local to regionally-derived maps\\nto Spalding et al. [2] results in better mapping (depending on the scales and methods used). Hence,\\nwhilst the maps of mangrove area are broadly in agreement, many differences exist in terms of area\\nand boundary locations with these sometimes exaggerated by differences in accuracy in the geometric\\nlocation, scale and generalisation of the map products. The maps generated are also historical (currently\\nby at least two decades) and are unable to be easily updated and certainly not on a regular (e.g., annual)\\nbasis. Rates of mangrove loss can also then not be determined as the products from different years are\\nbased on different methods.\\nTo address the need for timely information on mangroves at a global level, the Japan Aerospace\\nExploration Agency (JAXA) Kyoto & Carbon (K&C) Initiative formulated the Global Mangrove Watch\\n(GMW), which aimed to produce consistent 25 m spatial resolution maps of mangrove extent across\\ntheir range by generating a baseline map for 2010. For mapping, Japanese L-band Synthetic Aperture\\nRadar (SAR) data were considered most appropriate given their global coverage and sensitivity\\nto the woody components of mangroves [ 12]. However, a limitation is that mangroves are often\\ndifficult to distinguish from other land covers (particularly forests and plantations) on the landward\\nmargins. For this reason, Landsat sensor data were integrated into the analysis to improve the baseline\\nmap. The mapping was also confined to locations with conditions considered suitable to support\\nmangroves. The objective of the GMW is to provide the information needed by a wide range of users,\\nincluding wetland and forest managers, civil society organisations, contracting partners of the Ramsar\\nConvention, and countries with mangroves in their territories.\\nMany studies have used Earth Observation (EO) data to map mangrove extent. At a global level,\\nthe study of Giri et al. [1]was the first, with this using an unsupervised classification approach and\\nmanual selection of classes associated with mangroves. Many studies have used the Giri et al. [1]Remote Sens. 2018,10, 1669 3 of 19\\nproduct as a basis for further analysis. For example, Hamilton and Casey [13]intersected the\\nGiri et al. [1] map with the forest cover change of Hansen et al. [14]to assess changes in mangrove\\nextent. Thomas et al. [6]was the first to consider L-band SAR for global assessment of mangrove\\nchange, which was assessed visually by on a 1\\u000e\\u00021\\u000egrid overlain onto a composite of Japanese Earth\\nResources Satellite (JERS-1) SAR from 1996 and Advanced Land Observing Satellite (ALOS PALSAR)\\ndata from 2007 and 2010. Causes of change were also reviewed based on features including shape and\\ncontext. Other studies have been more focused on local sites, such as a single delta (e.g., the Mangoky\\nRiver delta, Madagascar [ 15], Mekong Delta, Vietnam [ 16]) or countries (e.g., Mozambique [ 17],\\nPhilippines\\u2019 [ 18], Kenya [ 19], and Mexico [ 20]). Methods adopted have varied. The majority have\\nused optical (primarily Landsat) datasets (e.g., [ 15,17\\u201319]), while a few have fused optical and SAR\\ndata (e.g., [ 21,22]). In terms of analysis, a broad range of techniques have been used, including object\\norientated methods making use of image segmentation (e.g., [ 23]), rule based classifiers (e.g., [ 21]),\\nunsupervised classifiers (e.g., [ 17,18,24]) and machine learning methods (e.g., [ 22,23]). While there\\nis no clear dominant direction in terms of methodology for assessing mangrove extent, a significant\\ngap is the lack of studies that have sought to develop and apply a single consistent methodology that\\nis repeatable over large geographic areas, including at the global level. Therefore, this study aims to\\nprovide a new updated baseline of global mangrove extent, which can be used as a basis for studying\\nmangrove change and uses a single globally consistent methodology.\\n2. Methods\\nThe new global mangrove baseline has been generated using a combination of Synthetic Aperture\\nRadar (SAR) from the Advanced Land Observing Satellite (ALOS) Phased-Array L-band Synthetic\\nAperture Radar (PALSAR) and optical satellite data from Landsat-5 Thematic Mapper (TM) and\\nLandsat-7 Enhanced TM (ETM+). The overall approach followed four stages: (a) extraction of a\\ncoastal water mask from the PALSAR data; (b) generation of a mangrove \\u201chabitat\\u201d layer that identified\\nareas that were actually or potentially able to support mangroves; (c) generation of an initial baseline\\nclassification using the PALSAR data only; and (d) refinement of the initial baseline classification using\\nLandsat sensor composites to improve the distinction of the landward border between mangroves and\\nother terrestrial land covers. A final quality assurance (QA) of the resulting baseline product was then\\nundertaken through visual assessment and, where appropriate, errors were corrected. An overview of\\nthe methods for producing the new mangrove baseline is shown in Figure 1.\\nUnless otherwise stated, all data processing was undertaken using the open source Remote\\nSensing and GIS Software Library (RSGISLib [ 25]), the KEA file format [ 26], the Scikit-Learn [ 27]\\nmachine learning library and scripted in python as outlined by Clewley et al. [28].\\n2.1. Datasets\\nUsing data acquired in 2010, a baseline map of mangrove extent was generated by integrating\\nALOS PALSAR and a composite of Landsat sensor data and referencing the 2000 Shuttle Radar\\nTopographic Mission (SRTM) 30 m Digital Elevation Model data and existing products delineating\\nshorelines, surface water occurrence and previous attempts to delineate global mangrove extents.\\nThese datasets are summarised in Table 1\\nFrom the global shoreline dataset, a global ocean regions dataset was derived to identify oceanic\\nwater bodies. The shoreline dataset was rasterised onto the same pixel grid as the ALOS PALSAR data\\nand oceanic water was defined as pixels that were 200 pixels ( \\u00185000 m) from the defined shoreline.Remote Sens. 2018,10, 1669 4 of 19\\nMangrove BaselineCoastal MaskMangrove \\u2018Habitat\\u2019Mangrove Baseline (2010) #1Water OccurrenceBathymetryShoreline2010 PALSARExtremely Randomized Trees Classi\\ufb01cationDist. Giri et al Dist. Mangrove AtlasLat/LongDist. WaterDist. OceanElevationExtremely Randomized Trees Classi\\ufb01cationGiri 2000Mangrove AtlasDist. Shoreline2010 PALSARExtremely Randomized Trees Classi\\ufb01cationMangrove Baseline (2010) #22010 Landsat CompositeExtremely Randomized Trees Classi\\ufb01cationMerge into Global ProductQuality Assurance\\nFigure 1. Overview of the methodology for producing a global mangrove baseline. The numbers\\nreference the section number within the article, while the main flow of boxes indicate data dependency\\nbetween the stages (e.g., the coastal water mask is used to defined the mangrove habitat mask).\\nTable 1. Details of the datasets and sources used for this project.\\nDataset Period Resolution Source\\nALOS PALSAR 2010 25 m JAXA\\nLandsat TM and ETM+ 2009\\u20132011 30 m USGS\\nShuttle Radar Topography Mission (SRTM) 2000 30 m NASA\\nWater Occurrence 1984\\u20132016 30 m JRC [29]\\nGlobal Distribution of Mangroves USGS (v 1.3) 1997\\u20132000 30 m Giri et al. [1]\\nWorld Atlas of Mangroves (v 1.1) 1999\\u20132003 1:1,000,000 Spalding et al. [2]\\nGlobal Self-consistent Hierarchical\\nHigh-resolution Shorelines (v 2.3.5)- \\u201cFull Resolution\\u2019 [30,31]\\nGEBCO gridded bathymetry 2014 30 arc-seconds [32]\\nAll data were re-sampled or rasterised onto the same 0.8 arc-second pixel grid as the ALOS\\nPALSAR data. For the SRTM data cubic spline interpolation was used, while for other continuous data\\n(e.g., Landsat) a cubic convolution was applied and for categorical data nearest neighbour interpolation\\nwas used.\\n2.1.1. ALOS PALSAR\\nThe ALOS PALSAR dual polarisation (HH+HV) backscatter data used were provided by JAXA\\nas1\\u000e\\u00021\\u000emosaic tiles. The nominal spatial resolution was 25 m (0.8 arc seconds) and data were\\nprovided in the WGS84 (EPSG:4326) coordinate system. The mosaics are openly available in the public\\ndomain (http://www.eorc.jaxa.jp/ALOS/en/palsar_fnf/fnf_index.htm). The processing undertaken\\nto produce the tiled mosaics is detailed in Shimada et al. [33]. Global mosaics from JERS-1 SAR, ALOS\\nPALSAR and ALOS-2 PALSAR-2 were available for 1996, annually from 2007 to 2010 and from 2015 to\\n2017. However, the 2010 mosaic was the most complete in terms of temporal consistency and spatial\\ncoverage and therefore was defined as the baseline (reference) year.\\n2.1.2. Landsat Composites\\nAlthough the ALOS PALSAR dual polarisation L-band SAR data provided a reasonable level\\nof discrimination of mangroves from other land cover types (particularly bare ground), there was\\nsome confusion with other wetland or forest types. This was particularly the case for certain\\ntypes of adjoining terrestrial forests and wetlands with similar structure to mangroves. However,\\nmangroves were distinct from many of these land covers within the Landsat sensor data, particularly inRemote Sens. 2018,10, 1669 5 of 19\\nthe near infrared and shortwave infrared wavelength regions. For this reason, composite images were\\ngenerated using Landsat sensor data acquired for 2010, although 2009 and 2011 images were also used,\\nwhere necessary, to provide sufficient imagery for the processing. In order to minimise the impact\\nof the Landsat 7 scan-line (SLC-off) error, which results in no-data striping in the imagery, Landsat 5\\ndata were primarily selected when available. To identify the scenes to download for each Landsat\\nrow/path, the following sequence of rules were applied:\\n1. Identify 10 Landsat 5 scenes with less than 10% cloud cover from 2010.\\n2. If less than 10 scenes available, then add Landsat 7 scenes with less than 10% cloud cover\\nfrom 2010.\\n3. If less than 5 scenes, then add Landsat 5 and 7 scenes from 2010 with less than 50% cloud up to a\\nmaximum of 15 scenes.\\n4. If less than 5 scenes, then extend time range to 2009\\u20132011 and repeat Steps 1\\u20133.\\nA total of 15,346 top-of-atmosphere Landsat scenes from 1766 row/paths were downloaded\\nusing the Google Cloud API (https://cloud.google.com/storage/docs/public-datasets/landsat).\\nThe images where processed to surface reflectance, cloud masked and topographically corrected using\\nthe \\u201cAtmospheric and Radiometric Correction of Satellite Imagery\\u201d (ARCSI [ 34]) software. ARCSI\\nderives a scene based aerosol optical depth (AOD) value using a dark object subtraction (DOS [ 35])\\nwhere a numerical inversion of the 6S [ 36] atmospheric model is applied to derive an AOD value\\nbased on the Blue wavelength. The 30 m (1 arc-second) SRTM elevation model was used to construct a\\nlook-up table (LUT) for correction with respect to elevation, which was applied subsequently to the\\ninput image to derive standardised (i.e., topographically corrected) reflectance using the approach\\nof Shepherd and Dymond [37]. The FMASK [ 38,39] cloud masking algorithm was applied for removal\\nof cloud and cloud shadow.\\nTo allow fusion with the ALOS PALSAR data, the resulting Landsat data were re-sampled,\\nusing cubic convolution, to match the 0.8 arc-second pixel grid of the ALOS PALSAR data. A maximum\\nNDVI compositing [ 40,41] processing chain was then applied using RSGISLib [ 25] at a project level\\n(see Section 2.2) to generate a single Landsat composite image corresponding with the project region\\ndefined using the ALOS PALSAR data.\\n2.2. Project Region Definition\\nTo undertake the processing, 128 project regions were defined that grouped the 1\\u000e\\u00021\\u000etiles\\nsuch that: (a) no continuous area of mangroves was split by a project border; (b) the mangroves\\nwithin a project were considered to be contained within a similar bio-geographic region and (c) the\\ncomputational requirements of processing the projects were appropriate (i.e., balancing speed of\\nprocessing with available computing resource).\\nThe projects were defined by the union of Giri et al. [1]and Spalding et al. [2]datasets, where each\\nwere buffered by 0.1\\u000eand touching or overlapping polygons merged. The resulting polygons where\\nclustered using the approach outlined in Bunting et al. [42]where the minimum spanning tree was\\ncreated and edges with a length >0.5\\u000eor greater than 1 standard deviation of the edge lengths in\\nthe tree removed creating individual clusters. The resulting groups where then assessed, with small\\nregions merged into larger regions and large regions split when these were deemed too large for\\nefficient computational processing. This resulted in 131 project regions globally, although, for three,\\nthere were no ALOS PALSAR data and so they were excluded. The resulting 128 projects where\\nintersected with the 1\\u000e\\u00021\\u000etile grid and grouped into 12 geographic regions (Figure 2) to create a\\nhierarchical numbering system.Remote Sens. 2018,10, 1669 6 of 19\\nFigure 2. GMW project regions: ( A) the 12 top level regions; and ( B) an example of the individual\\nprojects for the South American region.\\n2.3. Coastal Mask\\nMangroves are found within a coastal environment and therefore a key component of defining the\\nmangrove habitat mask was to define a coastal water mask. To achieve this, a water mask was defined\\nusing a per-pixel Extremely Randomized Trees classification using Scikit-Learn [ 27] and RSGISLib [ 25]\\nsoftware. The number of estimators for the Extremely Randomized Trees classifier was defined as 500\\nfollowing a grid search sensitivity analysis. The classification was performed using the ALOS PALSAR\\nHH and HV polarisations, the ratio of HH/HV, local incident angle and acquisition date.\\nThe key step in defining the coastal water mask was to define the training samples and regions\\nto be classified, which was performed automatically. An initial water mask was produced using a\\nthreshold of > 20water occurrences, and this was subsequently intersected with the oceanic region\\n(Section 2.1) to identify oceanic water. A coastal region was then defined as the area 20 pixels ( \\u0018500 m)\\neither side of the shoreline with a bathymetry depth of > \\u0000100m. Additional regions based on 80 pixels\\n(\\u00182000 m) either side of the shoreline and a water occurrence < 80were added to this mask, with this\\nthen defining the region to be classified. 100,000 training pixels were then extracted randomly for land\\nand water from regions between > 20(\\u0018500 m) and < 80(\\u00182000 m) pixels away from the shoreline,\\nwith this defined as water or land using the water mask retrieved from the water occurrence layer.\\nFollowing the classification, a refinement was performed to remove small features, which required\\nclumping the classification to identify connected regions of a single class. Clumps classified as\\nland with an area of < 20pixels ( \\u001812,500 m2) and > 20water occurrence observations were assigned\\nto the water class, while water regions with an area of < 50pixels ( \\u001831,250 m2) were assigned to\\nland. These thresholds were identified through a sensitivity analysis and by visually assessing the\\nresulting maps.Remote Sens. 2018,10, 1669 7 of 19\\nThe thresholds used for generating the coastal mask were identified through an iterative sensitivity\\nanalysis based on a visual inspection of the resulting maps for a number of projects and sites globally\\nrepresenting a range of mangrove habitats.\\n2.4. Mangrove Habitat\\nMangroves exist within a specific ecological niche, which can be used to eliminate much of the area\\nwhere they will not be found. To define the region to be classified, and from which the non-mangrove\\npixels were selected, the following rules were defined, applied on a per-project basis. First, the SRTM\\nelevation needed to be less than 110% of the 99th percentile of the elevation of mangrove pixels. If the\\nresulting threshold was less than 5 m the threshold was set to 30 m, remembering that the SRTM is a\\nsurface model and therefore includes a component of vegetation height. The second rule, defined that\\nthe distance from the coastal water mask needed to be less than 110% of the 99th percentile of the\\ndistance of the mangrove pixels.\\nWithin the region defined above, a classification was subsequently performed. In total, 100,000\\nmangrove training pixels were randomly extracted from a union of the existing global mangrove\\nmaps from Giri et al. [1] and Spalding et al. [2], while 100,000 non-mangrove training samples were\\nrandomly extracted from within the region but outside of the mangrove union. If less than 100,000\\nmangrove pixels were available, then the number of samples selected for both classes was equal to the\\nnumber of mangrove pixels within the project.\\nThe classification was performed using the Extremely Randomized Trees classifier,\\nwith 100 estimators, defined through the use of a grid search sensitivity analysis of classifier\\nparameters. The input variables to the classification were: (a) pixel longitude and latitude; (b) distance\\nto water (defined using the coastal mask); (c) surface elevation defined by the SRTM; (d) distance to\\nthe oceanic layer; and (e) distances to the mangrove extents of Giri et al. [1]and Spalding et al. [2].\\nThe resulting habitat mask was visually checked and missing regions, including those that were not\\nidentified in the Giri et al. [1] and Spalding et al. [2] products, were added manually.\\nThe mangrove habitat layer (to be available at http://www.globalmangrovewatch.org) defines\\nthe maximum possible extent of mangrove habitat and therefore would not be needed to re-calculated\\nfor any subsequent mangrove mapping efforts.\\n2.5. Baseline Classification\\nThe new baseline was classified in two independent steps: first using the ALOS PALSAR and then\\nthe Landsat data. The ALOS PALSAR data were geographically contained entirely within the projects,\\nwhich allowed complete classification, but there were occasional gaps in the coverage of the Landsat\\nsensor data primarily because of cloud cover. In these gaps, the classification was based solely on the\\nALOS PALSAR data.\\n2.5.1. Classification: ALOS PALSAR\\nThe classification was undertaken using the Extremely Randomized Trees classifier, based on\\n100 estimators that were also defined through a grid search sensitivity analysis. The input variables\\nwere ALOS PALSAR HH and HV data (transformed to log unit dB), the ratio of HH/HV, pixel longitude\\nand latitude and the mangrove probability. Mangrove probability was defined using the union of\\nmangrove extent and generating a multi-dimensional histogram for the HH, HV and HH/HV data for\\nmangroves (defined using Giri et al. [1]) with a bin width of 0.25. The histogram was converted to a\\nprobability distribution function, which was used to calculate a probability of mangroves occurring in\\neach pixel.\\nTraining samples where defined through random sampling where 100,000 mangrove and\\nnon-mangrove samples were taken, resulting in 200,000 in total per project. For mangrove, 20,000\\nsamples were extracted from the intersection of the Giri et al. [1]and Spalding et al. [2]products and\\nthe remaining 80,000 were taken from the union of the two products. The non-mangrove samples wereRemote Sens. 2018,10, 1669 8 of 19\\nalso split, with 20,000 from within the habitat mask and 80,000 outside. The region outside the habitat\\nmask, within which training samples were selected, was defined as < 150pixels ( \\u00183750 m) from the\\nunion of the mangrove products over areas of water and < 250pixels ( \\u00186250 m) over terrestrial areas.\\nThe training points were visually checked and edited with reference to Google Earth Imagery as well\\nas the ALOS PALSAR and Landsat sensor imagery. In total, 20 M training points were defined globally\\nacross the 128 projects.\\n2.5.2. Classification: Landsat\\nUsing only a classification of ALOS PALSAR data, a consistent over-classification of the area of\\nmangroves was observed with this attributed to similarities in the structure and moisture content\\nof wetlands and forest cover types (indicated earlier). Therefore, a further refinement using optical\\nimagery was deemed necessary. The second classification iteration used the same training samples\\nas the ALOS PALSAR classification but samples without valid Landsat sensor data were removed.\\nUsing the Blue, Green, Red, Near-Infrared (NIR), Shortwave Infrared 1 (SWIR1) and SWIR2 spectral\\nbands, the Extremely Randomized Trees classifier, again using 100 estimators identified through a\\nsensitivity analysis, was applied to generate the final classification.\\n2.6. Merging into a Global Product\\nThe resulting project based analysis was compiled into a single global product for 2010 on a\\n1\\u000e\\u00021\\u000etile basis. A few project regions shared individual tiles and these needed to be merged,\\nwhich was undertaken using a union operation.\\n2.7. Quality Assurance\\nFollowing the automated analysis, an extensive quality assurance (QA) process was undertaken.\\nDuring this process, the product was visually checked against the ALOS PALSAR and Landsat sensor\\ndata as well as contemporary (2010) Google Earth imagery. Where significant errors of omission and\\ncommission were identified, polygons were drawn and edits applied.\\n2.8. Accuracy Assessment\\nTo assess the overall accuracy of the product, a point-based accuracy assessment was undertaken.\\nFor the accuracy assessment, a stratified random sample was undertaken within each project using the\\nwater, mangrove and terrestrial non-mangrove classes, within a 50 pixels ( \\u00181250 m) buffer from the\\nmangrove regions and within the mangrove habitat region. The number of accuracy samples, for each\\nclass, was 0.5% of the number of mangrove pixels, unless the resulting number of samples was less\\nthan 1000 in which case a 1% sample was taken.\\nWithin the projects, sites were selected (Figure 3 and Table 2) based on available local knowledge\\nand in some cases high resolution data. The accuracy assessment was undertaken using a custom\\nQGIS plugin that guides the operator to each point, providing a simple interface to decide between\\nclasses. The imagery used for reference included high resolution Google Earth imagery, custom high\\nresolution imagery, GMW Landsat image composites and ALOS PALSAR 2010 data.\\nTable 2. Regions where the accuracy assessment was undertaken and the number of accuracy samples\\nwhich were used.\\nSite Number Points\\nAustralia 4347\\nFiji 6487\\nHaiti 1356\\nIndonesia (1) 1343\\nIndonesia (2) 3717Remote Sens. 2018,10, 1669 9 of 19\\nTable 2. Cont.\\nSite Number Points\\nIndonesia (3) 144\\nJapan/Okinawa 2742\\nMexico (1) 6948\\nMexico (2) 2167\\nMyanmar 1106\\nPapua New Guinea 854\\nSamoa 90\\nSaudi Arabia 339\\nIndia 910\\nTanzania (Rufiji Delta) 3449\\nTonga 72\\nUSA (Mississippi Delta) 4590\\nUSA (West Florida) 5615\\nVenezuela 1793\\nVietnam 5809\\nTotal 53,878\\nVersion September 8, 2018 submitted to Remote Sens. 9 of 19\\nTable 2. Regions where the accuracy assessment was undertaken and the number of accuracy samples\\nwhich were used.\\nSite Number Points\\nAustralia 4347\\nFiji 6487\\nHaiti 1356\\nIndonesia (1) 1343\\nIndonesia (2) 3717\\nIndonesia (3) 144\\nJapan/Okinawa 2742\\nMexico (1) 6948\\nMexico (2) 2167\\nMyanmar 1106\\nPapua New Guinea 854\\nSamoa 90\\nSaudi Arabia 339\\nIndia 910\\nTanzania (Rufiji Delta) 3449\\nTonga 72\\nUSA (Mississippi Delta) 4590\\nUSA (West Florida) 5615\\nVenezuela 1793\\nVietnam 5809\\nTotal 53878\\n-20-20002020-180\\n-180-160\\n-160-140\\n-140-120\\n-120-100\\n-100-80\\n-80-60\\n-60-40\\n-40-20\\n-200\\n020\\n2040\\n4060\\n6080\\n80100\\n100120\\n120140\\n140160\\n160180\\n180\\nFigure 3. Distribution of sites used to undertake the accuracy assessment.\\n(23.4\\u25e6S). Asia is estimated to account for 38.7 % of the world\\u2019s mangroves, with Southeast Asia alone 294\\nrepresenting almost a third (32.2 %). The Americas are estimated to comprise 28.7 %, and Africa and 295\\nOceania 20.0 % and 11.9 %, respectively. European Overseas Territories account for 0.7 %. 296\\nTable 3 shows the extent of mangroves for the six Ramsar regions, Asia is the region with the 297\\nlargest area of mangroves (53,278 km2) with Latin America and the Caribbean (previously referred to 298\\nas the Neotropics) (27,940 km2) and Africa (27,465 km2) regions having the similar amounts. While 299\\nin terms of individual countries (Table 4) Indonesia contain 19.5 % of the worlds mangroves and the 300\\nnext three highest, by area, Brazil, Australia and Mexico combined contain 22.3 %. 301\\n3.2. Accuracy Assessment 302\\nThe overall accuracy (Table 5) of the classification was 95.3 %, with a 99 % likelihood that 303\\nthe confidence interval, using the Wilson score interval [43], was between 4.5\\u20135.0 %. Therefore, 304\\nthe overall accuracy was in the range 95.0\\u201395.5 %. 53,878 sample points (Table 2) were used for 305\\nthe accuracy assessment, where the points were manually allocated to the classes of mangroves, 306\\nwater and terrestrial (other). In terms of mangroves, the main confusion was with other terrestrial 307\\nFigure 3. Distribution of sites used to undertake the accuracy assessment.\\n3. Results\\n3.1. Mangrove Baseline\\nThe resulting baseline map of global mangrove extent gives an estimated total mangrove area\\nin 2010 of 137,600 km2. A Mollweide Equal Area projection was used for all area calculations.\\nFigure 4 illustrates the global distribution of mangroves, which can be found as far north as 32.3\\u000eN\\n(Bermuda) and as far south as 38.9\\u000eS (Australia). Figure 5 illustrates the spatial detail within the\\nmap. Approximately 96% are found between the Tropic of Cancer ( 23.4\\u000eN) and Tropic of Capricorn\\n(23.4\\u000eS). Asia is estimated to account for 38.7% of the world\\u2019s mangroves, with Southeast Asia alone\\nrepresenting almost a third (32.2%). The Americas are estimated to comprise 28.7%, and Africa and\\nOceania 20.0% and 11.9%, respectively. European Overseas Territories account for 0.7%.\\nTable 3 shows the extent of mangroves for the six Ramsar regions. Asia is the region with the\\nlargest area of mangroves (53,278 km2) with Latin America and the Caribbean (previously referred to\\nas the Neotropics) (27,940 km2) and Africa (27,465 km2) regions having similar amounts. In terms of\\nindividual countries (Table 4), Indonesia contains 19.5% of the worlds mangroves and the next three\\nhighest, by area, Brazil, Australia and Mexico combined contain 22.3%.\\n3.2. Accuracy Assessment\\nThe overall accuracy (Table 5) of the classification was 95.3%, with a 99% likelihood that the\\nconfidence interval, using the Wilson score interval [ 43], was 4.5\\u20135.0%. Therefore, the overall\\naccuracy was in the range 95.0\\u201395.5%. In total, 53,878 sample points (Table 2) were used for the\\naccuracy assessment, where the points were manually allocated to the classes of mangroves, water andRemote Sens. 2018,10, 1669 10 of 19\\nterrestrial (other). In terms of mangroves, the main confusion was with other terrestrial vegetation,\\ndemonstrating that 97.5% of the areas classified as mangroves were correct with the confusion resulting\\nin a producers accuracy of 94.0%. Therefore, there is a 99% likelihood that the confidence interval for\\nthe overall mangrove accuracy was between 93.6\\u201394.5%.\\nFigure 4. GMW mangrove baseline for 2010 and distribution of mangroves in longitude and latitude\\n(WGS-84; epsg:4326).\\nFigure 5. Example GMW v2.0 maps, using the Open Street Map (https://www.openstreetmap.org) data\\nas background mapping. From west to east: ( A) Central America (Honduras/Nicaragua); ( B) Africa\\n(Madagascar); and ( C) Australia (Queensland). The maps are presented in WGS-84 (epsg:4326) with\\ncoordinates in decimal degrees (valid for all figures below).\\nTable 3. GMW v2.0 baseline extents for the six Ramsar regions.\\nRegion GMW v2.0 (km2) Percentage of Global (%)\\nAfrica 27,465 20.0\\nAsia 53,278 38.7\\nEurope (Overseas Territories) 1026 0.7\\nLatin America and the Caribbean 27,939 20.3\\nNorth America 11,563 8.4\\nOceania 16,329 11.9\\nTotal 137,600\\nThe most common errors observed within the GMW baseline are associated with fine-scale\\nfeatures (e.g., riverine, aquaculture and fine coastal fringes; Figure 6), which was particularly the\\ncase for areas with a high degree of anthropogenic fragmentation. As the minimum feature size of\\nobjects identifiable within the ALOS PALSAR and Landsat sensor data encompassed multiple pixels,Remote Sens. 2018,10, 1669 11 of 19\\na recommended minimum mapping unit of 1 ha (i.e., 8 pixels) for reliable mapping is considered to be\\nthe most appropriate for end users.\\nTable 4. GMW v2.0 baseline extents for the world\\u2019s Top 10 countries with mangroves.\\nCountry GMW v2.0 (km2) Percentage of Global (%)\\nIndonesia 26,890 19.5\\nBrazil 11,072 8.1\\nAustralia 10,060 7.3\\nMexico 9537 6.9\\nNigeria 6958 5.1\\nMalaysia 5201 3.8\\nMyanmar 5011 3.6\\nPapua New Guinea 4762 3.5\\nBangladesh 4163 3.0\\nIndia 3521 2.6\\nTable 5. Accuracy assessment of the GMW v2.0 baseline.\\nMangroves Water Terrestrial Other User\\u2019s\\nMangroves 18,246 98 370 97.5%\\nWater 191 16,463 101 98.3%\\nTerrestrial Other 969 828 16,612 90.2%\\nProducer\\u2019s 94.0% 94.7% 97.2% 95.3%\\nFigure 6. Anthropogenic disturbance near Surabaya in Eastern Java, Indonesia. The background\\nimagery is the 2010 Landsat composite generated for this study, visualised using the NIR, SWIR and\\nRed wavelength bands. ( A) The Landsat composite, where the mangroves appear orange within the\\nband combination: and ( B) the Landsat composite with the GMW v2.0 baseline displayed over the top,\\nin green.\\n3.3. Comparison to Existing Maps\\nAlthough the time period for which they refer and methodology for production differ,\\na comparison between the GMW 2010 baseline and the 2000 Giri et al. [1](1997\\u20132000) and\\nSpalding et al. [2] (1999\\u20132003) datasets was undertaken (Table 6) for the six Ramsar regions.\\nThe Giri et al. [1] and Spalding et al. [2]datasets both represent a period of around 2000 while the\\nGMW product is for 2010 so some differences in area were expected. Although the global total\\nestimates of the 2010 GMW v2.0 baseline and the 2000 Giri et al. [1]datasets are very close (137,600Remote Sens. 2018,10, 1669 12 of 19\\nversus 137,760 km2), significant differences (>10%) between the datasets can be observed at a regional\\nlevel that are unlikely to be attributed to actual changes. These differences are, in part, due to errors\\nand missing regions in the products (e.g., Figure 7).\\n-0.50-0.75103.25103.25\\n103.50103.50\\n103.75103.75\\n103.25103.25\\n103.50103.50\\n103.75103.75\\n-0.50-0.75103.25103.25\\n103.50103.50\\n103.75103.75ABC\\nFigure 7. Riau/Jambi in Sumatra, Indonesia: ( A) GMW v2.0 baseline; ( B) Giri et al. [1]; and\\n(C) Spalding et al. [2] , illustrating differences between the three datasets. Background maps: Open\\nStreet Map (https://www.openstreetmap.org).\\nVisually, there is often a high degree of similarity between the products (see, for example, Figure 8).\\nHowever, numerical comparison of the Giri et al. [1]and Spalding et al. [2]products demonstrated\\nsignificant differences between these two products where, for instance, the global estimates of\\nmangrove extent equate to 137,760 km2versus 152,361 km2, respectively. The corresponding FAO [11]\\nestimates for 2000 and 2005 are 157,400 km2and 152,310 km2, respectively. This highlights a\\nsignificant uncertainty in our knowledge of global mangrove extent. Through a visual comparison, it\\nis considered that Spalding et al. [2]often overestimates the overall mangrove extent (e.g., Figure 9),\\nalthough there are also regions of missing data (e.g., Figure 7). At a regional scale, the errors\\nassociated with the Spalding et al. [2]dataset are relatively clear. For instance, the Spalding et al. [2]\\ndataset demonstrates that the region covering Latin America and the Caribbean accounts for 23.1%\\nof the World\\u2019s mangroves compared with 20.3% denoted by the GMW v2.0 baseline. Similarly,\\nthe Spalding et al. [2] dataset demonstrates that the Oceania region accounts for 7.7% of the world\\u2019s\\nmangroves, compared to 11.9% that is denoted in this study and in the Giri et al. [1] dataset.\\nTable 6. Mangrove extent comparison for the six Ramsar regions between the GMW v2.0 baseline,\\nGiri et al. [1] (v1.3; released 2015) and Spalding et al. [2](v2.0; released 2017). Figures for the latter\\ntwo were calculated from datasets downloaded from the UN Ocean Data Viewer (http://data.unep-\\nwcmc.org), and thus differ marginally from figures published by Giri et al. [1]and Spalding et al. [2]\\n(in brackets). It should be recognised that the comparison between these products should not be used\\nto infer changes in mangrove extent, as the differences rather can be considered to be predominately\\ndue to the mapping methodology and accuracy.\\nRegionGMW v2.0 (km2)\\n2010Giri et al. [1] (km2)\\n1997\\u20132000Spalding et al. [2] (km2)\\n1999\\u20132003\\nAfrica 27,465 (20.0%) 26,342 (19.1%) 31,149 (20.5%)\\nAsia 53,278 (38.7%) 55,068 (40.0%) 60,435 (39.7%)\\nEurope (Overseas Terr.) 1026 (0.7%) 1427 (1.0%) 1194 (0.8%)\\nLatin America and the Caribbean 27,939 (20.3%) 28,643 (20.8%) 35,113 (23.1%)\\nNorth America 11,563 (8.4%) 9739 (7.1%) 12,492 (8.2%)\\nOceania 16,329 (11.9%) 16,380 (11.9%) 11,735 (7.7%)\\nTotal 137,600 137,599 (137,760) 152,118 (152,361)Remote Sens. 2018,10, 1669 13 of 19\\n4.254.00117.25117.25\\n117.50117.50\\n117.75117.75\\n117.25117.25\\n117.50117.50\\n117.75117.75\\n4.254.00117.25117.25\\n117.50117.50\\n117.75117.75ABC\\nFigure 8. Border of North Kalimantan, Indonesia, and Sabah, Malaysia, illustrating a typical region\\nwith good correspondence between the GMW v2.0 baseline and the Giri et al. [1]andSpalding et al. [2]\\nproducts: ( A) GMW v2.0 baseline; ( B) Giri et al. [1]; and ( C) Spalding et al. [2]. Background maps:\\nOpen Street Map.\\n13.40\\n-87.50-87.50\\n-87.45-87.45\\n-87.50-87.50\\n-87.45-87.45\\n13.40\\n-87.50-87.50\\n-87.45-87.45ABC\\nFigure 9. Atl\\u00e1ntico Norte, Nicaragua: ( A) GMW v2.0 baseline; ( B) Giri et al. [1]; and ( C) Spalding et al. [2],\\nillustrating a region where the Spalding et al. [2]is generalised and overestimates the mangroves extent\\ncompared to Giri et al. [1]and the GMW v2.0 baseline. In this example, the Giri et al. [1]product has\\nmore detail than the GMW v2.0 baseline. Background maps: Open Street Map.\\n4. Discussion\\n4.1. Methods of Mapping Mangroves\\nOur results have yielded an updated global mangrove baseline, with an accuracy in excess of 90%.\\nThis new global baseline represents an improvement on existing global maps (e.g., Giri et al. [1]) for\\nmany regions across the world. This includes the successful mapping of mangroves for areas that were\\nfound to be absent in other existing products (e.g., Figure 7). The method made use of the existing\\nGiri et al. [1] and Spalding et al. [2]datasets to automatically generate classifier training samples that\\nwere subsequently visually checked. This approach produced a new mangrove extent yielding a total\\narea approximately equal to that of Giri et al. [1], while displaying significant regional variations. It\\nshould be noted that, due to the methodological differences in the generation of the GMW, Giri et al. [1]\\nand Spalding et al. [2]datasets, they cannot be used to infer indications of changes between their\\nrespective baseline years. The majority of mangrove area can be found in Asia, as identified by Giri\\net al. [1], with an approximately equal proportion distributed between Africa and Latin America and\\nthe Caribbean.\\nThis mangrove baseline was derived using publicly open imagery from the ALOS PALSAR and\\nLandsat sensors. These sensors are complimentary and were used in combination to achieve theRemote Sens. 2018,10, 1669 14 of 19\\nupdated baseline. The radar and optical imagery measure different properties of the forest and\\nwere used together to attain the baseline with high accuracy. The optical data is sensitive to the\\nbio-chemical (e.g., photosynthesis) properties of the forest and the radar is sensitive to the physical\\n(e.g., woody biomass) of the forest. In combination, these provide a more complete description of the\\nforest than from one dataset alone. The ALOS PALSAR data have the advantages of being cloud-free\\nand therefore each path is a consistent date rather than composited from a number of dates as with the\\nLandsat sensor data. This study also benefited from the availability of a number of additional global\\ndatasets, such as the water occurrence dataset [ 29] and shorelines [ 30,31], bathymetry [ 32] and the\\nSRTM elevation model.\\nThe study has produced a new baseline of global mangrove extent for 2010. The date of the\\nbaseline was driven by the availability of the ALOS PALSAR data, which was most complete for\\n2010. However, the availability of Landsat data in 2010 is poor with Landsat 5 TM data not available\\nglobally, with particular sparsity of data throughout Africa. The Landsat 7 ETM+ suffered with the\\nSLC-off failure (Figure 10). Given the importance of the Landsat sensor data to the classification of\\nmangroves, future studies would be recommended to prioritise the availability of suitability optical\\ndata (i.e., Landsat-8 and Sentinel-2). Additionally, the increased spatial resolution (10 m) of Sentinel-2\\nis expected to improve the mapping of fine features (e.g., riverine, aquaculture and fine coastal fringes)\\nand disturbed areas where the error in the GMW v2.0 baseline are highest.\\nFigure 10. Douala, Cameroon: ( A) the Landsat Composite; and ( B) the Landsat composite with\\nthe GMW v2.0 baseline overlaid in green, illustrating an area with poor Landsat coverage due to\\ncloud cover, lack of Landsat-5 data and influence of the Landsat-7 SLC-off artefact. The 2010 Landsat\\ncomposite generated for this study is visualised using the NIR, SWIR and Red wavelength bands.\\nThe updated baseline is able to suit the requirements and needs of policy and decision makers.\\nThese data are aimed to support a wide range of international initiatives and users, including wetland\\nmanagers, government bodies, civil society users and Ramsar Convention contracting parties.\\nAn up-to-date baseline is of critical importance for the inclusion of mangroves in these and future\\ninitiatives, such as REDD+. However, while a baseline is highly useful, the measurement of change in\\nmangrove extent using a consistent global methodology would be a very significant further advance\\nand direction for future work.\\n4.2. Forming a Monitoring System\\nThis Global Mangrove Watch map represents the extent and distribution for 2010, but is also a\\nbaseline from which a monitoring system can be built (Figure 11). Thomas et al. [22]demonstrated a\\nnovel \\u201cmap-to-image\\u201d method to update mangrove baselines using time-series radar imagery with aRemote Sens. 2018,10, 1669 15 of 19\\nhigh degree of accuracy. By focussing on the mapping of changes away from the baseline, the trend in\\nchange is more consistent than comparing independently classified baselines. The \\u201cmap-to-image\\u201d\\nmethod is also directly applicable at the global level and can be used to iteratively derive baselines\\nback in time using historical data and into the future with the continued acquisition of current\\nsensors and anticipated launch of future satellites. Being derived from, and therefore spatially\\nregistered to the ALOS PALSAR data, this new GMW v2.0 baseline constitutes an ideal basis for\\nsuch a monitoring system using the Japanese JERS-1 SAR (ca. 1996), ALOS PALSAR (2007\\u20132010)\\nand ALOS-2 PALSAR-2 (2015\\u2013present) imagery, enabling maps of mangrove extent to be generated\\nfor a number of epochs. Data availability is expected to continue and increase into the future with\\nanticipated data from ALOS-4 PALSAR-3, as well as other globally available and near-future datasets\\n(e.g., Sentinel-1, SAOCOM-1A/1B, NISAR and Tandem-L). The global mangrove baseline detailed\\nin this paper, in combination with the novel \\u201cmap-to-image\\u201d change detection technique outlined\\nin Thomas et al. [22], can therefore be used to used to form an operational global mangrove monitoring\\nsystem for driving policy and informing management decisions.\\nFigure 11. A flowchart of the proposed monitoring system which could be built on the 2010 GMW v2.0\\nbaseline using the methodology of Thomas et al. [22].\\n4.3. Cautions and Caveats\\nThe minimum size of mangrove region that is considered to be reliably identifiable within\\nthe ALOS PALSAR and Landsat sensor data are those than occupy multiple pixels and therefore\\na recommended minimum mapping unit of 1 ha (i.e., 8 pixels) for reliable mapping was used and\\nis advocated. Errors associated with the minimum feature size are particularly evident in areas of\\ndisturbance, such as around aquaculture ponds (e.g., Figure 12) as well as in riverine mangroves that\\nform narrow shoreline fringes.\\nThe Landsat image composites include artefacts (e.g., Figure 10) as a result of persistent cloud\\ncover and the Landsat-7 SLC-off error. This has particularly effected areas in West Africa (e.g., Niger\\nDelta and Cameroon) where cloud cover is frequent and Landsat-5 data were not available for 2010.\\nFuture work should focus on determining an optimal year for the production of an optical image\\ncomposite. For instance, data quality and availability is likely to be greater in the years after Landsat-8\\nwas launched (2013). Similarly, the availability of Sentinel-2 imagery (particularly since 2017 with\\nthe launch of Sentinel-2B) is considered a significant opportunity for further improvements, with a\\nresolution of 10 m aiding the mapping of smaller fringing and fragmented mangroves and the increased\\ntemporal resolution improves the quality of cloud-free composites.\\nThere are also some areas where mangroves are known to have been omitted in this version (v2.0)\\nof the GMW dataset, due to satellite data unavailability, including: Andaman and Nicobar Islands\\n(India), Bermuda (UK), Europa Island (France), Fiji, east of Anti-meridian, Guam and Saipan (USA),\\nKiribati, Maldives, Peru (south of latitude S4) and Wallis and Futuna Islands (France). While these\\nare not significant in terms of mangrove extent globally, which is the focus of this paper, they will be\\nincluded in the release of future GMW datasets.Remote Sens. 2018,10, 1669 16 of 19\\nVersion September 8, 2018 submitted to Remote Sens. 16 of 19\\nFigure 12. A drone photograph looking over part of the Xu\\u00e2n Th/uni1EE7y National Park, on the Red\\nRiver Delta, Vietnam (March 2018). The photograph illustrates an area of aquaculture with highly\\nfragmented mangroves.\\nthe launch of Sentinel-2B) is considered a significant opportunity for further improvements, with 412\\na resolution of 10 m aiding the mapping of smaller fringing features and the increase temporal 413\\nresolution aiding the generation of cloud free composites. 414\\nThere are also some areas where mangroves are known to have been omitted in this version 415\\n(v2.0) of the GMW dataset, due to satellite data unavailability, including: Andaman and Nicobar 416\\nIslands (India), Bermuda (U.K.), Europa Island (France), Fiji, east of Anti-meridian, Guam and Saipan 417\\n(U.S.A.), Kiribati, Maldives, Peru (south of latitude S4) and Wallis and Futuna Islands (France). While 418\\nthese are not significant in terms of mangrove extent globally, which is the focus of this paper, they 419\\nwill be included in the release of future GMW datasets. 420\\n5. Conclusions 421\\nThis study is the first to establish a global baseline map of mangrove extent from Earth 422\\nObservation data, using a globally consistent methodology that is automated and reproducible. To 423\\nproduce the baseline a series of steps were undertaken: a) classification of coastal water; b) definition 424\\nof mangrove habitat regions; c) classification of mangrove areas using the ALOS PALSAR data; d) 425\\nrefinement of the mangrove extent map using a classification of a Landsat composite and e) finally a 426\\nmanual quality assurance process was undertaken where edits where applied to improve the overall 427\\nquality of the mangrove extent map. The new global mangrove map represents an improvement on 428\\nexisting products and provides a basis for assessing change over all mangrove regions with a precision 429\\nof approximately 1 ha. 430\\nThe new global mangrove map demonstrated a high degree of accuracy with a 99 % likelihood 431\\nthat the confidence interval for the overall mangrove accuracy was between 93.6\\u201394.5 %. The baseline 432\\nhas mapped 137,600 km2of mangroves with 38.7 % found in Asia, 20.3 % in Latin America and the 433\\nCaribbean, 20 % in Africa, 11.9 % in Oceania, 8.4 % in North America and 0.7 % in the European 434\\nOverseas Territories. This new globally consistent baseline can form the basis of an operational 435\\nmangrove monitoring system using the JAXA JERS-1 SAR, ALOS PALSAR and ALOS-2 PALSAR-2 436\\nto assess global mangrove change from 1996 to present, providing a valuable tool for policy makers 437\\nand land managers. 438\\nFigure 12. A drone photograph looking over part of the Xu\\u00e2n Th/uni1EE7y National Park, on the Red\\nRiver Delta, Vietnam (March 2018). The photograph illustrates an area of aquaculture with highly\\nfragmented mangroves.\\n5. Conclusions\\nThis study is the first to establish a global baseline map of mangrove extent from Earth Observation\\ndata, using a globally consistent methodology that is automated and reproducible. To produce the\\nbaseline, the following steps were undertaken: (a) classification of coastal water; (b) definition of\\nmangrove habitat regions; (c) classification of mangrove areas using the ALOS PALSAR data; (d)\\nrefinement of the mangrove extent map using a classification of a Landsat composite; and (e) a manual\\nquality assurance process where edits were applied to improve the overall quality of the mangrove\\nextent map. The new global mangrove map represents an improvement on existing products and\\nprovides a basis for assessing change over all mangrove regions with a precision of approximately 1 ha.\\nThe new global mangrove map demonstrated a high degree of accuracy with a 99% likelihood that\\nthe confidence interval for the overall mangrove accuracy was 93.6\\u201394.5%. The baseline has mapped\\n137,600 km2of mangrove with 38.7% found in Asia, 20.3% in Latin America and the Caribbean, 20%\\nin Africa, 11.9% in Oceania, 8.4% in North America and 0.7% in the European Overseas Territories.\\nThis new globally consistent baseline can form the basis of an operational mangrove monitoring system\\nusing the JAXA JERS-1 SAR, ALOS PALSAR and ALOS-2 PALSAR-2 to assess global mangrove change\\nfrom 1996 to present, providing a valuable tool for policy makers and land managers.Remote Sens. 2018,10, 1669 17 of 19\\nAuthor Contributions: Conceptualisation, A.R., R.M.L., L.-M.R., M.S. and C.M.F.; Data curation, A.R., R.M.L.,\\nL.H., T.I. and M.S.; Funding acquisition, P.B. and L.H.; Methodology, P.B., A.R., R.M.L., N.T. and A.H.; Project\\nadministration, A.R.; Resources, L.H., T.I., M.S. and C.M.F.; Software, P.B. and N.T.; Validation, P.B., A.R., R.M.L.\\nand A.H.; Writing\\u2014Original draft, P.B. and A.R.; and Writing\\u2014Review and editing, P.B., A.R., R.M.L., L.-M.R.,\\nL.H., N.T. and A.H.\\nFunding: Funding was provided for this study through the \\u201cMangrove Capital Africa\\u201d project funded by DOB\\nEcology and the RCUK NERC funded project \\u201cMOnitoring Mangrove ExteNT & Services (MOMENTS): What is\\ncontrolling Tipping Points?\\u201d as part of the Newton Fund (NE/P014127/1).\\nAcknowledgments: This project was undertaken in part within the framework of the JAXA Kyoto & Carbon\\nInitiative. JAXA and RESTEC are thanked for the provision of the SAR datasets used within this study.\\nSuperComputing Wales (SCW) are also thanked for supporting the project through the provision of the High\\nPerformance Computing (HPC) facility on which all the data were analysed.\\nConflicts of Interest: The authors declare no conflict of interest.\\nReferences\\n1. Giri, C.; Ochieng, E.; Tieszen, L.L.; Zhu, Z.; Singh, A.; Loveland, T.; Masek, J.; Duke, N. Status and distribution\\nof mangrove forests of the world using earth observation satellite data. Glob. Ecol. Biogeogr. 2011,20, 154\\u2013159.\\n[CrossRef]\\n2. Spalding, M.; Kainuma, M.; Collins, L. World Atlas of Mangroves (Version 3) ; Routledge: London, UK, 2010.\\n3. Spalding, M.; Blasco, F.; Field, C. World Atlas of Mangroves ; The International Society for Mangrove\\nEcosystems: Okinawa, Japan, 1997.\\n4. FAO. Loss of Mangroves Alarming ; Food and Agriculture Organization of the United Nations: Rome, Italy, 2008.\\n5. Roma \\u02dcnach, S.S.; DeAngelis, D.L.; Koh, H.L.; Li, Y.; Teh, S.Y.; Raja Barizan, R.S.; Zhai, L. Conservation and\\nrestoration of mangroves: Global status, perspectives, and prognosis. Ocean Coast. Manag. 2018,154, 72\\u201382.\\n[CrossRef]\\n6. Thomas, N.; Lucas, R.; Bunting, P.; Hardy, A.; Rosenqvist, A.; Simard, M. Distribution and drivers of global\\nmangrove forest change, 1996\\u20132010. PLoS ONE 2017,12, e0179302. [CrossRef] [PubMed]\\n7. Malik, A.; Fensholt, R.; Mertz, O. Mangrove exploitation effects on biodiversity and ecosystem services.\\nBiodivers. Conserv. 2015,24, 3543\\u20133557. [CrossRef]\\n8. Donato, D.C.; Kauffman, J.B.; Murdiyarso, D.; Kurnianto, S.; Stidham, M.; Kanninen, M. Mangroves among\\nthe most carbon-rich forests in the tropics. Nat. Geosci. 2011,4, 293\\u2013297. [CrossRef]\\n9. Swamy, L.; Drazen, E.; Johnson, W.R.; Bukoski, J.J. The future of tropical forests under the United Nations\\nSustainable Development Goals. J. Sustain. For. 2017,37, 221\\u2013256. [CrossRef]\\n10. FAO. Status and Trends in Mangrove Area Extent Worldwide, by M.L. Wilkie and S. Fortuna ; FAO: Rome, Italy,\\n2003.\\n11. FAO. The World\\u2019s Mangroves 1980\\u20132005 ; Food and Agriculture Organization of the United Nations: Rome,\\nItaly, 2007.\\n12. Lucas, R.M.; Rebelo, L.M.; Rosenqvist, A.; Itoh, T.; Shimada, M.; Simard, M.; Souza-Filho, P.W.; Thomas, N.;\\nTrettin, C.; Accad, A.; et al. Contribution of L-band SAR to systematic global mangrove monitoring.\\nMar. Freshw. Res. 2014,65, 589\\u2013603. [CrossRef]\\n13. Hamilton, S.E.; Casey, D. Creation of a high spatio-temporal resolution global database of continuous\\nmangrove forest cover for the 21st century (CGMFC-21). Glob. Ecol. Biogeogr. 2016,25, 729\\u2013738. [CrossRef]\\n14. Hansen, M.C.; Potapov, P.V.; Moore, R.; Hancher, M.; Turubanova, S.A.; Tyukavina, A.; Thau, D.;\\nStehman, S.V.; Goetz, S.J.; Loveland, T.R.; et al. High-Resolution Global Maps of 21st-Century Forest\\nCover Change. Science 2013,342, 850\\u2013853. [CrossRef] [PubMed]\\n15. Rakotomavo, A.; Fromard, F. Dynamics of mangrove forests in the Mangoky River delta, Madagascar,\\nunder the influence of natural and human factors. For. Ecol. Manag. 2010,259, 1161\\u20131169. [CrossRef]\\n16. Tong, P.H.S.; Auda, Y.; Populus, J.; Aizpuru, M.; Habshi, A.A.; Blasco, F. Assessment from space of\\nmangroves evolution in the Mekong Delta, in relation to extensive shrimp farming. Int. J. Remote Sens. 2004,\\n25, 4795\\u20134812. [CrossRef]\\n17. Ferreira, M.A.; Andrade, F.; Bandeira, S.O.; Cardoso, P.; Mendes, R.N.; Paula, J. Analysis of cover change\\n(1995\\u20132005) of Tanzania/Mozambique trans-boundary mangroves using Landsat imagery. Aquat. Conserv.\\n2009,19, S38\\u2013S45. [CrossRef]Remote Sens. 2018,10, 1669 18 of 19\\n18. Long, J.B.; Giri, C. Mapping the Philippines\\u2019 Mangrove Forests Using Landsat Imagery. Sensors 2011,\\n11, 2972\\u20132981. [CrossRef] [PubMed]\\n19. Kirui, K.B.; Kairo, J.G.; Bosire, J.; Viergever, K.M.; Rudra, S.; Huxham, M.; Briers, R.A. Mapping of mangrove\\nforest land cover change along the Kenya coastline using Landsat imagery. Ocean Coast. Manag. 2013,\\n83, 19\\u201324. [CrossRef]\\n20. CONABIO. Distribuci\\u00f3n de los Manglares en M\\u00e9xico en 2015\\u2019, Escala: 1:50000. Edici\\u00f3N: 1 ; Comisi\\u00f3n Nacional\\npara el Conocimiento y Uso de la Biodiversidad. Sistema de Monitoreo de los Manglares de M\\u00e9xico (SMMM):\\nCiudad de M\\u00e9xico, Mexico, 2016.\\n21. Nascimento, W.R., Jr.; Souza Filho, P.W.M.; Proisy, C.; Lucas, R.M.; Rosenqvist, A. Mapping changes in\\nthe largest continuous Amazonian mangrove belt using object-based classification of multisensor satellite\\nimagery. Estuar. Coast. Shelf Sci. 2013,117, 83\\u201393. [CrossRef]\\n22. Thomas, N.; Bunting, P.; Hardy, A.; Lucas, R.; Rosenqvist, A.; Fatoyinbo, T. Mapping mangrove baseline and\\ntime-series change extent: A global monitoring approach. Remote Sens. 2018,10, 1466. [CrossRef]\\n23. Heumann, B.W. An Object-Based Classification of Mangroves Using a Hybrid Decision Tree\\u2014Support\\nVector Machine Approach. Remote Sens. 2011,3, 2440\\u20132460. [CrossRef]\\n24. Kovacs, J.M.; de Santiago, F.F.; Bastien, J.; Lafrance, P. An Assessment of Mangroves in Guinea, West Africa,\\nUsing a Field and Remote Sensing Based Approach. Wetlands 2010,30, 773\\u2013782. [CrossRef]\\n25. Bunting, P.; Clewley, D.; Lucas, R.M.; Gillingham, S. The Remote Sensing and GIS Software Library\\n(RSGISLib). Comput. Geosci. 2014,62, 216\\u2013226. [CrossRef]\\n26. Bunting, P.; Gillingham, S. The KEA image file format. Comput. Geosci. 2013,57, 54\\u201358. [CrossRef]\\n27. Pedregosa, F.; Varoquaux, G.; Gramfort, A.; Michel, V.; Thirion, B.; Grisel, O.; Blondel, M.; Prettenhofer, P.;\\nWeiss, R.; Dubourg, V.; et al. Scikit-learn: Machine Learning in Python. J. Mach. Learn. Res. 2011,\\n12, 2825\\u20132830.\\n28. Clewley, D.; Bunting, P.; Shepherd, J.; Gillingham, S.; Flood, N.; Dymond, J.; Lucas, R.; Armston, J.;\\nMoghaddam, M. A Python-Based Open Source System for Geographic Object-Based Image Analysis\\n(GEOBIA) Utilizing Raster Attribute Tables. Remote Sens. 2014,6, 6111\\u20136135. [CrossRef]\\n29. Cottam, A.; Gorelick, N.; Belward, A.S.; Pekel, J.F. High-resolution mapping of global surface water and its\\nlong-term changes. Nature 2016,540, 1\\u201319.\\n30. Soluri, E.A.; Woodson, V.A. World Vector Shoreline. Int. Hydrogr. Rev. 1990,1, 27\\u201335.\\n31. Wessel, P.; Smith, W.H.F. A global, self-consistent, hierarchical, high-resolution shoreline database.\\nJ. Geophys. Res. 1996,101, 8741\\u20138743. [CrossRef]\\n32. Weatherall, P.; Marks, K.M.; Jakobsson, M.; Schmitt, T.; Tani, S.; Arndt, J.E.; Rovere, M.; Chayes, D.; Ferrini, V.;\\nWigley, R. A new digital bathymetric model of the world\\u2019s oceans. Earth Space Sci. 2015,2, 331\\u2013345.\\n[CrossRef]\\n33. Shimada, M.; Itoh, T.; Motohka, T.; Watanabe, M.; Shiraishi, T.; Thapa, R.; Lucas, R. New global\\nforest/non-forest maps from ALOS PALSAR data (2007\\u20132010). Remote Sens. Environ. 2014,155, 13\\u201331.\\n[CrossRef]\\n34. Bunting, P.; Clewley, D. Atmospheric and Radiometric Correction of Satellite Imagery (ARCSI). 2018.\\nAvailable online: https://arcsi.remotesensing.info (accessed on 21 October 2018).\\n35. Chavez, P.S., Jr. An improved dark-object subtraction technique for atmospheric scattering correction of\\nmultispectral data. Remote Sens. Environ. 1988,24, 459\\u2013479. [CrossRef]\\n36. Vermote, E.; Tanre, D.; Deuze, J.; Herman, M.; Morcrette, J. Second Simulation of the Satellite Signal in the\\nSolar Spectrum, 6S: An overview. IEEE Trans. Geosci. Remote Sens. 1997,35, 675\\u2013686. [CrossRef]\\n37. Shepherd, J.D.; Dymond, J.R. Correcting satellite imagery for the variance of reflectance and illumination\\nwith topography. Int. J. Remote Sens. 2003,24, 3503\\u20133514. [CrossRef]\\n38. Zhu, Z.; Woodcock, C.E. Object-based cloud and cloud shadow detection in Landsat imagery.\\nRemote Sens. Environ. 2012,118, 83\\u201394. [CrossRef]\\n39. Zhu, Z.; Wang, S.; Woodcock, C.E. Improvement and expansion of the Fmask algorithm: cloud, cloud\\nshadow, and snow detection for Landsats 4\\u20137, 8, and Sentinel 2 images. Remote Sens. Environ. 2015,\\n159, 269\\u2013277. [CrossRef]\\n40. Holben, B.N. Characteristics of maximum-value composite images from temporal AVHRR data. Int. J.\\nRemote Sens. 1986,7, 1417\\u20131434. [CrossRef]Remote Sens. 2018,10, 1669 19 of 19\\n41. Ramoino, F.; Tutunaru, F.; Pera, F.; Arino, O. Ten-Meter Sentinel-2A Cloud-Free Composite\\u2014Southern Africa\\n2016. Remote Sens. 2017,9, 652. [CrossRef]\\n42. Bunting, P.; Lucas, R.; Jones, K.; Bean, A. Characterisation and mapping of forest communities by clustering\\nindividual tree crowns. Remote Sens. Environ. 2010,114, 2536\\u20132547. [CrossRef]\\n43. Wilson, E.B. Probable inference, the law of succession, and statistical inference. J. Am. Stat. Assoc. 1927,\\n22, 209\\u2013212. [CrossRef]\\nc\\r2018 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access\\narticle distributed under the terms and conditions of the Creative Commons Attribution\\n(CC BY) license (http://creativecommons.org/licenses/by/4.0/).\",\n          \"remote sensing  \\nArticle\\nA New Vegetation Index to Detect Periodically\\nSubmerged Mangrove Forest Using Single-Tide\\nSentinel-2 Imagery\\nMingming Jia1,2\\n, Zongming Wang1,*, Chao Wang2\\n, Dehua Mao1\\nand Yuanzhi Zhang3,4\\n1Key Laboratory of Wetland Ecology and Environment, Northeast Institute of Geography and Agroecology,\\nChinese Academy of Sciences, No. 4888, Shengbei Street, Changchun 130102, China\\n2State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan\\nUniversity, No.129 Luoyu Road, Wuhan 430079, China\\n3Center for Housing Innovations, Chinese University of Hong Kong, Shatin, New Territories, Hong Kong\\n4Key Lab of Lunar Science and Deep-exploration, National Astronomical Observatories, Chinese Academy of\\nSciences, Beijing 100101, China\\n*Correspondence: zongmingwang@iga.ac.cn\\nReceived: 4 July 2019; Accepted: 27 August 2019; Published: 29 August 2019\\n/gid00030/gid00035/gid00032/gid00030/gid00038/gid00001/gid00033/gid00042/gid00045 /gid00001\\n/gid00048/gid00043/gid00031/gid00028/gid00047/gid00032/gid00046\\nAbstract: Mangrove forests are tropical trees and shrubs that grow in sheltered intertidal zones.\\nAccurate mapping of mangrove forests is a great challenge for remote sensing because mangroves are\\nperiodically submerged by tidal \\ufb02oods. Traditionally, multi-tides images were needed to remove the\\nin\\ufb02uence of water; however, such images are often unavailable due to rainy climates and uncertain\\nlocal tidal conditions. Therefore, extracting mangrove forests from a single-tide imagery is of great\\nimportance. In this study, re\\ufb02ectance of red-edge bands in Sentinel-2 imagery were utilized to\\nestablish a new vegetation index that is sensitive to submerged mangrove forests. Speci\\ufb01cally, red\\nand short-wave near infrared bands were used to build a linear baseline; the average re\\ufb02ectance\\nvalue of four red-edge bands above the baseline is de\\ufb01ned as the Mangrove Forest Index (MFI).\\nTo evaluate MFI, capabilities of detecting mangrove forests were quantitatively assessed between\\nMFI and four widely used vegetation indices (VIs). Additionally, the practical roles of MFI were\\nvalidated by applying it to three mangrove forest sites globally. Results showed that: (1) theoretically,\\nJensen\\u2013Shannon divergence demonstrated that a submerged mangrove forest and water pixels have\\nthe largest distance in MFI compared to other VIs. In addition, the boxplot showed that all submerged\\nmangrove forests could be separated from the water background in the MFI image. Furthermore, in\\nthe MFI image, to separate mangrove forests and water, the threshold is a constant that is equal to\\nzero. (2) Practically, after applying the MFI to three global sites, 99\\u2013102% of submerged mangrove\\nforests were successfully extracted by MFI. Although there are still some uncertainties and limitations,\\nthe MFI o \\u000bers great bene\\ufb01ts in accurately mapping mangrove forests as well as other coastal and\\naquatic vegetation worldwide.\\nKeywords: Sentinel-2 MultiSpectral Instrument (MSI); red-edge band; aquatic vegetation; tidal\\ncondition; vegetation index; coastal vegetation\\n1. Introduction\\nMangrove forest are highly productive ecosystems with signi\\ufb01cant ecological and socio- economic\\nimportance in the world [ 1,2]. However, over the past century, these forests have declined at an\\nalarming rate that is more rapid than that of inland tropical forests [ 3]. Therefore, there is an emerging\\ndemand for conservation and restoration e \\u000borts in mangrove forests. Obtaining accurate information\\nRemote Sens. 2019 ,11, 2043; doi:10.3390 /rs11172043 www.mdpi.com /journal /remotesensingRemote Sens. 2019 ,11, 2043 2 of 17\\nregarding the current and past acreage and condition of mangrove forests is essential for e \\u000ecient\\nmanagement of these ecosystems and for policy- and decision-making processes [4,5].\\nLocated in intertidal zones, mangrove forests are often inaccessible for traditional \\ufb01eld surveys.\\nFor decades, remote sensing has been widely used to monitor the distribution of mangrove forests, yet\\naccurate and timely interpretation of the relatively small patches has been rare, due to the lack of full\\nconsideration of tidal conditions [ 6\\u20139]. Mangrove forests located near the shoreline are periodically\\nsubmerged by tides, especially in regions with high tide \\ufb02uctuations and lower mangrove shrubs [ 9,10].\\nIdeally, it is better to use images acquired during low tides; however, such data are di \\u000ecult to obtain,\\ndue to uncertainties of local instantaneous tidal conditions during predetermined times that satellites\\npass over [ 11,12]. For a long time, numerous studies have pointed out that tides may seriously\\nin\\ufb02uence remote sensing results of mangrove forests, yet, solutions were not reported until the past\\ntwo years [ 10,13,14]. However, all these studies used multi-tides (multi-date) images; therefore, we\\nhave one concern: if multi-tides images are not available due to rainy climates and uncertain local tide\\nconditions, how could we accurately map mangrove forests by a single-date image?\\nOver the last two decades, remote sensing of submerged and emerged aquatic vegetation has\\nbeen widely studied [ 15,16]. Hyperspectral image with numerous narrow and contiguous bands is\\nreliable for studying aquatic vegetation and is able to detect the biophysical properties of vegetation\\ne\\u000eciently [ 16\\u201319]. However, there is no freely available satellite hyperspectral data in recent years, and\\nairborne applications are exorbitantly expensive and only cover a very small spatial extent. Landsat\\nimages with moderate spatial resolution of 30\\u201360 m have been widely used for mapping aquatic\\nvegetation [ 20\\u201324]. Yet, Landsat only has one band in the spectral region of near infrared (760\\u2013900 nm),\\nwhich may become less sensitive as water depth increases [ 25]. The MODIS (Moderate Resolution\\nImaging Spectroradiometer) and AVHRR (Advanced Very High Resolution Radiometer) are publicly\\navailable with high spectral resolution but coarse spatial resolution (250\\u20131100 m, respectively), making\\nthem unsuitable for mangrove detection [ 9]. In contrast, the Sentinel-2 MultiSpectral Instrument\\n(MSI) sensor has a 10\\u201320 m spatial resolution and \\ufb01ve bands in near infrared region, which provides\\nopportunities to conduct quick, robust, and e \\u000ecient monitoring of submerged mangrove forests.\\nFor years, numerous methods were utilized to map mangrove forests as well as other aquatic\\nvegetation from remote sensing imagery, ranging from pixel to object-oriented approach, and manual\\nto unsupervised methods [ 9,14,26\\u201328]. Recently, machine-learning algorithms such as random\\nforest, neural network, and support vector machine provide promising accuracy in mangrove forests\\nextraction [ 10,13,29]. As it is hard to locate representative training samples due to uncertain tidal\\nconditions, it is relatively hard to apply these methods to extract submerged mangrove forests from\\na single-date image. Vegetation indices (VIs), which are mathematically determined based on the\\nspectral characteristics of vegetation, have been proven e \\u000ecient in monitoring vegetation from\\nspace [ 30]. The Normalized Di \\u000berence Vegetation Index (NDVI) is the most commonly used index\\nin global vegetation studies (e.g., [ 30,31]). The Land Surface Water Index (LSWI) and the Modi\\ufb01ed\\nNormalized Di \\u000berence Water Index (MNDWI) were proposed and widely used for mapping surface\\nwater [ 32\\u201334]. Given that these indices are established based on di \\u000berences between two bands,\\nthey are insensitive to small variations of the re\\ufb02ectance of submerged mangrove forests and water\\nbackground [ 14]. Furthermore, it is hard to decide thresholds that distinguish submerged mangroves\\nand water. With more bands, several VIs were built based on a baseline theory, such as Maximum\\nChlorophyll Index (MCI; [ 35]), the Floating Algae Index (FAI; [ 36]), and the Floating Vegetation Index\\n(FVI; [ 17]). However, these indices were de\\ufb01ned to extract \\ufb02oating vegetation (above water surface)\\nfrom water, not submerged vegetation. Meanwhile, bands used to build MCI and FVI did not exist in\\nSentinel MSI image.\\nThus, the objective of this study is to develop a new vegetation index, called the Mangrove Forest\\nIndex (MFI), which is capable to map the distribution of mangroves based on a single date MSI image.\\nThen, we will compare MFI with other widely used VIs to validate MFI\\u2019s capabilities in detecting\\nsubmerged mangrove forests from water background. Additionally, MFI will be applied to three sitesRemote Sens. 2019 ,11, 2043 3 of 17\\nof typical mangrove forests worldwide; the practical roles of mapping mangrove forests during local\\nhigh-tide conditions will also be discussed.\\n2. Materials and Methods\\n2.1. Sentinel-2 Imagery\\nSentinel-2, a European Space Agency (ESA) land-monitoring mission, has two matching satellites\\nthat provide high-resolution optical imagery. Sentinel-2A and Sentinel-2B carry the MultiSpectral\\nInstrument (MSI) and were successfully launched in June 2015 and March 2017 respectively and\\nprovide important means to augment earth observation capabilities [ 37]. These satellites revisit the\\nsame location every 2 to 5 days. The MSI sensor o \\u000bers 13 spectral bands, with four bands at 10 m, six\\nbands at 20 m, and three bands at a 60 m spatial resolution (Table 1) and o \\u000bers a wide range of earth\\nobservation applications [38].\\nIn this study, Sentinel-2 MSI images were downloaded from European Space Agency Sentinels\\nScienti\\ufb01c Data Hub; the images were preprocessed with geometric and radiometric corrections at\\nsub-pixel accuracy. Then, atmospheric correction (converting top-of-atmosphere re\\ufb02ectance into\\ntop-of-canopy re\\ufb02ectance) was performed by the tool of SEN2COR (version 2.05.05), which was\\navailable in the Sentinel Application Platform (SNAP) toolbox [ 39,40]. In order to standardize di \\u000berent\\nspatial resolutions of bands in MSI images, we excluded bands with a spatial resolution of 60 m (Band\\n1, Band 9, and Band 10). After atmospheric correction, all remaining bands were resampled to a pixel\\nsize of 20 m\\u000220 m.\\nTable 1. General characteristics of the Sentinal-2 MultiSpectral Instrument (MSI) sensor.\\nMSI Band Band NameWavelength\\n(Central, nm)Spectral Width\\n(nm)Spatial Resolution\\n(m)\\nB1 Aerosols 443 20 60\\nB2 Blue 490 65 10\\nB3 Green 560 35 10\\nB4 Red 665 30 10\\nB5 Vegetation red-edge 705 15 20\\nB6 Vegetation red-edge 740 15 20\\nB7 Vegetation red-edge 783 20 20\\nB8 Near infrared 842 115 10\\nB8A Vegetation red-edge 865 20 20\\nB9 Water-vapor 945 20 60\\nB10 Cirrus 1380 30 60\\nB11Shortwave-infrared\\nre\\ufb02ectance (SWIR)11610 90 20\\nB12 SWIR2 2190 180 20\\n2.2. Study Area\\nThe study area, Zhenzhu Harbor (21\\u000e280\\u201321\\u000e420N and 108\\u000e000\\u2013108\\u000e200N), is located in Guangxi\\nProvince, China, in the southwest portion of mainland China and the north region of Tonkin Gulf\\n(Figure 1). In Zhenzhu Harbor, mangrove forests are mainly composed of four communities: Comm. A.\\nmarina, Comm. A. corniculatum, Comm. A. marina\\u2013A. corniculatum, and Comm. K. candel\\u2013A. corniculatum .\\nThe tides in the coast of Zhenzhu Harbor are diurnal, with an average tidal range of 2.24 m, and\\nmangrove forests here are primarily younger shrubs with an average height of less than 3 m [ 7].\\nTherefore, the Zhenzhu Harbor is a typical area for the study of submerged mangrove forests, due to a\\nlarge area of pioneer mangrove trees and shrubs that would be entirely submerged during high tides\\n(Figure 1A,B). Information of MSI images we selected are shown in Table 2.Remote Sens. 2019 ,11, 2043 4 of 17\\nAdditionally, a \\ufb01eld survey of Zhenzhu Harbor was conducted during April 2017, in which 408\\nground truth samples were collected including samples of mangrove forest, open water, and other\\nland cover.\\nFigure 1. Snapshots of low- and high-tide Sentinel MSI images of study area (( A) during local low\\ntide all mangrove forests were emerged; ( B) during local high tide some of the mangrove forests were\\nsubmerged).\\nTable 2. Description of satellite data, including the path, row, date, time of acquisition, and tide level of\\nthe nearest tide station (Fangcheng Harbor Station, 108\\u000e140E, 21\\u000e280N).\\nSensor Path Row Date Time (hh:mm) Tide Height (m)\\nMSI 205 118 2017-12-17 11:23 \\u00000.9\\nMSI 205 118 2017-09-28 16:37 1.8\\n2.3. Build a Reference Map\\nGround surveys were conducted along the coasts of Zhenzhu Harbor in November 2017. The\\nlocation of each sampling point was measured using a global positioning system (GPS), with an error\\nless than 1 m. The observations collected in the surveys contained 85 mangrove points and 81 water\\npoints. A vector \\ufb01le of ground survey points with the attributes of location (longitude and latitude),\\nland cover types, and photos was created with ArcGIS.\\nThe spectral curves of water, submerged mangrove forests, and emerged mangrove forests were\\nextracted from images. The work\\ufb02ow of discriminating these classes is shown in Figure 2. A reference\\nmap was built based on object-oriented methods and visual interpretation.\\nThe description of the object-oriented method can be found in Harayama and Jaquet [ 41]. The\\neCognition Developer 9.0, an image analysis program, was used to conduct object-oriented classi\\ufb01cation.\\nVisual interpretation was performed to classify objects as either mangrove forests or water. To facilitateRemote Sens. 2019 ,11, 2043 5 of 17\\nvisual interpretation, a false color composite of MSI Bands 11 (centered 1610 nm), Band 8 (centered\\n842 nm), and Band 4 (centered 665 nm) was generated. This band combination that was deemed the\\nbest for detecting mangroves which appears dark green color [ 42]. Furthermore, in order to conduct the\\nadjustment in a robust manner, visual interpretation was performed by an experienced remote sensing\\nexpert who was familiar with this area. First, we identi\\ufb01ed mangrove forest and surrounding water\\nfrom the low-tide MSI image. Subsequently, a confusion matrix was generated using the independent\\nground-truth samples described in Section 2.2. With this matrix, we achieved an overall classi\\ufb01cation\\naccuracy of 97% with a Kappa coe \\u000ecient of 0.92, which indicated excellent agreements between our\\nmapping results and ground-truth data. Therefore, mangrove forests identi\\ufb01ed with this method\\nwere assumed to cover entire area of local mangrove forests. Second, using the same techniques as\\nabove, mangrove forests were identi\\ufb01ed from the high-tide MSI image. Finally, the extent of the\\nsubmerged mangrove was determined by subtracting the high-tide from the low-tide mangrove forest\\nmap. Figure 3 shows the distributions of emerged mangrove forests and submerged mangrove forests\\nin the high-tidal MSI image.\\nFigure 2. Work \\ufb02ow for identifying submerge mangrove forests.Remote Sens. 2019 ,11, 2043 6 of 17\\nFigure 3. Distribution of emerged and submerged mangrove forests in high-tide MSI image.\\n2.4. Theories\\nFigure 4 shows the \\ufb01eld measurements of spectral curves of the water, emerged vegetation,\\nand submerged vegetation, generated by Chen et al. (2018; Figure 4A) and Visser et al. (2015;\\nFigure 4B) [ 15,25]. As normal green plants, vegetation above the water surface showed high re\\ufb02ectance\\nin the spectral region of 770\\u2013890 nm. Waterbody is characterized by low re\\ufb02ectance in near infrared at\\n700 nm while emerged mangrove has a relatively high re\\ufb02ectance, which make them separable from\\neach other. However, when mangroves are submerged under water, the re\\ufb02ectance is largely reduced,\\ntherefore, it is di \\u000ecult to distinguish submerged vegetation from waterbody [ 15,25,43]. As measured,\\nwhen submerged vegetation are 43\\u201351 cm below clear water, the NDVI value was close to zero, which\\nmeans no di \\u000berences were observed between the red band and NIR band [44].\\nHowever, by careful inspection of the spectral curves shown in Figure 4A,B, two re\\ufb02ectance\\npeaks ranging from approximately 690\\u2013740 nm and 810\\u2013830 nm were found, even for the curves of\\nvegetation located 40 cm below the water surface. These peaks result from the competing e \\u000bects\\nof the chlorophyll re\\ufb02ectance plateau and the absorption e \\u000bects of water located within submerged\\nvegetation and the surrounding water background. However, traditional multispectral satellite sensors\\ncould not capture these re\\ufb02ectance peaks. Fortunately, the MSI sensor has \\ufb01ve channels that cover\\nthese regions. Figure 5 shows the typical spectral curves of water (WB), emerged mangrove forest\\n(EMF), and submerged mangrove forest (SMF) that are observed on the MSI image. As shown in\\nFigure 5, the emerged and shallow submerged mangrove forest pixels demonstrated a strong re\\ufb02ection\\nin the region of 660\\u2013900 nm, the absorption valleys appeared in bands 4 (centered wavelength 665 nm)\\nand 12 (centered 2160 nm). For the submerged mangrove forest (b) curves, a small re\\ufb02ectance peak\\nappeared in the 660\\u2013900 nm region; the absorption valley also appeared in bands 4 (centered 665 nm)\\nand 12 (centered 2160 nm). The re\\ufb02ectance of the water pixels shows a continuous decreasing tendency\\nbeginning with band 4 (central wavelength 665 nm). Therefore, comparing submerged curves to water\\ncurves, the higher re\\ufb02ectance in bands 5 (centered 705 nm), 6 (centered 740 nm), 7 (centered 783 nm),\\n8 (centered 842 nm), and 8A (centered 865 nm) could be used to distinguish submerged mangrove\\nforests from the water background.Remote Sens. 2019 ,11, 2043 7 of 17\\nFigure 4. The spectral curves of water, emerged, and submerged vegetation, as well as the absorption\\ncoe\\u000ecients of water (cm\\u00001). ((A) \\ufb01eld-measurement [ 15]; (B) \\ufb01eld-measured of submerged vegetation\\u2019s\\nre\\ufb02ectance at 1.5, 16, and 40 cm below water surface [25]).\\nFigure 5. (A) Typical spectral curves of emerged (EMF), submerged mangrove forests (SMF) and water\\n(WB) in Sentinel-2A MSI image. ( B) EMF and SMF forests in Sentinel MSI image and \\ufb01eld photo. ( a)\\nRepresents shallow submerged mangrove forests (0\\u201330 cm), ( b) Represents deep submerged mangrove\\nforests (30\\u201360 cm).\\n2.5. Existing Vegetation Indices\\nPreviously, NDVI (Equation 1), LSWI (Equation 2), and MNDWI (Equation 3) and FAI (Equation\\n4) were used in detecting vegetation from water bodies [33,34,45].\\nNDVI =\\u001aNIR\\u0000\\u001aRed\\n\\u001aNIR+\\u001aRed(1)\\nLSWI =\\u001aNIR\\u0000\\u001aSWIR\\n\\u001aNIR+\\u001aSWIR(2)\\nMNDWI =\\u001aGreen\\u0000\\u001aSWIR\\n\\u001aGreen +\\u001aSWIR(3)\\nFAI=\\b\\u001a860\\u0000[\\u001a1240+(\\u001a660\\u0000\\u001a1240)\\u0002(1240\\u0000860)/(1240\\u0000660)]\\t(4)\\nwhere\\u001aGreen ,\\u001aRed,\\u001aNIR, and\\u001aSWIR are the re\\ufb02ectance of the green, red, NIR, and SWIR, respectively.\\nHowever, these indices are not suitable for discerning submerged vegetation from water bodies,\\nbecause there are no obvious re\\ufb02ectance di \\u000berences in bands green, red, and SWIR between submerged\\nvegetation and water bodies (Figures 4 and 5).Remote Sens. 2019 ,11, 2043 8 of 17\\n2.6. Formulation of MFI\\nFor this study, according to the analysis in Section 2.4, the absorption valleys in band 4 (centered\\n665 nm) and band 12 (centered 2190 nm) could be used to form a baseline (Figure 6). In order to\\nenhance the stability of di \\u000berences between submerged mangrove forests and the water background,\\nthe average value of re\\ufb02ectance of band 5 (centered 705 nm), band 6 (centered 740 nm), band 7 (centered\\n783 nm), and band 8A (centered 865 nm) above the baseline, is de\\ufb01ned as MFI. Band 8 was excluded\\nbecause Bands 7 (centered 783 nm) and 8A (centered 865 nm) covered most of its spectra, and its\\nspectral range overlaps with the water absorption region. The mathematical formulation is\\nMFI =h\\n(\\u001a\\u00151\\u0000\\u001aB\\u00151)+(\\u001a\\u00152\\u0000\\u001aB\\u00152)+(\\u001a\\u00153\\u0000\\u001aB\\u00153)+(\\u001a\\u00154\\u0000\\u001aB\\u00154\\u0011\\n]/4 (5)\\n\\u001aB\\u0015i=\\u001a2190+(\\u001a665\\u0000\\u001a2190)\\u0002(2190\\u0000\\u0015i)/(2190\\u0000665) (6)\\nwhere the \\u001a\\u0015is the re\\ufb02ectance of the band center of \\u0015, and iranged from 1 to 4; \\u00151,\\u00152,\\u00153,\\u00154represent\\nthe center wavelengths at 705, 740, 783 and 865 nm, respectively. \\u001aB\\u0015iis the baseline re\\ufb02ectance in\\n\\u0015i.\\u001a665and\\u001a2190are the re\\ufb02ectance of band 4 (centered at 665 nm) and 12 (centered at 2190 nm),\\nrespectively. Pixels with an MFI value above 0 are recognized as mangrove forests.\\nFigure 6. Baseline theory of establishing Mangrove Forest Index (MFI), including re\\ufb02ectance of\\nsubmerged mangrove forest and water.\\n2.7. Quantitative Comparison between MFI and Other VIs\\nIn this study, Jensen\\u2013Shannon divergence (JSD)\\u2014a measure of distance between a \\ufb01nite number\\nof distributions\\u2014was adopted to compare sensitivities of MFI and other VIs. The JSD ( D) quanti\\ufb01es\\nthe di \\u000berence between two or more probability distributions. In this study, it was used to compare\\nthe di \\u000berences between submerged mangrove forests and water pixels in di \\u000berent VI images. The\\nDvalue, which was calculated in MATLAB, is de\\ufb01ned as follows: let p(1)\\u0011(p(1)\\n1,p(1)\\n2,:::,p(1)\\nk)\\nand p(2)\\u0011\\u0012\\np(2)\\n1,p(2)\\n2,:::,p(2)\\nk\\u0013\\ndenote two probability distributions satisfying the usual constraints\\nPk\\ni=1p(j)\\ni=1and 0\\u0014p(j)\\ni\\u00141for all i=1,2,:::,k and j=1,2; and let \\u0019(1)and\\u0019(2)denote the weights\\nof the distributions p(1)and p(2), satisfying the constraints \\u0019(1)+\\u0019(2)=1and 0\\u0014\\u0019(j)\\u00141. Then theRemote Sens. 2019 ,11, 2043 9 of 17\\nJensen\\u2013Shannon divergence Dbetween the probability distributions p(1)and p(2)with weights \\u0019(1)\\nand\\u0019(2)is de\\ufb01ned by [46]:\\nDh\\np(1),p(2)i\\n\\u0011Hh\\n\\u0019(1)p(1)+\\u0019(2)p(2)i\\n\\u0000\\u0010\\n\\u0019(1)Hh\\np(1)i\\n+\\u0019(2)Hh\\np(2)i\\u0011\\n(7)\\nwhere\\nH[p]=\\u0000Xk\\ni=1pilog2pi (8)\\ndenotes the Shannon entropy of the probability distribution p\\u0011(p1,p2,:::pk).Dranging from 0\\u20131, 0\\nmeans no di \\u000berence between distributions, 1 means the distributions are completely di \\u000berent.\\n3. Results\\n3.1. Quantitative Comparison of MFI, FAI, NDVI, LSWI, and MNDWI\\nTo compare the ability to distinguish submerged mangrove forests from the water background,\\nthe VIs values of all submerged mangrove forests (in total 12,001 pixels extracted in Section 2.3), and\\n22,668 pixels of water in the high-tidal MSI image (acquired on 28 September 2017) were calculated.\\nAdditionally, to make the di \\u000berent VIs comparable, the MFI and FAI were calculated to 10 times of their\\noriginal values. The boxplots of submerged mangrove forests and water pixels are shown in Figure 7.\\nFigure 7. Boxplot of di \\u000berent index values over submerged mangrove forest pixels and water pixels\\n(MFI and Floating Algae Index (FAI) are 10 times their original value. SMF means submerged mangrove\\nforest, WB means Water Body. The horizontal axis represents di \\u000berent indices).\\nAs shown in Figure 7, all submerged mangrove forest pixels have higher MFI values than those of\\nthe water background, the minimum value of submerged mangrove forests is equal to the maximal\\nvalue of water. Most of the water pixels are confused with submerged mangrove forests in FAI, NDVI,\\nand NDWI image. According to our calculations, the Dvalues of MFI, FAI, NDVI, LSWI, and MNDWI\\nare 0.209, 0.077, 0.012, 0.003, and 0.121, respectively, which means pixels of submerged mangrove\\nforests and water are better separated in an MFI image than other VIs.Remote Sens. 2019 ,11, 2043 10 of 17\\n3.2. Evaluation of MFI at Di \\u000berent Mangrove Forests around the World\\nGlobally, three selected mangrove forest sites were chosen to demonstrate the practical utility\\nof our newly formed index (MFI) in distinguishing mangrove forests from water background. They\\nare (a) Zhenzhu Harbor, Guangxi, China, (b) Dalhousie Island, Sundarbans, India, (c) Baia do Arraial,\\nAmazon Coast, Brazil. Locations are shown in Figure 8.\\nFigure 8. Global study sites of mangrove forests. (Displayed imagery: R:G:B =Sentinel MSI Band 8A:\\n4:3. ( a) Zhenzhu Harbor, Guangxi, China; ( b) Dalhousie Island, Sundarbans, India; ( c) Baia do Arraial,\\nAmazon Coast, Brazil).\\nClassi\\ufb01cation accuracy assessment is essential for validating the performance of the MFI index.\\nIn this study, a table containing the overall accuracy, user\\u2019s accuracy, producer\\u2019s accuracy, and the\\nKappa coe \\u000ecient of each site were presented in Table 3. In Zhenzhu Harbor, the validation samples\\nwere collected from \\ufb01eld survey. In Dalhousie Island and Baja do Arraial, validation samples were\\nrandomly selected from Google Earth high-resolution images.Remote Sens. 2019 ,11, 2043 11 of 17\\nTable 3. Confusion matrix for worldwide study sites of mangrove forests, including overall accuracy,\\nproducer\\u2019s accuracy, user\\u2019s accuracy, and Kappa coe \\u000ecient.\\nZhenzhu Harbor\\nLand CoverClassi\\ufb01cation Results\\nMangrove Water Producer\\u2019s Accuracy\\nMangrove 82 3 96.4%\\nWater 2 79 97.5%\\nUser\\u2019s accuracy 97.6% 96.3% \\u2013\\nOverall accuracy 97.0% Kappa coe \\u000ecient 0.94\\nDalhousie Island Mangrove Water Producer\\u2019s accuracy\\nMangrove 52 1 98.1%\\nWater 2 39 95.1%\\nUser\\u2019s accuracy 96.2% 97.5% \\u2013\\nOverall accuracy 96.8% Kappa coe \\u000ecient 0.93\\nBaja do Arraial Mangrove Water Producer\\u2019s accuracy\\nMangrove 30 3 90.9%\\nWater 3 36 92.3%\\nUser\\u2019s accuracy 90.9% 92.3% \\u2013\\nOverall accuracy 91.7% Kappa coe \\u000ecient 0.83\\n3.2.1. Zhenzhu Harbor, Guangxi, China\\nMFI was applied to the high-tidal Sentinel MSI image (acquired 2017-09-28). Figure 9 shows\\nthe MFI image (Figure 9A), mangrove forest distribution classi\\ufb01ed from MFI image (Figure 9B), and\\nreference map (Figure 9C) derived from low-tide Sentinel MSI images (described in Section 2.3).\\nAccording to the results shown in the reference map (Figure 9C), the total area of mangrove forests was\\n856.30 ha, with 107.05 ha of submerged and 749.25 ha of emerged mangrove forests. In Figure 9B, the\\ntotal area of mangrove forest we classi\\ufb01ed from the MFI image was 849.4 ha, which means 99% of the\\nmangrove forest pixels were successfully extracted from water background by the MFI. According to\\nTable 3, the overall accuracy of this mangrove map is 97% with a Kappa coe \\u000ecient of 0.94. In Zhenzhu\\nHarbor, the MFI value of emerged mangrove forests, submerged mangrove forests, and water pixels\\nrange from 0.19 to 0.30, \\u00000.01 to 0.18, and\\u00000.2 to\\u00000.01.\\nFigure 9. Apply the MFI to extract mangrove forests in Zhenzhu Harbor, Guangxi, China. ( A) MFI\\nimage, ( B) mangrove forests extracted from MFI image, and ( C) reference map.\\n3.2.2. Dalhousie Island, Sundarbans, India\\nSundarbans has the biggest patch of mangrove forest \\ufb02ourishing on the world\\u2019s largest delta\\n(Ganga\\u2013Bramhaputra\\u2013Meghna Delta; [ 47]). The tidal amplitude within the estuary ranges from 3.5\\nto 4 m, with seasonal variation between 1 and 6 m; mangrove forests are periodically submerged\\nduring high tide [ 48,49]. In this study, Dalhousie Island (located in the southern part of Sundarbans,\\nIndia) was chosen as a typical area to validate the performance of the MFI. Figure 10 shows a local\\nhigh-tidal MSI image (Figure 10A, captured on 2016-10-17), the MFI-derived image (Figure 10B), andRemote Sens. 2019 ,11, 2043 12 of 17\\nground-truth images obtained by Google Earth snapshot (Figure 10a\\u2013c). As shown in Figure 10A, in\\nmangrove swamps, a number of patches seem similar to seawater. In Figure 10a\\u2013c, although these\\npatches show white tones, they are lower and sparser mangrove forests that are intermittently \\ufb02ooded\\nby tides. Fortunately, these patches have positive values in the MFI image (Figure 10B). According to\\nMondal and Saha (2018), Dalhousie Island had 5950 ha of mangrove forests on 2015-08-03 [ 50]. In the\\nMFI image, the extent of mangrove extracted by the MFI is 6105 ha (pixels with positive MFI values),\\naccounting for 102% of Mondal and Saha\\u2019s result. Although the MSI image was captured during high\\ntide, almost all the local mangrove forests were detected by the MFI. According to Table 3, the overall\\naccuracy of this mangrove map is 96.8%, with a Kappa coe \\u000ecient of 0.93. In Dalhousie Island, the MFI\\nvalue of emerged mangrove forests, submerged mangrove forests, and water pixels range from 0.11 to\\n0.25, 0 to 0.10, and \\u20130.03 to 0.\\nFigure 10. Apply the MFI to extract mangrove forests in Dalhousie Island, Sundarbans, India. ( A)\\nSentinel MSI image (Band combination: R:G:B =8A: 4: 3); ( B) Sentinel MSI-based MFI image; ( a\\u2013c):\\nGoogle Earth snapshot.\\n3.2.3. Baia do Arraial, Amazon Coast, Brazil\\nBaia do Arraial is located along the south coasts of S \\u00e3o Lu \\u00eds city, Brazil (Figure 11). The coastal\\nzone of S \\u00e3o Lu \\u00eds is dominated by a semidiurnal tide; the high energy causes a maximum tidal height\\nof 8 m during the equinoctial spring tide. Therefore, numerous mangrove trees and shrubs would\\nbe submerged during high tides. As shown in Figure 11A, on 2018-06-14, patches in the northwest\\nand the middle of mangrove swamps were submerged; fortunately, these mangrove forests showed\\npositive values in Figure 11B, and the snapshot of Google Earth images con\\ufb01rmed that these places\\nwere occupied by low mangrove forests. Therefore, we concluded that submerged mangrove forests\\nin Baia do Arraial could be detected by the MFI. According to Table 3, the overall accuracy of this\\nmangrove map is 91.7%, with a Kappa coe \\u000ecient of 0.83. In Baia do Arraial, the MFI values of emerged\\nmangrove forests, submerged mangrove forests, and water pixels range from 0.09 to 0.25, 0 to 0.09, and\\n\\u00000.06 to 0.Remote Sens. 2019 ,11, 2043 13 of 17\\nFigure 11. Apply the MFI to extract mangrove forests in Baia do Arraial, Amazon Coast, Brazil. ( A)\\nSentinel MSI image (band combination: R:G:B =8A: 4: 3), ( B) Sentinel MSI based MFI image, ( a,b):\\nGoogle Earth snapshot.\\n4. Discussion\\n4.1. Advantages and Potential Applications of MFI\\nLocated along intertidal zones, mangrove forests are always relatively small patches; therefore,\\nmisclassi\\ufb01cation of a small area would greatly a \\u000bect mapping results. The lack of full consideration\\nof tidal conditions would cause misclassi\\ufb01cation between mangrove forests and water background.\\nTo accurately map and manage mangrove forests, in this study, we attempt to extract all mangrove\\nforests during local high tides. Undeniably, using VIs to extract mangrove forests is not new. All the\\ncommonly used indices are applicable to detecting emerged mangrove forests. However, during high\\ntides, according to our statistics in Figure 7, in LSWI, MNDWI, NDVI, and FAI images 27%, 8%, 19%,\\nand 5% of submerged pixels were mixed with water background. Furthermore, based on the result of\\nJensen\\u2013Shannon divergence, MFI greatly increased the distance of submerged mangrove forests and\\nwater. However, in the MFI image, nearly all the submerged pixels were completely separated from\\nthe water background. Furthermore, all traditional vegetation indices have a vital uncertainty, that\\nallow for the determination of the threshold of VIs. Fortunately, based on the theory of being above\\nthe baseline, one advantage of using the MFI in detecting mangrove forests is that the threshold is at\\nthe \\ufb01xed value of zero.\\nThis study provides an index built by Sentinel-2 MSI bands for discriminating submerged\\nmangrove forests from water background. It supports the \\ufb01ndings of previous studies that the NIR\\nand red-edge provide great opportunities in discriminating between vegetation and water. Sentinel-2\\nMSI image contains \\ufb01ve bands in NIR region, four of which were used to build the MFI. The FAI was\\nalso established based on baseline theory, but with one NIR band. However, according to Figure 7\\nand our statistics, unlike MFI (completely separated submerged mangrove forest and water), in the\\nFAI image, 5% of submerged mangrove forests pixels were mixed with water pixels. This is primarily\\nbecause unexpected \\ufb02uctuation in one NIR band could greatly a \\u000bect the value of the FAI. The four MSI\\nred-edge bands demonstrated relatively stable discrimination between submerged mangrove forest\\nand water.\\nTheoretically, the MFI concept can be applied to other sensors that contain spectral channels of red,\\nNIR, and SWIR, for example, the Landsat OLI sensor which has a red band ranging from 630 to 690 nm,\\nan NIR band ranging from 840 to 890 nm, and a SWIR band ranging from 2100 to 2300 nm. However,\\ndi\\u000berent sensors may acquire di \\u000berent MFI values due to the di \\u000berent ranges of red, NIR, and SWIR\\nbands. Furthermore, the performance of the Sentinel-2 MSI red-edge bands will also be present on\\nthe Sentinel-3 Ocean and Land Color Instrument (OLCI) sensor [ 51]. Therefore, the adaptability of\\nthe MFI to other remote sensing sensors still requires further examination. Moreover, the MFI was\\ndesigned based on the re\\ufb02ectance peak in the NIR spectral regions of green vegetation. Therefore,Remote Sens. 2019 ,11, 2043 14 of 17\\nthe MFI has great potential in detecting any submerged or emerged vegetation in aquatic environments,\\nsuch as \\ufb02oating algae and aquatic macrophytes. However, considering the various environments\\nwhere aquatic vegetation grows, the applicability of the MFI in detecting other aquatic vegetation still\\nwarrants further exploration.\\n4.2. Uncertainties Leading to Overestimation of Mangrove Forests Using the MFI\\nThis study demonstrates that there are abundant di \\u000berences in the spectral re\\ufb02ectance between\\nsubmerged mangrove forests and water bodies. In addition, the spectral curves of submerged and\\nemerged mangrove forests showed similar concave\\u2013convex characteristics (Figure 5). Therefore, the\\nMFI function can e \\u000eciently identify and detect mangrove forests from water background. However,\\nthe MFI was designed based on the re\\ufb02ectance peak between red and SWIR; any other vegetation that\\ncontains absorption signatures of chlorophyll in aquatic environment can also be detected [ 17,36,52].\\nHence, pixels containing \\ufb02oating vegetation (for example, algae) and other aquatic macrophytes (for\\nexample, Spartina alterni\\ufb02ora ) may be classi\\ufb01ed as mangrove forest. Additionally, due to limits in image\\nresolution, a small area of the water could still be classi\\ufb01ed as mangrove forests, due to having similar\\nspectral characteristics as nearby mangrove forests. These uncertainties can lead to overestimation of\\nmangrove forests by the MFI. In our application in Dalhousie Island, Sundarbans, India, the bias of\\narea of mangrove forests obtained by MFI is 2% larger.\\n4.3. Limitations Leading to Underestimation of Mangrove Forests Using the MFI\\nIn this study, MFI was created based on the typical re\\ufb02ectance curves of submerged mangrove\\nforests. However, the spectral curve of submerged mangrove forest can be a \\u000bected by several factors,\\nincluding water transparency (turbidity), distance that mangrove canopy under the water surface, and\\nthe coverage of mangrove forest [ 15]. Liew and Chang proved that the spectral curves of submerged\\nvegetation changes when water turbidity and depth change [ 53]. They demonstrated that with high\\nturbidity (50 nephelometric turbidity units), green vegetation could not be distinguished at a water\\ndepth of 0.5 m. In addition, with low turbidity (0.5 nephelometric turbidity units), typical vegetation\\nre\\ufb02ectance was undetectable at a water depth of 1 m. Chen et al. discovered that when submerged\\nvegetation coverage was less than 40%, it is di \\u000ecult to detect vegetation based on the NIR peak in\\nthe spectral re\\ufb02ectance curve [ 15]. Unfortunately, water \\ufb02ow in mangrove swamps always has high\\nturbidity, and newly grown trees at the edge of mangrove forests always have low coverage. According\\nto our \\ufb01eld measurement, in Zhenzhu Harbor, submerged mangrove forests with a depth of 60 cm\\nunder the water surface would not be detected by MFI. Moreover, due to limits of image resolution,\\nsmall parts of the mangrove forests may be classi\\ufb01ed as water due to low tree coverage. As shown in\\nFigure 12, in Zhenzhu Harbor, low mangrove forests along tidal creeks were not identi\\ufb01ed by MFI.\\nThese limitations lead to underestimation of the areal extent of mangrove forests by the MFI.\\nFigure 12. Intermittently \\ufb02ooded mangrove forests in local low tide period.\\n5. Conclusions\\nBased on the spectral response curves of submerged mangrove forests, a new vegetation index\\n(MFI) was developed to distinguish mangrove forests from the water background. To take fullRemote Sens. 2019 ,11, 2043 15 of 17\\nadvantage of the di \\u000berences in re\\ufb02ectance between submerged mangrove forests and the water\\nbackground, Sentinel-2 MSI bands, red and SWIR2 were selected to build a linear baseline, and the\\naverage re\\ufb02ectance value of four red-edge bands above the baseline was de\\ufb01ned as mangrove forest\\nindex (MFI). This new vegetation index is more advantageous in detecting submerged mangrove\\nforests than the traditional NDVI, LSWI, MNDWI, and FAI indices. According to the results of\\nJensen\\u2013Shannon divergence, MFI signi\\ufb01cantly widens the distance of submerged mangrove forest and\\nwater pixels compared to other VIs (the Jensen-Shannon divergence values of MFI, FAI, NDVI, LSWI,\\nand MNDWI are 0.209, 0.077, 0.012, 0.003, and 0.121, respectively). Theoretically, 100% of submerged\\nmangrove forests could be extracted from MFI images. Practically, application of the MFI in three\\nglobal mangrove sites showed 99% to 102% of submerged mangrove forests were successfully extracted\\nfrom the MFI image. The overall accuracy of classi\\ufb01cation results obtained from the MFI image ranged\\nfrom 91.7% to 97.6%. According to our \\ufb01eld measurements in Zhenzhu Harbor, MFI is insensitive to\\nmangrove forests with canopies under 60 cm of the water surface. There are some uncertainties and\\nlimitations, but the MFI was proven to be e \\u000bective in detecting the extent and condition of mangrove\\nforests from high-tide Sentinel MSI images. Although the repeatability and portability of the MFI is\\nstill a work in progress, this index brings great bene\\ufb01ts to remote sensing communities of coastal and\\naquatic vegetation studies.\\nAuthor Contributions: M.J. and Z.W. designed the research, process the data, and wrote the manuscript draft.\\nY.Z. helped with designed research and reviewed the manuscript. C.W. helped with image analysis, \\ufb01eldwork,\\nand reviewed the manuscript. D.M. helped with image analysis and reviewed the manuscript.\\nFunding: The work is supported by Science and Technology Basic Resources Investigation Program of China (No.\\n2017FY100706), the National Natural Science Foundation of China (No. 41601470, No. 41601406), the Strategic\\nPlanning Project of the Institute of Northeast Geography and Agroecology (IGA), Chinese Academy of Sciences\\n(No. Y6H2091000), and the Youth Innovation Promotion Association of Chinese Academy of Sciences (2017277,\\n2012178). This work is supported by Open Fund of State Laboratory of Information Engineering in Surveying,\\nMapping and Remote Sensing, Wuhan University (Grant No. 19I02).\\nAcknowledgments: The authors are grateful to the colleagues who participated in the \\ufb01eld surveys and\\ndata collection.\\nCon\\ufb02icts of Interest: The authors declare no con\\ufb02ict of interest.\\nReferences\\n1. Collins, D.S.; Avdis, A.; Allison, P .A.; Johnson, H.D.; Hill, J.; Piggott, M.D.; Hassan, M.H.A.; Damit, A.R.\\nTidal dynamics and mangrove carbon sequestration during the Oligo-Miocene in the South China Sea.\\nNat. Commun. 2017 ,8, 15698. [CrossRef] [PubMed]\\n2. Richards, D.R.; Friess, D.A. Rates and drivers of mangrove deforestation in Southeast Asia, 2000\\u20132012.\\nProc. Natl. Acad. Sci. USA 2016 ,113, 344\\u2013349. [CrossRef] [PubMed]\\n3. Friess, D.A.; Webb, E.L. Variability in mangrove change estimates and implications for the assessment of\\necosystem service provision. Glob. Ecol. Biogeogr. 2014 ,23, 715\\u2013725. [CrossRef]\\n4. Kuenzer, C.; Bluemel, A.; Gebhardt, S.; Quoc, T.V .; Dech, S. Remote sensing of mangrove ecosystems:\\nA review. Remote Sens. 2011 ,3, 878\\u2013928. [CrossRef]\\n5. Hamilton, S.E.; Casey, D. Creation of a high spatio-temporal resolution global database of continuous\\nmangrove forest cover for the 21st century (CGMFC-21). Glob. Ecol. Biogeogr. 2016 ,25, 729\\u2013738. [CrossRef]\\n6. Giri, C.; Pengra, B.; Zhu, Z.; Singh, A.; Tieszen, L.L. Monitoring mangrove forest dynamics of the Sundarbans\\nin Bangladesh and India using multi-temporal satellite data from 1973 to 2000. Estuar. Coast. Shelf Sci. 2007 ,\\n73, 91\\u2013100. [CrossRef]\\n7. Li, M.; Lee, S. Mangroves of China: A brief review. For. Ecol. Manag. 1997 ,96, 241\\u2013259. [CrossRef]\\n8. Spalding, M.D.; Blasco, F.; Field, C.D. World Mangrove Atlas ; Routledge: London, UK, 1997.\\n9. Cardenas, N.Y.; Joyce, K.E.; Maier, S.W. Monitoring mangrove forests: Are we taking full advantage of\\ntechnology? Int. J. Appl. Earth Obs. Geoinf. 2017 ,63, 1\\u201314. [CrossRef]\\n10. Rogers, K.; Lymburner, L.; Salum, R.; Brooke, B.P .; Woodro \\u000be, C.D. Mapping of mangrove extent and\\nzonation using high and low tide composites of Landsat data. Hydrobiologia 2017 ,803, 49\\u201368. [CrossRef]Remote Sens. 2019 ,11, 2043 16 of 17\\n11. Jia, M.; Wang, Z.; Zhang, Y.; Mao, D.; Wang, C. Monitoring loss and recovery of mangrove forests during\\n42 years: The achievements of mangrove conservation in China. Int. J. Appl. Earth Obs. Geoinf. 2018 ,73,\\n535\\u2013545. [CrossRef]\\n12. Jia, M.; Wang, Z.; Zhang, Y.; Ren, C.; Song, K. Landsat-based estimation of mangrove forest loss and\\nrestoration in Guangxi province, China, in\\ufb02uenced by human and natural factors. IEEE J. Sel. Top. Appl.\\nEarth Obs. Remote Sens. 2015 ,8, 311\\u2013323. [CrossRef]\\n13. Xia, Q.; Qin, C.-Z.; Li, H.; Huang, C.; Su, F.-Z. Mapping mangrove forests based on multi-tidal high-resolution\\nsatellite imagery. Remote Sens. 2018 ,10, 1343. [CrossRef]\\n14. Zhang, X.; Treitz, P .M.; Chen, D.; Quan, C.; Shi, L.; Li, X. Mapping mangrove forests using multi-tidal\\nremotely-sensed data and a decision-tree-based procedure. Int. J. Appl. Earth Obs. Geoinf. 2017 ,62, 201\\u2013214.\\n[CrossRef]\\n15. Chen, Q.; Yu, R.; Hao, Y.; Wu, L.; Zhang, W.; Zhang, Q.; Bu, X. A New Method for Mapping Aquatic\\nVegetation Especially Underwater Vegetation in Lake Ulansuhai Using GF-1 Satellite Data. Remote Sens.\\n2018 ,10, 1279. [CrossRef]\\n16. Silva, T.S.; Costa, M.P .; Melack, J.M.; Novo, E.M. Remote sensing of aquatic vegetation: Theory and\\napplications. Environ. Monit. Assess. 2008 ,140, 131\\u2013145. [CrossRef] [PubMed]\\n17. Gao, B.-C.; Li, R.-R. FVI\\u2014A Floating Vegetation Index Formed with Three Near-IR Channels in the 1.0\\u20131.24\\n\\u0016m Spectral Range for the Detection of Vegetation Floating over Water Surfaces. Remote Sens. 2018 ,10, 1421.\\n[CrossRef]\\n18. Sibanda, M.; Mutanga, O.; Dube, T.; S Vundla, T.; L Mafongoya, P . Estimating LAI and mapping canopy\\nstorage capacity for hydrological applications in wattle infested ecosystems using Sentinel-2 MSI derived\\nred edge bands. GISci. Remote Sens. 2019 ,56, 68\\u201386. [CrossRef]\\n19. Williams, D.J.; Rybicki, N.B.; Lombana, A.V .; O\\u2019Brien, T.M.; Gomez, R.B. Preliminary investigation of\\nsubmerged aquatic vegetation mapping using hyperspectral remote sensing. In Coastal Monitoring through\\nPartnerships ; Springer: Berlin, Germany, 2003; pp. 383\\u2013392.\\n20. Luo, J.; Li, X.; Ma, R.; Li, F.; Duan, H.; Hu, W.; Qin, B.; Huang, W. Applying remote sensing techniques to\\nmonitoring seasonal and interannual changes of aquatic vegetation in Taihu Lake, China. Ecol. Indic. 2016 ,\\n60, 503\\u2013513. [CrossRef]\\n21. Ma, R.; Duan, H.; Liu, Q.; Loiselle, S.A. Approximate bottom contribution to remote sensing re\\ufb02ectance in\\nTaihu Lake, China. J. Great Lakes Res. 2011 ,37, 18\\u201325. [CrossRef]\\n22. Pu, R.; Bell, S.; Meyer, C.; Baggett, L.; Zhao, Y. Mapping and assessing seagrass along the western coast of\\nFlorida using Landsat TM and EO-1 ALI /Hyperion imagery. Estuar. Coast. Shelf Sci. 2012 ,115, 234\\u2013245.\\n[CrossRef]\\n23. Purnamasayangsukasih, P .R.; Norizah, K.; Ismail, A.A.; Shamsudin, I. A review of uses of satellite imagery\\nin monitoring mangrove forests. In Proceedings of the IOP Conference Series: Earth and Environmental\\nScience, Prague, Czech Republic, 12\\u201319 July 2016; p. 012034.\\n24. Zhao, D.; Jiang, H.; Yang, T.; Cai, Y.; Xu, D.; An, S. Remote sensing of aquatic vegetation distribution in Taihu\\nLake using an improved classi\\ufb01cation tree with modi\\ufb01ed thresholds. J. Environ. Manag. 2012 ,95, 98\\u2013107.\\n[CrossRef] [PubMed]\\n25. Visser, F.; Buis, K.; Verschoren, V .; Meire, P . Depth estimation of submerged aquatic vegetation in clear water\\nstreams using low-altitude optical remote sensing. Sensors 2015 ,15, 25287\\u201325312. [CrossRef] [PubMed]\\n26. Heumann, B.W. An object-based classi\\ufb01cation of mangroves using a hybrid decision tree\\u2014Support vector\\nmachine approach. Remote Sens. 2011 ,3, 2440\\u20132460. [CrossRef]\\n27. Heumann, B.W. Satellite remote sensing of mangrove forests: Recent advances and future opportunities.\\nProg. Phys. Geogr. 2011 ,35, 87\\u2013108. [CrossRef]\\n28. Wang, T.; Zhang, H.; Lin, H.; Fang, C. Textural\\u2013spectral feature-based species classi\\ufb01cation of mangroves in\\nMai Po Nature Reserve from Worldview-3 imagery. Remote Sens. 2016 ,8, 24. [CrossRef]\\n29. Wan, L.; Zhang, H.; Wang, T.; Li, G.; Lin, H. Mangrove species discrimination from very high resolution\\nimagery using gaussian markov random \\ufb01eld model. Wetlands 2018 ,38, 861\\u2013874. [CrossRef]\\n30. Huete, A.; Justice, C.; Van Leeuwen, W. MODIS vegetation index (MOD 13) algorithm theoretical basis\\ndocument (ATBD) Version 3.0. EOS Proj. O \\u000b.1999 , 2\\u20133.Remote Sens. 2019 ,11, 2043 17 of 17\\n31. Matsushita, B.; Yang, W.; Chen, J.; Onda, Y.; Qiu, G. Sensitivity of the enhanced vegetation index (EVI) and\\nnormalized di \\u000berence vegetation index (NDVI) to topographic e \\u000bects: A case study in high-density cypress\\nforest. Sensors 2007 ,7, 2636\\u20132651. [CrossRef] [PubMed]\\n32. Gao, B.-C. NDWI\\u2014A normalized di \\u000berence water index for remote sensing of vegetation liquid water from\\nspace. Remote Sens. Environ. 1996 ,58, 257\\u2013266. [CrossRef]\\n33. Xiao, X.; Boles, S.; Liu, J.; Zhuang, D.; Frolking, S.; Li, C.; Salas, W.; Moore, B., III. Mapping paddy rice\\nagriculture in southern China using multi-temporal MODIS images. Remote Sens. Environ. 2005 ,95, 480\\u2013492.\\n[CrossRef]\\n34. Xu, H. Modi\\ufb01cation of normalised di \\u000berence water index (NDWI) to enhance open water features in remotely\\nsensed imagery. Int. J. Remote Sens. 2006 ,27, 3025\\u20133033. [CrossRef]\\n35. Gower, J.; Hu, C.; Borstad, G.; King, S. Ocean color satellites show extensive lines of \\ufb02oating Sargassum in\\nthe Gulf of Mexico. IEEE Trans. Geosci. Remote Sens. 2006 ,44, 3619\\u20133625. [CrossRef]\\n36. Hu, C. A novel ocean color index to detect \\ufb02oating algae in the global oceans. Remote Sens. Environ. 2009 ,\\n113, 2118\\u20132129. [CrossRef]\\n37. Li, S.; Ganguly, S.; Dungan, J.L.; Wang, W.; Nemani, R.R. Sentinel-2 MSI radiometric characterization and\\ncross-calibration with Landsat-8 OLI. Adv. Remote Sens 2017 ,6, 147. [CrossRef]\\n38. Wang, Q.; Blackburn, G.A.; Onojeghuo, A.O.; Dash, J.; Zhou, L.; Zhang, Y.; Atkinson, P .M. Fusion of Landsat\\n8 OLI and Sentinel-2 MSI data. IEEE Trans. Geosci. Remote Sens. 2017 ,55, 3885\\u20133899. [CrossRef]\\n39. Clevers, J.G.; Kooistra, L.; van den Brande, M.M. Using Sentinel-2 data for retrieving LAI and leaf and\\ncanopy chlorophyll content of a potato crop. Remote Sens. 2017 ,9, 405. [CrossRef]\\n40. Quintano, C.; Fern \\u00e1ndez-Manso, A.; Fern \\u00e1ndez-Manso, O. Combination of Landsat and Sentinel-2 MSI data\\nfor initial assessing of burn severity. Int. J. Appl. Earth Obs. Geoinf. 2018 ,64, 221\\u2013225. [CrossRef]\\n41. Harayama, A.; Jaquet, J.-M. Multi-Source Object-Oriented Classi\\ufb01cation of Landcover Using Very High Resolution\\nImagery and Digital Elevation Model ; UNEP: Geneva, Switzerland, 2004.\\n42. Spalding, M. World Atlas of Mangroves ; Routledge: London, UK, 2010.\\n43. Han, L.; Rundquist, D. The spectral responses of Ceratophyllum demersum at varying depths in an\\nexperimental tank. Int. J. Remote Sens. 2003 ,24, 859\\u2013864. [CrossRef]\\n44. Cho, H.J.; Kirui, P .; Natarajan, H. Test of multi-spectral vegetation index for \\ufb02oating and canopy-forming\\nsubmerged vegetation. Int. J. Environ. Res. Public Health 2008 ,5, 477\\u2013483. [CrossRef]\\n45. Tucker, C.J. Red and photographic infrared linear combinations for monitoring vegetation. Remote Sens.\\nEnviron. 1979 ,8, 127\\u2013150. [CrossRef]\\n46. Lin, J. Divergence measures based on the Shannon entropy. IEEE Trans. Inf. Theory 1991 ,37, 145\\u2013151. [CrossRef]\\n47. Manna, S.; Raychaudhuri, B. Mapping distribution of Sundarban mangroves using Sentinel-2 data and new\\nspectral metric for detecting their health condition. Geocarto Int. 2018 , 1\\u201330. [CrossRef]\\n48. Ghosh, A.; Schmidt, S.; Fickert, T.; N\\u00fcsser, M. The Indian Sundarban mangrove forests: History, utilization,\\nconservation strategies and local perception. Diversity 2015 ,7, 149\\u2013169. [CrossRef]\\n49. Islam, M.T. Vegetation changes of Sundarbans based on Landsat Imagery analysis between 1975 and 2006.\\nActa Geogr. Debrecina Landsc. Environ. Ser. 2014 ,8, 1\\u20139.\\n50. Mondal, B.; Saha, A.K. Spatio-Temporal Analysis of Mangrove Loss in Vulnerable Islands of Sundarban World\\nHeritage Site, India. In Proceedings of the Annual International Conference on Geographic Information\\nScience, Lund, Sweden, 12\\u201315 June 2018; Springer: Cham, Switzerland, 2018; pp. 93\\u2013109.\\n51. Clevers, J.G.; Gitelson, A.A. Remote estimation of crop and grass chlorophyll and nitrogen content using\\nred-edge bands on Sentinel-2 and-3. Int. J. Appl. Earth Obs. Geoinf. 2013 ,23, 344\\u2013351. [CrossRef]\\n52. Cho, H.J.; Lu, D. A water-depth correction algorithm for submerged vegetation spectra. Remote Sens. Lett.\\n2010 ,1, 29\\u201335. [CrossRef]\\n53. Liew, S.C.; Chang, C.W. Detecting submerged aquatic vegetation with 8-band WorldView-2 satellite images.\\nIn Proceedings of the 2012 IEEE International Geoscience and Remote Sensing Symposium (IGARSS), Munich,\\nGermany, 22\\u201327 July 2012; pp. 2560\\u20132562.\\n\\u00a92019 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access\\narticle distributed under the terms and conditions of the Creative Commons Attribution\\n(CC BY) license (http: //creativecommons.org /licenses /by/4.0/).\",\n          \"Extinguished philosophies lie about the cradle of every sci ence as the\\nstrangled snakes beside that of Hercules. - adapted from T. H . Huxley\\n1WHAT IS ARTIFICIAL INTELLIGENCE?\\nJohn McCarthy\\nComputer Science Department\\nStanford University\\nStanford, CA 94305\\njmc@cs.stanford.edu\\nhttp://www-formal.stanford.edu/jmc/\\n2007 Nov 12, 2:05 a.m.\\nRevised November 12, 2007:\\nAbstract\\nThis article for the layman answers basic questions about ar ti\\ufb01cial\\nintelligence. The opinions expressed here are not all conse nsus opinion\\namong researchers in AI.\\n1 Basic Questions\\nQ. What is arti\\ufb01cial intelligence?\\nA. It is the science and engineering of making intelligent ma chines, es-\\npecially intelligent computer programs. It is related to th e similar task of\\nusing computers to understand human intelligence, but AI do es not have to\\ncon\\ufb01ne itself to methods that are biologically observable.\\nQ. Yes, but what is intelligence?\\nA. Intelligence is the computational part of the ability to a chieve goals in\\nthe world. Varying kinds and degrees of intelligence occur i n people, many\\nanimals and some machines.\\nQ. Isn\\u2019t there a solid de\\ufb01nition of intelligence that doesn\\u2019 t depend on\\nrelating it to human intelligence?\\n2A. Not yet. The problem is that we cannot yet characterize in g eneral\\nwhat kinds of computational procedures we want to call intel ligent. We\\nunderstand some of the mechanisms of intelligence and not ot hers.\\nQ. Is intelligence a single thing so that one can ask a yes or no question\\n\\u201cIs this machine intelligent or not?\\u201d?\\nA. No. Intelligence involves mechanisms, and AI research ha s discovered\\nhow to make computers carry out some of them and not others. If doing a\\ntask requires only mechanisms that are well understood toda y, computer pro-\\ngrams can give very impressive performances on these tasks. Such programs\\nshould be considered \\u201csomewhat intelligent\\u201d.\\nQ. Isn\\u2019t AI about simulating human intelligence?\\nA. Sometimes but not always or even usually. On the one hand, w e can\\nlearn something about how to make machines solve problems by observing\\nother people or just by observing our own methods. On the othe r hand, most\\nwork in AI involves studying the problems the world presents to intelligence\\nrather than studying people or animals. AI researchers are f ree to use meth-\\nods that are not observed in people or that involve much more c omputing\\nthan people can do.\\nQ. What about IQ? Do computer programs have IQs?\\nA. No. IQ is based on the rates at which intelligence develops in children.\\nIt is the ratio of the age at which a child normally makes a cert ain score\\nto the child\\u2019s age. The scale is extended to adults in a suitab le way. IQ\\ncorrelates well with various measures of success or failure in life, but making\\ncomputers that can score high on IQ tests would be weakly corr elated with\\ntheir usefulness. For example, the ability of a child to repe at back a long\\nsequence of digits correlates well with other intellectual abilities, perhaps\\nbecause it measures how much information the child can compu te with at\\nonce. However, \\u201cdigit span\\u201d is trivial for even extremely li mited computers.\\nHowever, some of the problems on IQ tests are useful challeng es for AI.\\nQ. What about other comparisons between human and computer i ntelli-\\ngence?\\nArthur R. Jensen [Jen98], a leading researcher in human inte lligence,\\nsuggests \\u201cas a heuristic hypothesis\\u201d that all normal humans have the same\\nintellectual mechanisms and that di\\ufb00erences in intelligen ce are related to\\n\\u201cquantitative biochemical and physiological conditions\\u201d . I see them as speed,\\nshort term memory, and the ability to form accurate and retri evable long term\\nmemories.\\nWhether or not Jensen is right about human intelligence, the situation in\\n3AI today is the reverse.\\nComputer programs have plenty of speed and memory but their a bilities\\ncorrespond to the intellectual mechanisms that program des igners understand\\nwell enough to put in programs. Some abilities that children normally don\\u2019t\\ndevelop till they are teenagers may be in, and some abilities possessed by\\ntwo year olds are still out. The matter is further complicate d by the fact\\nthat the cognitive sciences still have not succeeded in dete rmining exactly\\nwhat the human abilities are. Very likely the organization o f the intellectual\\nmechanisms for AI can usefully be di\\ufb00erent from that in peopl e.\\nWhenever people do better than computers on some task or comp uters\\nuse a lot of computation to do as well as people, this demonstr ates that the\\nprogram designers lack understanding of the intellectual m echanisms required\\nto do the task e\\ufb03ciently.\\nQ. When did AI research start?\\nA. After WWII, a number of people independently started to wo rk on\\nintelligent machines. The English mathematician Alan Turi ng may have\\nbeen the \\ufb01rst. He gave a lecture on it in 1947. He also may have b een the\\n\\ufb01rst to decide that AI was best researched by programming com puters rather\\nthan by building machines. By the late 1950s, there were many researchers\\non AI, and most of them were basing their work on programming c omputers.\\nQ. Does AI aim to put the human mind into the computer?\\nA. Some researchers say they have that objective, but maybe t hey are\\nusing the phrase metaphorically. The human mind has a lot of p eculiarities,\\nand I\\u2019m not sure anyone is serious about imitating all of them .\\nQ. What is the Turing test?\\nA. Alan Turing\\u2019s 1950 article Computing Machinery and Intelligence [Tur50]\\ndiscussed conditions for considering a machine to be intell igent. He argued\\nthat if the machine could successfully pretend to be human to a knowledge-\\nable observer then you certainly should consider it intelli gent. This test\\nwould satisfy most people but not all philosophers. The obse rver could in-\\nteract with the machine and a human by teletype (to avoid requ iring that\\nthe machine imitate the appearance or voice of the person), a nd the human\\nwould try to persuade the observer that it was human and the ma chine would\\ntry to fool the observer.\\nThe Turing test is a one-sided test. A machine that passes the test should\\ncertainly be considered intelligent, but a machine could st ill be considered\\nintelligent without knowing enough about humans to imitate a human.\\nDaniel Dennett\\u2019s book Brainchildren [Den98] has an excellent discussion\\n4of the Turing test and the various partial Turing tests that h ave been im-\\nplemented, i.e. with restrictions on the observer\\u2019s knowle dge of AI and the\\nsubject matter of questioning. It turns out that some people are easily led\\ninto believing that a rather dumb program is intelligent.\\nQ. Does AI aim at human-level intelligence?\\nA. Yes. The ultimate e\\ufb00ort is to make computer programs that c an solve\\nproblems and achieve goals in the world as well as humans. How ever, many\\npeople involved in particular research areas are much less a mbitious.\\nQ. How far is AI from reaching human-level intelligence? Whe n will it\\nhappen?\\nA. A few people think that human-level intelligence can be ac hieved by\\nwriting large numbers of programs of the kind people are now w riting and\\nassembling vast knowledge bases of facts in the languages no w used for ex-\\npressing knowledge.\\nHowever, most AI researchers believe that new fundamental i deas are\\nrequired, and therefore it cannot be predicted when human-l evel intelligence\\nwill be achieved.\\nQ. Are computers the right kind of machine to be made intellig ent?\\nA. Computers can be programmed to simulate any kind of machin e.\\nMany researchers invented non-computer machines, hoping t hat they\\nwould be intelligent in di\\ufb00erent ways than the computer prog rams could\\nbe. However, they usually simulate their invented machines on a computer\\nand come to doubt that the new machine is worth building. Beca use many\\nbillions of dollars that have been spent in making computers faster and faster,\\nanother kind of machine would have to be very fast to perform b etter than\\na program on a computer simulating the machine.\\nQ. Are computers fast enough to be intelligent?\\nA. Some people think much faster computers are required as we ll as new\\nideas. My own opinion is that the computers of 30 years ago wer e fast\\nenough if only we knew how to program them. Of course, quite ap art from\\nthe ambitions of AI researchers, computers will keep gettin g faster.\\nQ. What about parallel machines?\\nA. Machines with many processors are much faster than single proces-\\nsors can be. Parallelism itself presents no advantages, and parallel machines\\nare somewhat awkward to program. When extreme speed is requi red, it is\\nnecessary to face this awkwardness.\\nQ. What about making a \\u201cchild machine\\u201d that could improve by r eading\\nand by learning from experience?\\n5A. This idea has been proposed many times, starting in the 194 0s. Even-\\ntually, it will be made to work. However, AI programs haven\\u2019t yet reached\\nthe level of being able to learn much of what a child learns fro m physical\\nexperience. Nor do present programs understand language we ll enough to\\nlearn much by reading.\\nQ. Might an AI system be able to bootstrap itself to higher and higher\\nlevel intelligence by thinking about AI?\\nA. I think yes, but we aren\\u2019t yet at a level of AI at which this pr ocess can\\nbegin.\\nQ. What about chess?\\nA. Alexander Kronrod, a Russian AI researcher, said \\u201cChess i s theDrosophila\\nof AI.\\u201d He was making an analogy with geneticists\\u2019 use of that fruit \\ufb02y to\\nstudy inheritance. Playing chess requires certain intelle ctual mechanisms and\\nnot others. Chess programs now play at grandmaster level, bu t they do it\\nwith limited intellectual mechanisms compared to those use d by a human\\nchess player, substituting large amounts of computation fo r understanding.\\nOnce we understand these mechanisms better, we can build hum an-level\\nchess programs that do far less computation than do present p rograms.\\nUnfortunately, the competitive and commercial aspects of m aking com-\\nputers play chess have taken precedence over using chess as a scienti\\ufb01c do-\\nmain. It is as if the geneticists after 1910 had organized fru it \\ufb02y races and\\nconcentrated their e\\ufb00orts on breeding fruit \\ufb02ies that could win these races.\\nQ. What about Go?\\nA. The Chinese and Japanese game of Gois also a board game in which\\nthe players take turns moving. Goexposes the weakness of our present under-\\nstanding of the intellectual mechanisms involved in human g ame playing. Go\\nprograms are very bad players, in spite of considerable e\\ufb00or t (not as much as\\nfor chess). The problem seems to be that a position in Gohas to be divided\\nmentally into a collection of subpositions which are \\ufb01rst an alyzed separately\\nfollowed by an analysis of their interaction. Humans use thi s in chess also,\\nbut chess programs consider the position as a whole. Chess pr ograms com-\\npensate for the lack of this intellectual mechanism by doing thousands or, in\\nthe case of Deep Blue, many millions of times as much computat ion.\\nSooner or later, AI research will overcome this scandalous w eakness.\\nQ. Don\\u2019t some people say that AI is a bad idea?\\nA. The philosopher John Searle says that the idea of a non-bio logical ma-\\nchine being intelligent is incoherent. He proposes the Chin ese room argument\\nwww-formal.stanford.edu/jmc/chinese.html The philosop her Hubert Dreyfus\\n6says that AI is impossible. The computer scientist Joseph We izenbaum says\\nthe idea is obscene, anti-human and immoral. Various people have said that\\nsince arti\\ufb01cial intelligence hasn\\u2019t reached human level by now, it must be\\nimpossible. Still other people are disappointed that compa nies they invested\\nin went bankrupt.\\nQ. Aren\\u2019t computability theory and computational complexi ty the keys\\nto AI? [Note to the layman and beginners in computer science: These are\\nquite technical branches of mathematical logic and compute r science, and\\nthe answer to the question has to be somewhat technical.]\\nA. No. These theories are relevant but don\\u2019t address the fund amental\\nproblems of AI.\\nIn the 1930s mathematical logicians, especially Kurt G\\u00a8 ode l and Alan Tur-\\ning, established that there did not exist algorithms that we re guaranteed to\\nsolve all problems in certain important mathematical domai ns. Whether a\\nsentence of \\ufb01rst order logic is a theorem is one example, and w hether a poly-\\nnomial equations in several variables has integer solution s is another. Hu-\\nmans solve problems in these domains all the time, and this ha s been o\\ufb00ered\\nas an argument (usually with some decorations) that compute rs are intrinsi-\\ncally incapable of doing what people do. Roger Penrose claim s this. However,\\npeople can\\u2019t guarantee to solve arbitrary problems in these domains either.\\nSee my Review of The Emperor\\u2019s New Mind by Roger Penrose. More essays\\nand reviews defending AI research are in [McC96a].\\nIn the 1960s computer scientists, especially Steve Cook and Richard Karp\\ndeveloped the theory of NP-complete problem domains. Probl ems in these\\ndomains are solvable, but seem to take time exponential in th e size of the\\nproblem. Which sentences of propositional calculus are sat is\\ufb01able is a basic\\nexample of an NP-complete problem domain. Humans often solv e problems\\nin NP-complete domains in times much shorter than is guarant eed by the\\ngeneral algorithms, but can\\u2019t solve them quickly in general .\\nWhat is important for AI is to have algorithms as capable as pe ople at\\nsolving problems. The identi\\ufb01cation of subdomains for whic h good algo-\\nrithms exist is important, but a lot of AI problem solvers are not associated\\nwith readily identi\\ufb01ed subdomains.\\nThe theory of the di\\ufb03culty of general classes of problems is c alledcom-\\nputational complexity. So far this theory hasn\\u2019t interacted with AI as much\\nas might have been hoped. Success in problem solving by human s and by\\nAI programs seems to rely on properties of problems and probl em solving\\nmethods that the neither the complexity researchers nor the AI community\\n7have been able to identify precisely.\\nAlgorithmic complexity theory as developed by Solomono\\ufb00, K olmogorov\\nand Chaitin (independently of one another) is also relevant . It de\\ufb01nes the\\ncomplexity of a symbolic object as the length of the shortest program that\\nwill generate it. Proving that a candidate program is the sho rtest or close\\nto the shortest is an unsolvable problem, but representing o bjects by short\\nprograms that generate them should sometimes be illuminati ng even when\\nyou can\\u2019t prove that the program is the shortest.\\n2 Branches of AI\\nQ. What are the branches of AI?\\nA. Here\\u2019s a list, but some branches are surely missing, becau se no-one\\nhas identi\\ufb01ed them yet. Some of these may be regarded as conce pts or topics\\nrather than full branches.\\nlogical AI What a program knows about the world in general the facts\\nof the speci\\ufb01c situation in which it must act, and its goals ar e all\\nrepresented by sentences of some mathematical logical lang uage. The\\nprogram decides what to do by inferring that certain actions are ap-\\npropriate for achieving its goals. The \\ufb01rst article proposi ng this was\\n[McC59]. [McC89] is a more recent summary. [McC96b] lists so me of\\nthe concepts involved in logical aI. [Sha97] is an important text.\\nsearch AI programs often examine large numbers of possibilities, e .g. moves\\nin a chess game or inferences by a theorem proving program. Di scover-\\nies are continually made about how to do this more e\\ufb03ciently i n various\\ndomains.\\npattern recognition When a program makes observations of some kind,\\nit is often programmed to compare what it sees with a pattern. For\\nexample, a vision program may try to match a pattern of eyes an d a\\nnose in a scene in order to \\ufb01nd a face. More complex patterns, e .g. in\\na natural language text, in a chess position, or in the histor y of some\\nevent are also studied. These more complex patterns require quite\\ndi\\ufb00erent methods than do the simple patterns that have been s tudied\\nthe most.\\n8representation Facts about the world have to be represented in some way.\\nUsually languages of mathematical logic are used.\\ninference From some facts, others can be inferred. Mathematical logic al\\ndeduction is adequate for some purposes, but new methods of non-\\nmonotonic inference have been added to logic since the 1970s. The\\nsimplest kind of non-monotonic reasoning is default reason ing in which\\na conclusion is to be inferred by default, but the conclusion can be\\nwithdrawn if there is evidence to the contrary. For example, when\\nwe hear of a bird, we man infer that it can \\ufb02y, but this conclusi on\\ncan be reversed when we hear that it is a penguin. It is the poss ibil-\\nity that a conclusion may have to be withdrawn that constitut es the\\nnon-monotonic character of the reasoning. Ordinary logica l reasoning\\nis monotonic in that the set of conclusions that can the drawn from\\na set of premises is a monotonic increasing function of the pr emises.\\nCircumscription is another form of non-monotonic reasonin g.\\ncommon sense knowledge and reasoning This is the area in which AI\\nis farthest from human-level, in spite of the fact that it has been an\\nactive research area since the 1950s. While there has been co nsiderable\\nprogress, e.g. in developing systems of non-monotonic reasoning and\\ntheories of action, yet more new ideas are needed. The Cyc sys tem\\ncontains a large but spotty collection of common sense facts .\\nlearning from experience Programs do that. The approaches to AI based\\nonconnectionism andneural nets specialize in that. There is also learn-\\ning of laws expressed in logic. [Mit97] is a comprehensive un dergrad-\\nuate text on machine learning. Programs can only learn what f acts\\nor behaviors their formalisms can represent, and unfortuna tely learn-\\ning systems are almost all based on very limited abilities to represent\\ninformation.\\nplanning Planning programs start with general facts about the world ( es-\\npecially facts about the e\\ufb00ects of actions), facts about the particular\\nsituation and a statement of a goal. From these, they generat e a strat-\\negy for achieving the goal. In the most common cases, the stra tegy is\\njust a sequence of actions.\\nepistemology This is a study of the kinds of knowledge that are required\\nfor solving problems in the world.\\n9ontology Ontology is the study of the kinds of things that exist. In AI,\\nthe programs and sentences deal with various kinds of object s, and\\nwe study what these kinds are and what their basic properties are.\\nEmphasis on ontology begins in the 1990s.\\nheuristics A heuristic is a way of trying to discover something or an idea\\nimbedded in a program. The term is used variously in AI. Heuristic\\nfunctions are used in some approaches to search to measure how far\\na node in a search tree seems to be from a goal. Heuristic predicates\\nthat compare two nodes in a search tree to see if one is better t han the\\nother, i.e. constitutes an advance toward the goal, may be mo re useful.\\n[My opinion].\\ngenetic programming Genetic programming is a technique for getting pro-\\ngrams to solve a task by mating random Lisp programs and selec ting\\n\\ufb01ttest in millions of generations. It is being developed by J ohn Koza\\u2019s\\ngroup and here\\u2019s a tutorial1.\\n3 Applications of AI\\nQ. What are the applications of AI?\\nA. Here are some.\\ngame playing You can buy machines that can play master level chess for\\na few hundred dollars. There is some AI in them, but they play w ell\\nagainst people mainly through brute force computation\\u2014loo king at\\nhundreds of thousands of positions. To beat a world champion by\\nbrute force and known reliable heuristics requires being ab le to look at\\n200 million positions per second.\\nspeech recognition In the 1990s, computer speech recognition reached a\\npractical level for limited purposes. Thus United Airlines has replaced\\nits keyboard tree for \\ufb02ight information by a system using spe ech recog-\\nnition of \\ufb02ight numbers and city names. It is quite convenien t. On the\\nthe other hand, while it is possible to instruct some compute rs using\\nspeech, most users have gone back to the keyboard and the mous e as\\nstill more convenient.\\n1http://www.genetic-programming.com/gpanimatedtutori al.html\\n10understanding natural language Just getting a sequence of words into a\\ncomputer is not enough. Parsing sentences is not enough eith er. The\\ncomputer has to be provided with an understanding of the doma in\\nthe text is about, and this is presently possible only for ver y limited\\ndomains.\\ncomputer vision The world is composed of three-dimensional objects, but\\nthe inputs to the human eye and computers\\u2019 TV cameras are two d i-\\nmensional. Some useful programs can work solely in two dimen sions,\\nbut full computer vision requires partial three-dimension al informa-\\ntion that is not just a set of two-dimensional views. At prese nt there\\nare only limited ways of representing three-dimensional in formation di-\\nrectly, and they are not as good as what humans evidently use.\\nexpert systems A \\u201cknowledge engineer\\u201d interviews experts in a certain do-\\nmain and tries to embody their knowledge in a computer progra m for\\ncarrying out some task. How well this works depends on whethe r the\\nintellectual mechanisms required for the task are within th e present\\nstate of AI. When this turned out not to be so, there were many d is-\\nappointing results. One of the \\ufb01rst expert systems was MYCIN in\\n1974, which diagnosed bacterial infections of the blood and suggested\\ntreatments. It did better than medical students or practici ng doctors,\\nprovided its limitations were observed. Namely, its ontolo gy included\\nbacteria, symptoms, and treatments and did not include pati ents, doc-\\ntors, hospitals, death, recovery, and events occurring in t ime. Its in-\\nteractions depended on a single patient being considered. S ince the\\nexperts consulted by the knowledge engineers knew about pat ients,\\ndoctors, death, recovery, etc., it is clear that the knowled ge engineers\\nforced what the experts told them into a predetermined frame work. In\\nthe present state of AI, this has to be true. The usefulness of current\\nexpert systems depends on their users having common sense.\\nheuristic classi\\ufb01cation One of the most feasible kinds of expert system\\ngiven the present knowledge of AI is to put some information i n one\\nof a \\ufb01xed set of categories using several sources of informat ion. An\\nexample is advising whether to accept a proposed credit card purchase.\\nInformation is available about the owner of the credit card, his record\\nof payment and also about the item he is buying and about the es tab-\\nlishment from which he is buying it (e.g., about whether ther e have\\n11been previous credit card frauds at this establishment).\\n4 More questions\\nQ. How is AI research done?\\nA. AI research has both theoretical and experimental sides. The experi-\\nmental side has both basic and applied aspects.\\nThere are two main lines of research. One is biological, base d on the\\nidea that since humans are intelligent, AI should study huma ns and imitate\\ntheir psychology or physiology. The other is phenomenal, ba sed on studying\\nand formalizing common sense facts about the world and the pr oblems that\\nthe world presents to the achievement of goals. The two appro aches interact\\nto some extent, and both should eventually succeed. It is a ra ce, but both\\nracers seem to be walking.\\nQ. What are the relations between AI and philosophy?\\nA. AI has many relations with philosophy, especially modern analytic\\nphilosophy. Both study mind, and both study common sense. Th e best\\nreference is [Tho03].\\nQ. How are AI and logic programming related?\\nA. At the very least, logic programming provides useful prog ramming\\nlanguages (mainly Prolog).\\nBeyond that, sometimes a theory Tuseful in AI can be expressed as a col-\\nlection HofHorn clauses , and goal Gto be achieved can be expressed as that\\nof \\ufb01nding values of variables x1. . .x nsatisfying an expression g(x1. . .x n).\\nThe problem can sometimes be solved by running the Prolog pro gram con-\\nsisting of GandH.\\nThere are two possible obstacles to regarding AI as logic pro gramming.\\nFirst, Horn theories do not exhaust \\ufb01rst order logic. Second , the Prolog\\nprogram expressing the theory may be extremely ine\\ufb03cient. M ore elaborate\\ncontrol than just executing the program that expresses the t heory is often\\nneeded. Map coloring provides examples.\\nQ. What should I study before or while learning AI?\\nA. Study mathematics, especially mathematical logic. The m ore you\\nlearn about sciences, e.g. physics or biology, the better. F or the biological\\napproaches to AI, study psychology and the physiology of the nervous system.\\nLearn some programming languages\\u2014at least C, Lisp and Prolo g. It is also a\\ngood idea to learn one basic machine language. Jobs are likel y to depend on\\n12knowing the languages currently in fashion. In the late 1990 s, these include\\nC++ and Java.\\nQ. What is a good textbook on AI?\\nA.Arti\\ufb01cial Intelligence by Stuart Russell and Peter Norvig, Prentice Hall\\nis the most commonly used textbbook in 1997. The general view s expressed\\nthere do not exactly correspond to those of this essay. Arti\\ufb01cial Intelligence:\\nA New Synthesis by Nils Nilsson, Morgan Kaufman, may be easier to read.\\nSome people prefer Computational Intelligence by David Poole, Alan Mack-\\nworth and Randy Goebel, Oxford, 1998.\\nQ. What organizations and publications are concerned with A I?\\nA. The American Association for Arti\\ufb01cial Intelligence (AA AI)2, the Eu-\\nropean Coordinating Committee for Arti\\ufb01cial Intelligence (ECCAI)3and the\\nSociety for Arti\\ufb01cial Intelligence and Simulation of Behav ior (AISB)4are\\nscienti\\ufb01c societies concerned with AI research. The Associ ation for Comput-\\ning Machinery (ACM) has a special interest group on arti\\ufb01cia l intelligence\\nSIGART5.\\nThe International Joint Conference on AI (IJCAI)6is the main inter-\\nnational conference. The AAAI7runs a US National Conference on AI.\\nElectronic Transactions on Arti\\ufb01cial Intelligence8,Arti\\ufb01cial Intelligence9,\\nandJournal of Arti\\ufb01cial Intelligence Research10, and IEEE Transactions on\\nPattern Analysis and Machine Intelligence11are four of the main journals\\npublishing AI research papers. I have not yet found everythi ng that should\\nbe in this paragraph.\\nPage of Positive Reviews12lists papers that experts have found impor-\\ntant.\\nFunding a Revolution: Government Support for Computing Res earch by a\\ncommittee of the National Research covers support for AI res earch in Chapter\\n2http://www.aaai.org\\n3http://www.eccai.org/\\n4http://www.cogs.susx.ac.uk/aisb\\n5http://www.acm.org/sigart\\n6http://www.ijcai.org\\n7http://www.aaai.org\\n8http://www.ida.liu.se/ext/etai/\\n9http://www.elsevier.nl/locate/artint/\\n10http://www.jair.org/\\n11http://computer.org/tpami/\\n12http://www.cs.utexas.edu/users/vl/ppr/\\n139.13\\nReferences\\n[Den98] Daniel Dennett. Brainchildren: Essays on Designing Minds . MIT\\nPress, 1998.\\n[Jen98] Arthur R. Jensen. Does IQ matter? Commentary , pages 20\\u201321,\\nNovember 1998. The reference is just to Jensen\\u2019s comment\\u2014on e\\nof many.\\n[McC59] John McCarthy. Programs with Common Sense14. InMechani-\\nsation of Thought Processes, Proceedings of the Symposium o f the\\nNational Physics Laboratory , pages 77\\u201384, London, U.K., 1959.\\nHer Majesty\\u2019s Stationery O\\ufb03ce. Reprinted in [McC90].\\n[McC89] John McCarthy. Arti\\ufb01cial Intelligence, Logic and F ormalizing\\nCommon Sense15. In Richmond Thomason, editor, Philosophical\\nLogic and Arti\\ufb01cial Intelligence . Kl\\u00a8 uver Academic, 1989.\\n[McC90] John McCarthy. Formalizing Common Sense: Papers by John\\nMcCarthy . Ablex Publishing Corporation, 1990.\\n[McC96a] John McCarthy. Defending AI research : a collection of essays\\nand reviews . CSLI lecture notes: no. 49. Center for the Study\\nof Language and Information, 1996. distributed by Cambridg e\\nUniversity Press.\\n[McC96b] John McCarthy. Concepts of Logical AI16, 1996. Web only for\\nnow but may be referenced.\\n[Mit97] Tom Mitchell. Machine Learning . McGraw-Hill, 1997.\\n[Sha97] Murray Shanahan. Solving the Frame Problem, a mathematical\\ninvestigation of the common sense law of inertia . M.I.T. Press,\\n1997.\\n13http://www.nap.edu/readingroom/books/far/ch9.html\\n14http://www-formal.stanford.edu/jmc/mcc59.html\\n15http://www-formal.stanford.edu/jmc/ailogic.html\\n16http://www-formal.stanford.edu/jmc/concepts-ai.html\\n14[Tho03] Richmond Thomason. Logic and arti\\ufb01cial intelligen ce. In Ed-\\nward N. Zalta, editor, The Stanford Encyclopedia of Philosophy .\\n2003. http://plato.stanford.edu/entries/logic-ai/.\\n[Tur50] Alan Turing. Computing machinery and intelligence .Mind, 1950.\\n/@steam.stanford.edu:/u/ftp/jmc/whatisai.tex: begun S at Nov 23 10:30:17 1996, latexed November 12, 2007 at 2:05 a.m .\\n15\"\n        ],\n        \"num_unique_values\": 3,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfFileReader\n",
        "\n",
        "def get_info(path):\n",
        "    with open(path, 'rb') as f:\n",
        "        pdf = PdfReader(f)\n",
        "        metadata = pdf.metadata\n",
        "        num_pages = len(pdf.pages)\n",
        "\n",
        "        author = metadata.get('/Author', 'Unknown Author')\n",
        "        creator = metadata.get('/Creator', 'Unknown Creator')\n",
        "        producer = metadata.get('/Producer', 'Unknown Producer')\n",
        "        subject = metadata.get('/Subject', 'Unknown Subject')\n",
        "        title = metadata.get('/Title', 'Unknown Title')\n",
        "\n",
        "        return {\n",
        "            'Author': author,\n",
        "            'Creator': creator,\n",
        "            'Producer': producer,\n",
        "            'Subject': subject,\n",
        "            'Title': title,\n",
        "            'Number of Pages': num_pages\n",
        "        }\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    pdf_paths = ['/content/gen1/A-New-Vegetation-Index-to-Dete-35086913-d72d-4d90-b224-4bd93a517488.pdf','/content/gen1/Ai.pdf','/content/gen1/The-global-mangrove-watch-a-ne-4abecf89-c8a2-4e96-9c66-98c850be668f.pdf']\n",
        "\n",
        "    for path in pdf_paths:\n",
        "        pdf_info = get_info(path)\n",
        "        print(f\"PDF: {path}\")\n",
        "        for key, value in pdf_info.items():\n",
        "            print(f\"{key}: {value}\")\n",
        "        print(\"=\" * 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0SB2r13V80k",
        "outputId": "6d2e55c6-5d04-42e0-9351-9693ecdc9d53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF: /content/gen1/A-New-Vegetation-Index-to-Dete-35086913-d72d-4d90-b224-4bd93a517488.pdf\n",
            "Author: Unknown Author\n",
            "Creator: Unknown Creator\n",
            "Producer: iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)\n",
            "Subject: Unknown Subject\n",
            "Title: Unknown Title\n",
            "Number of Pages: 17\n",
            "==============================\n",
            "PDF: /content/gen1/Ai.pdf\n",
            "Author: \n",
            "Creator: LaTeX with hyperref package\n",
            "Producer: dvips + AFPL Ghostscript 8.53\n",
            "Subject: \n",
            "Title: \n",
            "Number of Pages: 15\n",
            "==============================\n",
            "PDF: /content/gen1/The-global-mangrove-watch-a-ne-4abecf89-c8a2-4e96-9c66-98c850be668f.pdf\n",
            "Author: Pete Bunting, Ake Rosenqvist, Richard M. Lucas, Lisa-Maria Rebelo, Lammert Hilarides, Nathan Thomas, Andy Hardy, Takuya Itoh, Masanobu Shimada and C. Max Finlayson\n",
            "Creator: LaTeX with hyperref package\n",
            "Producer: pdfTeX-1.40.18\n",
            "Subject:  This study presents a new global baseline of mangrove extent for 2010 and has been released as the first output of the Global Mangrove Watch (GMW) initiative. This is the first study to apply a globally consistent and automated method for mapping mangroves, identifying a global extent of 137,600 km2. The overall accuracy for mangrove extent was 94.0% with a 99% likelihood that the true value is between 93.6–94.5%, using 53,878 accuracy points across 20 sites distributed globally. Using the geographic regions of the Ramsar Convention on Wetlands, Asia has the highest proportion of mangroves with 38.7% of the global total, while Latin America and the Caribbean have 20.3%, Africa has 20.0%, Oceania has 11.9%, North America has 8.4% and the European Overseas Territories have 0.7%. The methodology developed is primarily based on the classification of ALOS PALSAR and Landsat sensor data, where a habitat mask was first generated, within which the classification of mangrove was undertaken using the Extremely Randomized Trees classifier. This new globally consistent baseline will also form the basis of a mangrove monitoring system using JAXA JERS-1 SAR, ALOS PALSAR and ALOS-2 PALSAR-2 radar data to assess mangrove change from 1996 to the present. However, when using the product, users should note that a minimum mapping unit of 1 ha is recommended and that the error increases in regions of disturbance and where narrow strips or smaller fragmented areas of mangroves are present. Artefacts due to cloud cover and the Landsat-7 SLC-off error are also present in some areas, particularly regions of West Africa due to the lack of Landsat-5 data and persistence cloud cover. In the future, consideration will be given to the production of a new global baseline based on 10 m Sentinel-2 composites. \n",
            "Title: The Global Mangrove Watch—A New 2010 Global Baseline of Mangrove Extent\n",
            "Number of Pages: 19\n",
            "==============================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PyPDF2 import PdfFileReader\n",
        "\n",
        "def get_info(path):\n",
        "    with open(path, 'rb') as f:\n",
        "        pdf = PdfReader(f)\n",
        "        metadata = pdf.metadata\n",
        "        num_pages = len(pdf.pages)\n",
        "\n",
        "        author = metadata.get('/Author', 'Unknown Author')\n",
        "        creator = metadata.get('/Creator', 'Unknown Creator')\n",
        "        producer = metadata.get('/Producer', 'Unknown Producer')\n",
        "        subject = metadata.get('/Subject', 'Unknown Subject')\n",
        "        title = metadata.get('/Title', 'Unknown Title')\n",
        "\n",
        "        return {\n",
        "            'Author': author,\n",
        "            'Creator': creator,\n",
        "            'Producer': producer,\n",
        "            'Subject': subject,\n",
        "            'Title': title,\n",
        "            'Number of Pages': num_pages\n",
        "        }\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    #pdf_dir = '/content/gen1'\n",
        "    pdf_paths = [os.path.join(pdf_dir, filename) for filename in os.listdir(pdf_dir) if filename.lower().endswith('.pdf')]\n",
        "\n",
        "    for path in pdf_paths:\n",
        "        pdf_info = get_info(path)\n",
        "        print(f\"PDF: {path}\")\n",
        "        for key, value in pdf_info.items():\n",
        "            print(f\"{key}: {value}\")\n",
        "        print(\"=\" * 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KeuFfisW0JI",
        "outputId": "39f0b53d-d5e6-4b33-8682-eadf02195800"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF: /content/gen1/The-global-mangrove-watch-a-ne-4abecf89-c8a2-4e96-9c66-98c850be668f.pdf\n",
            "Author: Pete Bunting, Ake Rosenqvist, Richard M. Lucas, Lisa-Maria Rebelo, Lammert Hilarides, Nathan Thomas, Andy Hardy, Takuya Itoh, Masanobu Shimada and C. Max Finlayson\n",
            "Creator: LaTeX with hyperref package\n",
            "Producer: pdfTeX-1.40.18\n",
            "Subject:  This study presents a new global baseline of mangrove extent for 2010 and has been released as the first output of the Global Mangrove Watch (GMW) initiative. This is the first study to apply a globally consistent and automated method for mapping mangroves, identifying a global extent of 137,600 km2. The overall accuracy for mangrove extent was 94.0% with a 99% likelihood that the true value is between 93.6–94.5%, using 53,878 accuracy points across 20 sites distributed globally. Using the geographic regions of the Ramsar Convention on Wetlands, Asia has the highest proportion of mangroves with 38.7% of the global total, while Latin America and the Caribbean have 20.3%, Africa has 20.0%, Oceania has 11.9%, North America has 8.4% and the European Overseas Territories have 0.7%. The methodology developed is primarily based on the classification of ALOS PALSAR and Landsat sensor data, where a habitat mask was first generated, within which the classification of mangrove was undertaken using the Extremely Randomized Trees classifier. This new globally consistent baseline will also form the basis of a mangrove monitoring system using JAXA JERS-1 SAR, ALOS PALSAR and ALOS-2 PALSAR-2 radar data to assess mangrove change from 1996 to the present. However, when using the product, users should note that a minimum mapping unit of 1 ha is recommended and that the error increases in regions of disturbance and where narrow strips or smaller fragmented areas of mangroves are present. Artefacts due to cloud cover and the Landsat-7 SLC-off error are also present in some areas, particularly regions of West Africa due to the lack of Landsat-5 data and persistence cloud cover. In the future, consideration will be given to the production of a new global baseline based on 10 m Sentinel-2 composites. \n",
            "Title: The Global Mangrove Watch—A New 2010 Global Baseline of Mangrove Extent\n",
            "Number of Pages: 19\n",
            "==============================\n",
            "PDF: /content/gen1/A-New-Vegetation-Index-to-Dete-35086913-d72d-4d90-b224-4bd93a517488.pdf\n",
            "Author: Unknown Author\n",
            "Creator: Unknown Creator\n",
            "Producer: iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)\n",
            "Subject: Unknown Subject\n",
            "Title: Unknown Title\n",
            "Number of Pages: 17\n",
            "==============================\n",
            "PDF: /content/gen1/Ai.pdf\n",
            "Author: \n",
            "Creator: LaTeX with hyperref package\n",
            "Producer: dvips + AFPL Ghostscript 8.53\n",
            "Subject: \n",
            "Title: \n",
            "Number of Pages: 15\n",
            "==============================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JxdNJOhHLaxp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}